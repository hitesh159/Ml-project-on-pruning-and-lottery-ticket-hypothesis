{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_ml_project_fashion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaigMpdVIhYQ"
      },
      "source": [
        "#importing the libraries\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import gzip, pickle\n",
        "from torch import nn\n",
        "from torch import tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import requests\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import torch.nn.utils.prune as prune\n",
        "from math import ceil\n",
        "from torch.autograd import Variable\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjaHhDDgNM2d",
        "outputId": "43f01bb7-1cae-42ef-a023-d9992f9f5673"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIzJnIfFRRSV"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJqZnEB_RTWe",
        "outputId": "99809b9a-b154-4b03-cfc2-ede8e5705602"
      },
      "source": [
        "print( device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghS8oN2ZlN3P"
      },
      "source": [
        "#### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaNIfuj_NaQM"
      },
      "source": [
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzIc2YxAIpu5"
      },
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST('/content/drive/MyDrive/ml project/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                             ]))\n",
        "test_dataset =torchvision.datasets.FashionMNIST('/content/drive/MyDrive/ml project/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               \n",
        "                             ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC1N9zeldCKS",
        "outputId": "ce054af3-f2fd-474b-b599-06993b0f6658"
      },
      "source": [
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /content/drive/MyDrive/ml project/\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxjQVamZNmm2"
      },
      "source": [
        "train_dataset,val_dataset=torch.utils.data.dataset.random_split(train_dataset,lengths=[50000,10000],generator=torch.Generator().manual_seed(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShfGNG67dknV",
        "outputId": "bccfe6fd-849e-4a3b-cf8d-6e0197d43ab1"
      },
      "source": [
        "train_dataset.dataset[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyobWQGyZkWY"
      },
      "source": [
        "BATCH_SIZE=256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8WdY5aUY9tn"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
        "test_loader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U5nWDhhPUjg"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMf0LHCrTPyw"
      },
      "source": [
        "#LeNet-5 archietecture\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1)\n",
        "    self.average1 = nn.AvgPool2d(2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "    self.average2 = nn.AvgPool2d(2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(16, 120, kernel_size=4, stride=1)\n",
        "    self.flatten1 = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(120, 82)\n",
        "    self.fc2 = nn.Linear(82,10)\n",
        "  def forward(self,x):\n",
        "    out = x.view(-1, 1, 28, 28)\n",
        "    out = torch.tanh(self.conv1(out))\n",
        "    out = self.average1(out)\n",
        "    out = torch.tanh(self.conv2(out))\n",
        "    out = self.average2(out)\n",
        "    out = torch.tanh(self.conv3(out))\n",
        "    out = out.view(-1, out.shape[1])\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    out = F.softmax(self.fc2(out),dim=1)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lzqx1fGWFQN"
      },
      "source": [
        "model=Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyCW8CnbWJNO",
        "outputId": "3a40fe85-ad4c-4578-d772-e0d299b1ae53"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (average1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (average2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (flatten1): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=120, out_features=82, bias=True)\n",
              "  (fc2): Linear(in_features=82, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_brFocx2WWuY"
      },
      "source": [
        "learning_rate = 0.1\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn-ksHOuWsdD"
      },
      "source": [
        "crieteria=nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TBuAcKiW0f2"
      },
      "source": [
        "n_epochs=100\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "train_accuracy=[]\n",
        "val_accuracy=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_tcLZxsbDBH"
      },
      "source": [
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJfTdd0aldsO"
      },
      "source": [
        "#### Training baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipoh_bS9aldo",
        "outputId": "0d72e922-3636-46b3-f01e-2f15c3a0a507"
      },
      "source": [
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "  tr_loss=0\n",
        "  vl_loss=0\n",
        "  print(f\"-----------EPOCH {epoch} ------------------ \")\n",
        "  correct=0\n",
        "  for images, labels in train_loader:\n",
        "    #print(images.shape,len(labels))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    train = Variable(images.view(len(images), 1, 28, 28))\n",
        "    labels = Variable(labels)\n",
        "    outputs = model(train)\n",
        "   # print(outputs.shape)\n",
        "    loss = crieteria(outputs, labels)\n",
        "    tr_loss+=loss.item()*len(images)\n",
        "    predictions = torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss.append(tr_loss/len(train_dataset))\n",
        "  train_accuracy.append(correct/len(train_dataset))\n",
        "  print(f\"Training loss :{tr_loss/len(train_dataset)}\")\n",
        "  print(f\"Training Accuracy :{correct/len(train_dataset)}\")\n",
        "  correct=0\n",
        "  for images, labels in val_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    val = Variable(images.view(len(images), 1, 28, 28))\n",
        "    labels = Variable(labels)\n",
        "    outputs = model(val)\n",
        "    loss = crieteria(outputs, labels)\n",
        "    vl_loss+=loss.item()*len(images)\n",
        "    predictions = torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum()\n",
        "  val_loss.append(vl_loss/len(val_dataset))\n",
        "  val_accuracy.append(correct/len(val_dataset))\n",
        "  print(f\"Validation loss :{vl_loss/len(val_dataset)}\")\n",
        "  print(f\"Validation Accuracy :{correct/len(val_dataset)}\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.2606210261535646\n",
            "Training Accuracy :0.1750199943780899\n",
            "Validation loss :2.066728182411194\n",
            "Validation Accuracy :0.3971000015735626\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.8794935385894775\n",
            "Training Accuracy :0.6176999807357788\n",
            "Validation loss :1.7668575136184692\n",
            "Validation Accuracy :0.7226999998092651\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.738651905860901\n",
            "Training Accuracy :0.7410399913787842\n",
            "Validation loss :1.7149710748672486\n",
            "Validation Accuracy :0.7567999958992004\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.7033669500350952\n",
            "Training Accuracy :0.7679599523544312\n",
            "Validation loss :1.6974736894607545\n",
            "Validation Accuracy :0.7736999988555908\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.684995242614746\n",
            "Training Accuracy :0.784339964389801\n",
            "Validation loss :1.6786828147888184\n",
            "Validation Accuracy :0.7906000018119812\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6721498733520508\n",
            "Training Accuracy :0.7971199750900269\n",
            "Validation loss :1.6631513551712036\n",
            "Validation Accuracy :0.8066999912261963\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6618410833358765\n",
            "Training Accuracy :0.8068999648094177\n",
            "Validation loss :1.655055153465271\n",
            "Validation Accuracy :0.8130999803543091\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6530093063735962\n",
            "Training Accuracy :0.8139399886131287\n",
            "Validation loss :1.6464076633453368\n",
            "Validation Accuracy :0.8199999928474426\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6440981484222412\n",
            "Training Accuracy :0.8222000002861023\n",
            "Validation loss :1.6589997547149657\n",
            "Validation Accuracy :0.8072999715805054\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.637754427871704\n",
            "Training Accuracy :0.8286799788475037\n",
            "Validation loss :1.6371227500915528\n",
            "Validation Accuracy :0.8278999924659729\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6323505349349976\n",
            "Training Accuracy :0.8330199718475342\n",
            "Validation loss :1.6363964908599853\n",
            "Validation Accuracy :0.8294999599456787\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6263423543930053\n",
            "Training Accuracy :0.8391799926757812\n",
            "Validation loss :1.6247158349990845\n",
            "Validation Accuracy :0.8389999866485596\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6230121520996095\n",
            "Training Accuracy :0.8414799571037292\n",
            "Validation loss :1.6229536054611207\n",
            "Validation Accuracy :0.8430999517440796\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6177463381195067\n",
            "Training Accuracy :0.8462799787521362\n",
            "Validation loss :1.6230310665130616\n",
            "Validation Accuracy :0.8398999571800232\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.614139880065918\n",
            "Training Accuracy :0.8506399989128113\n",
            "Validation loss :1.6158027639389039\n",
            "Validation Accuracy :0.8481999635696411\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.610659605140686\n",
            "Training Accuracy :0.8538999557495117\n",
            "Validation loss :1.6186154573440552\n",
            "Validation Accuracy :0.8445000052452087\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6085912828826905\n",
            "Training Accuracy :0.8558200001716614\n",
            "Validation loss :1.6170003381729126\n",
            "Validation Accuracy :0.8452999591827393\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.606316437034607\n",
            "Training Accuracy :0.8569999933242798\n",
            "Validation loss :1.6068115306854247\n",
            "Validation Accuracy :0.856499969959259\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.603318964881897\n",
            "Training Accuracy :0.8605799674987793\n",
            "Validation loss :1.6235438997268676\n",
            "Validation Accuracy :0.838699996471405\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6005312799835205\n",
            "Training Accuracy :0.8628999590873718\n",
            "Validation loss :1.6027968473434449\n",
            "Validation Accuracy :0.8589999675750732\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5995902672576905\n",
            "Training Accuracy :0.8642199635505676\n",
            "Validation loss :1.6035111499786376\n",
            "Validation Accuracy :0.8600999712944031\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.5969758235168456\n",
            "Training Accuracy :0.8660399913787842\n",
            "Validation loss :1.6010444065093994\n",
            "Validation Accuracy :0.8622999787330627\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.5937945614242555\n",
            "Training Accuracy :0.8700599670410156\n",
            "Validation loss :1.6002436933517457\n",
            "Validation Accuracy :0.8631999492645264\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.5923290032577515\n",
            "Training Accuracy :0.8709799647331238\n",
            "Validation loss :1.5988355188369752\n",
            "Validation Accuracy :0.8629999756813049\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.591148718185425\n",
            "Training Accuracy :0.8722599744796753\n",
            "Validation loss :1.5973232374191284\n",
            "Validation Accuracy :0.8639000058174133\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5880898455810546\n",
            "Training Accuracy :0.8757399916648865\n",
            "Validation loss :1.6017651201248169\n",
            "Validation Accuracy :0.861299991607666\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5876623503875733\n",
            "Training Accuracy :0.8756799697875977\n",
            "Validation loss :1.595196572303772\n",
            "Validation Accuracy :0.8664000034332275\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.586540913887024\n",
            "Training Accuracy :0.8768799901008606\n",
            "Validation loss :1.5956922203063966\n",
            "Validation Accuracy :0.8661999702453613\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5851745972442628\n",
            "Training Accuracy :0.878600001335144\n",
            "Validation loss :1.5931790250778197\n",
            "Validation Accuracy :0.8691999912261963\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5827879809188843\n",
            "Training Accuracy :0.8804799914360046\n",
            "Validation loss :1.5951274055480957\n",
            "Validation Accuracy :0.8690999746322632\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5822221187973022\n",
            "Training Accuracy :0.8811599612236023\n",
            "Validation loss :1.5939350286483764\n",
            "Validation Accuracy :0.8672999739646912\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.581063519706726\n",
            "Training Accuracy :0.8827599883079529\n",
            "Validation loss :1.5940628498077392\n",
            "Validation Accuracy :0.8673999905586243\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5799348113632201\n",
            "Training Accuracy :0.8825399875640869\n",
            "Validation loss :1.589138027381897\n",
            "Validation Accuracy :0.8726999759674072\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5790551774597168\n",
            "Training Accuracy :0.8840199708938599\n",
            "Validation loss :1.591772235107422\n",
            "Validation Accuracy :0.8707000017166138\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5771562784576416\n",
            "Training Accuracy :0.8865799903869629\n",
            "Validation loss :1.5912661287307739\n",
            "Validation Accuracy :0.8705999851226807\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.575641104698181\n",
            "Training Accuracy :0.887499988079071\n",
            "Validation loss :1.5857104118347167\n",
            "Validation Accuracy :0.8763999938964844\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5741578559494018\n",
            "Training Accuracy :0.8886999487876892\n",
            "Validation loss :1.589144441986084\n",
            "Validation Accuracy :0.8739999532699585\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5727626363754272\n",
            "Training Accuracy :0.8908599615097046\n",
            "Validation loss :1.585771367073059\n",
            "Validation Accuracy :0.8763999938964844\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5707004668426514\n",
            "Training Accuracy :0.8924399614334106\n",
            "Validation loss :1.5820252201080323\n",
            "Validation Accuracy :0.8797000050544739\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5690149965667726\n",
            "Training Accuracy :0.8943600058555603\n",
            "Validation loss :1.5885240005493164\n",
            "Validation Accuracy :0.8740999698638916\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5684107711791992\n",
            "Training Accuracy :0.8949199914932251\n",
            "Validation loss :1.5808517389297485\n",
            "Validation Accuracy :0.8822999596595764\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5666598086166381\n",
            "Training Accuracy :0.8969799876213074\n",
            "Validation loss :1.5816565139770509\n",
            "Validation Accuracy :0.8807999491691589\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5657226768112182\n",
            "Training Accuracy :0.8979799747467041\n",
            "Validation loss :1.5793015768051148\n",
            "Validation Accuracy :0.8836999535560608\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5648384867858887\n",
            "Training Accuracy :0.8985799551010132\n",
            "Validation loss :1.580346509552002\n",
            "Validation Accuracy :0.8804000020027161\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.564241647415161\n",
            "Training Accuracy :0.8986999988555908\n",
            "Validation loss :1.5815447282791137\n",
            "Validation Accuracy :0.8800999522209167\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5632378720092774\n",
            "Training Accuracy :0.8997799754142761\n",
            "Validation loss :1.578405803489685\n",
            "Validation Accuracy :0.8836999535560608\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5613758826828004\n",
            "Training Accuracy :0.901919960975647\n",
            "Validation loss :1.5783661903381347\n",
            "Validation Accuracy :0.8841999769210815\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5608684367370604\n",
            "Training Accuracy :0.9023599624633789\n",
            "Validation loss :1.5791901741027832\n",
            "Validation Accuracy :0.8835999965667725\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5608226940536498\n",
            "Training Accuracy :0.9022799730300903\n",
            "Validation loss :1.5771392379760742\n",
            "Validation Accuracy :0.8842999935150146\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5592882592010497\n",
            "Training Accuracy :0.9039799571037292\n",
            "Validation loss :1.5759215950012206\n",
            "Validation Accuracy :0.8858999609947205\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5586398976898193\n",
            "Training Accuracy :0.9042199850082397\n",
            "Validation loss :1.5817391199111939\n",
            "Validation Accuracy :0.8792999982833862\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5573197119140625\n",
            "Training Accuracy :0.906059980392456\n",
            "Validation loss :1.5751485401153564\n",
            "Validation Accuracy :0.8867999911308289\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5570662210083008\n",
            "Training Accuracy :0.906059980392456\n",
            "Validation loss :1.5822045177459716\n",
            "Validation Accuracy :0.8794999718666077\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5557507390594483\n",
            "Training Accuracy :0.9075599908828735\n",
            "Validation loss :1.5741882341384887\n",
            "Validation Accuracy :0.8876999616622925\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5558447491073608\n",
            "Training Accuracy :0.9076399803161621\n",
            "Validation loss :1.576819458580017\n",
            "Validation Accuracy :0.8844999670982361\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.554128281326294\n",
            "Training Accuracy :0.9090200066566467\n",
            "Validation loss :1.5752073213577271\n",
            "Validation Accuracy :0.8858000040054321\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5535301364135743\n",
            "Training Accuracy :0.9096599817276001\n",
            "Validation loss :1.572461671447754\n",
            "Validation Accuracy :0.889799952507019\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5526809339141845\n",
            "Training Accuracy :0.9110999703407288\n",
            "Validation loss :1.573599167060852\n",
            "Validation Accuracy :0.8870999813079834\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.551993254776001\n",
            "Training Accuracy :0.9114599823951721\n",
            "Validation loss :1.5806348342895509\n",
            "Validation Accuracy :0.8816999793052673\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.551970459136963\n",
            "Training Accuracy :0.9112799763679504\n",
            "Validation loss :1.5725754888534547\n",
            "Validation Accuracy :0.88919997215271\n",
            "-----------EPOCH 60 ------------------ \n",
            "Training loss :1.5506993909835816\n",
            "Training Accuracy :0.9125999808311462\n",
            "Validation loss :1.573242659187317\n",
            "Validation Accuracy :0.8894999623298645\n",
            "-----------EPOCH 61 ------------------ \n",
            "Training loss :1.5512898696899413\n",
            "Training Accuracy :0.9120399951934814\n",
            "Validation loss :1.5716426155090333\n",
            "Validation Accuracy :0.8889999985694885\n",
            "-----------EPOCH 62 ------------------ \n",
            "Training loss :1.5488742261505126\n",
            "Training Accuracy :0.9143799543380737\n",
            "Validation loss :1.574523850440979\n",
            "Validation Accuracy :0.8868999481201172\n",
            "-----------EPOCH 63 ------------------ \n",
            "Training loss :1.548659405899048\n",
            "Training Accuracy :0.9141599535942078\n",
            "Validation loss :1.5708495027542115\n",
            "Validation Accuracy :0.8913999795913696\n",
            "-----------EPOCH 64 ------------------ \n",
            "Training loss :1.5474423706817626\n",
            "Training Accuracy :0.9158999919891357\n",
            "Validation loss :1.572323745918274\n",
            "Validation Accuracy :0.8898999691009521\n",
            "-----------EPOCH 65 ------------------ \n",
            "Training loss :1.547809114151001\n",
            "Training Accuracy :0.915340006351471\n",
            "Validation loss :1.572456639099121\n",
            "Validation Accuracy :0.8888999819755554\n",
            "-----------EPOCH 66 ------------------ \n",
            "Training loss :1.5477278354263306\n",
            "Training Accuracy :0.915340006351471\n",
            "Validation loss :1.5706992990493776\n",
            "Validation Accuracy :0.8906999826431274\n",
            "-----------EPOCH 67 ------------------ \n",
            "Training loss :1.5470115922546386\n",
            "Training Accuracy :0.916659951210022\n",
            "Validation loss :1.5709236219406129\n",
            "Validation Accuracy :0.8903999924659729\n",
            "-----------EPOCH 68 ------------------ \n",
            "Training loss :1.5469440116119384\n",
            "Training Accuracy :0.9159599542617798\n",
            "Validation loss :1.5741461860656738\n",
            "Validation Accuracy :0.8881999850273132\n",
            "-----------EPOCH 69 ------------------ \n",
            "Training loss :1.5450890524291991\n",
            "Training Accuracy :0.9182199835777283\n",
            "Validation loss :1.5723675136566162\n",
            "Validation Accuracy :0.8885999917984009\n",
            "-----------EPOCH 70 ------------------ \n",
            "Training loss :1.5446524398422241\n",
            "Training Accuracy :0.9187600016593933\n",
            "Validation loss :1.5697396690368652\n",
            "Validation Accuracy :0.8917999863624573\n",
            "-----------EPOCH 71 ------------------ \n",
            "Training loss :1.5436498044586182\n",
            "Training Accuracy :0.9198600053787231\n",
            "Validation loss :1.5701374347686767\n",
            "Validation Accuracy :0.889799952507019\n",
            "-----------EPOCH 72 ------------------ \n",
            "Training loss :1.5431725261688232\n",
            "Training Accuracy :0.91975998878479\n",
            "Validation loss :1.5738425937652587\n",
            "Validation Accuracy :0.8866999745368958\n",
            "-----------EPOCH 73 ------------------ \n",
            "Training loss :1.542962357940674\n",
            "Training Accuracy :0.9205799698829651\n",
            "Validation loss :1.567940983390808\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 74 ------------------ \n",
            "Training loss :1.5427996991729735\n",
            "Training Accuracy :0.9204199910163879\n",
            "Validation loss :1.5694742456436157\n",
            "Validation Accuracy :0.8930000066757202\n",
            "-----------EPOCH 75 ------------------ \n",
            "Training loss :1.54199015625\n",
            "Training Accuracy :0.9215799570083618\n",
            "Validation loss :1.5696778657913208\n",
            "Validation Accuracy :0.8914999961853027\n",
            "-----------EPOCH 76 ------------------ \n",
            "Training loss :1.5407574011611938\n",
            "Training Accuracy :0.9230999946594238\n",
            "Validation loss :1.5702127752304078\n",
            "Validation Accuracy :0.8915999531745911\n",
            "-----------EPOCH 77 ------------------ \n",
            "Training loss :1.5407699394989014\n",
            "Training Accuracy :0.9225399494171143\n",
            "Validation loss :1.573860192489624\n",
            "Validation Accuracy :0.8865999579429626\n",
            "-----------EPOCH 78 ------------------ \n",
            "Training loss :1.5406538171005248\n",
            "Training Accuracy :0.9231399893760681\n",
            "Validation loss :1.568639426422119\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 79 ------------------ \n",
            "Training loss :1.5406672216415405\n",
            "Training Accuracy :0.922059953212738\n",
            "Validation loss :1.5724773378372192\n",
            "Validation Accuracy :0.8886999487876892\n",
            "-----------EPOCH 80 ------------------ \n",
            "Training loss :1.5382948972702026\n",
            "Training Accuracy :0.9250999689102173\n",
            "Validation loss :1.5679612266540528\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 81 ------------------ \n",
            "Training loss :1.5385413858795165\n",
            "Training Accuracy :0.9250999689102173\n",
            "Validation loss :1.5685553691864014\n",
            "Validation Accuracy :0.8930000066757202\n",
            "-----------EPOCH 82 ------------------ \n",
            "Training loss :1.5380747692108154\n",
            "Training Accuracy :0.9253000020980835\n",
            "Validation loss :1.5679774618148803\n",
            "Validation Accuracy :0.894599974155426\n",
            "-----------EPOCH 83 ------------------ \n",
            "Training loss :1.5378201230621338\n",
            "Training Accuracy :0.9257199764251709\n",
            "Validation loss :1.5692376539230346\n",
            "Validation Accuracy :0.890999972820282\n",
            "-----------EPOCH 84 ------------------ \n",
            "Training loss :1.537683665084839\n",
            "Training Accuracy :0.9258599877357483\n",
            "Validation loss :1.5694542516708374\n",
            "Validation Accuracy :0.8917999863624573\n",
            "-----------EPOCH 85 ------------------ \n",
            "Training loss :1.5364108792495728\n",
            "Training Accuracy :0.9271599650382996\n",
            "Validation loss :1.5681820022583008\n",
            "Validation Accuracy :0.8922999501228333\n",
            "-----------EPOCH 86 ------------------ \n",
            "Training loss :1.5367661392974854\n",
            "Training Accuracy :0.9264400005340576\n",
            "Validation loss :1.5669203966140748\n",
            "Validation Accuracy :0.8949999809265137\n",
            "-----------EPOCH 87 ------------------ \n",
            "Training loss :1.5356478022384643\n",
            "Training Accuracy :0.9275199770927429\n",
            "Validation loss :1.5655240032196045\n",
            "Validation Accuracy :0.8955999612808228\n",
            "-----------EPOCH 88 ------------------ \n",
            "Training loss :1.5352735419464112\n",
            "Training Accuracy :0.9280999898910522\n",
            "Validation loss :1.568191665840149\n",
            "Validation Accuracy :0.8935999870300293\n",
            "-----------EPOCH 89 ------------------ \n",
            "Training loss :1.534307215461731\n",
            "Training Accuracy :0.9296199679374695\n",
            "Validation loss :1.5666568864822388\n",
            "Validation Accuracy :0.8953999876976013\n",
            "-----------EPOCH 90 ------------------ \n",
            "Training loss :1.5344232022476196\n",
            "Training Accuracy :0.9286999702453613\n",
            "Validation loss :1.565596372795105\n",
            "Validation Accuracy :0.8962999582290649\n",
            "-----------EPOCH 91 ------------------ \n",
            "Training loss :1.5340360370635986\n",
            "Training Accuracy :0.9295199513435364\n",
            "Validation loss :1.5666549131393432\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 92 ------------------ \n",
            "Training loss :1.5335825382232666\n",
            "Training Accuracy :0.9300199747085571\n",
            "Validation loss :1.5680361507415772\n",
            "Validation Accuracy :0.8937999606132507\n",
            "-----------EPOCH 93 ------------------ \n",
            "Training loss :1.532758518371582\n",
            "Training Accuracy :0.9303399920463562\n",
            "Validation loss :1.566012822151184\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 94 ------------------ \n",
            "Training loss :1.5331795360565186\n",
            "Training Accuracy :0.9300199747085571\n",
            "Validation loss :1.5669125896453857\n",
            "Validation Accuracy :0.8953999876976013\n",
            "-----------EPOCH 95 ------------------ \n",
            "Training loss :1.5315922730255127\n",
            "Training Accuracy :0.931659996509552\n",
            "Validation loss :1.5677097663879394\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 96 ------------------ \n",
            "Training loss :1.5321767611694337\n",
            "Training Accuracy :0.9308399558067322\n",
            "Validation loss :1.5657622323989868\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 97 ------------------ \n",
            "Training loss :1.531146604385376\n",
            "Training Accuracy :0.9322800040245056\n",
            "Validation loss :1.5673485763549804\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 98 ------------------ \n",
            "Training loss :1.5311202858352662\n",
            "Training Accuracy :0.9322199821472168\n",
            "Validation loss :1.566511386489868\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 99 ------------------ \n",
            "Training loss :1.5312559578704834\n",
            "Training Accuracy :0.9318199753761292\n",
            "Validation loss :1.5685195192337036\n",
            "Validation Accuracy :0.8920999765396118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw0M4AQXoYEN",
        "outputId": "6f75155e-80ec-4e28-d9cf-85b9a4f4741f"
      },
      "source": [
        "model(test_dataset[100][0].view(1,1,28,28).to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.0256e-09, 1.0799e-12, 7.3252e-12, 7.8732e-15, 3.2393e-10, 1.5599e-08,\n",
              "         1.0000e+00, 1.4372e-17, 2.1705e-10, 1.1894e-14]], device='cuda:0',\n",
              "       grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI6VmJgarlh8",
        "outputId": "8e88a056-8190-499b-8163-22d9b71c0663"
      },
      "source": [
        "#Testing baseline\n",
        "tloss=0\n",
        "correct=0\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    val = Variable(images.view(len(images), 1, 28, 28))\n",
        "    labels = Variable(labels)\n",
        "    outputs = model(val)\n",
        "    loss = crieteria(outputs, labels)\n",
        "    tloss+=loss.item()*len(images)\n",
        "    predictions = torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum()\n",
        "print(f\"Test loss :{tloss/len(test_dataset)}\")\n",
        "print(f\"Test Accuracy :{correct/len(test_dataset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss :1.5707487842559815\n",
            "Test Accuracy :0.8896999955177307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNbzuQgTm388"
      },
      "source": [
        "torch.save(model,\"/content/drive/MyDrive/ml project/model1_fas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O9VGYN2whU6"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUSmPv9Ryf3R",
        "outputId": "40567bb5-13c3-4e53-b777-4565c4f9a047"
      },
      "source": [
        "pytorch_total_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhkvSIky6oKK"
      },
      "source": [
        "import torch.nn.utils.prune as prune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nxPoXVKC9P_",
        "outputId": "51f8bde0-c447-4b8b-89d7-363b50ff161b"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (average1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (average2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=120, out_features=82, bias=True)\n",
              "  (fc2): Linear(in_features=82, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVFSqEnJDZF9"
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u1YhGDJly0R"
      },
      "source": [
        "#### Magnitude based pruning without retraining "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy8o42Kxm6NH"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/model1_fas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx8EkyaGst_A",
        "outputId": "18bedfca-eabf-4ae7-cb18-fb1c6e028bec"
      },
      "source": [
        "acc_wr=[0.8896999955177307]\n",
        "sparsity_wr=[1]\n",
        "for i in range(20):\n",
        "  parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.conv3, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "  )\n",
        "\n",
        "  prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        "  )\n",
        "\n",
        "  model.eval()\n",
        "  tloss=0\n",
        "  correct=0\n",
        "  for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tloss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "  print(f\"Test loss :{tloss/len(test_dataset)}\")\n",
        "  print(f\"Test Accuracy :{correct/len(test_dataset)}\")\n",
        "  sparsity_wr.append((1-0.2)**(i+1))\n",
        "  acc_wr.append(correct/len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss :1.5695224208831786\n",
            "Test Accuracy :0.8912000060081482\n",
            "Test loss :1.5719544815063478\n",
            "Test Accuracy :0.8880999684333801\n",
            "Test loss :1.578007314300537\n",
            "Test Accuracy :0.8827999830245972\n",
            "Test loss :1.5822379123687744\n",
            "Test Accuracy :0.8779000043869019\n",
            "Test loss :1.5907931869506835\n",
            "Test Accuracy :0.871399998664856\n",
            "Test loss :1.6102499485015869\n",
            "Test Accuracy :0.8515999913215637\n",
            "Test loss :1.6251988744735717\n",
            "Test Accuracy :0.837399959564209\n",
            "Test loss :1.6698698499679565\n",
            "Test Accuracy :0.7978999614715576\n",
            "Test loss :1.7661153009414672\n",
            "Test Accuracy :0.703000009059906\n",
            "Test loss :1.8523760080337524\n",
            "Test Accuracy :0.617900013923645\n",
            "Test loss :1.9573596134185791\n",
            "Test Accuracy :0.508899986743927\n",
            "Test loss :2.0352761749267576\n",
            "Test Accuracy :0.41589999198913574\n",
            "Test loss :2.160883317184448\n",
            "Test Accuracy :0.28380000591278076\n",
            "Test loss :2.261171620941162\n",
            "Test Accuracy :0.16759999096393585\n",
            "Test loss :2.2596914867401123\n",
            "Test Accuracy :0.1622999906539917\n",
            "Test loss :2.2768391487121584\n",
            "Test Accuracy :0.12199999392032623\n",
            "Test loss :2.275445572280884\n",
            "Test Accuracy :0.1370999962091446\n",
            "Test loss :2.2601618560791015\n",
            "Test Accuracy :0.17469999194145203\n",
            "Test loss :2.2802658180236817\n",
            "Test Accuracy :0.142099991440773\n",
            "Test loss :2.3026725006103517\n",
            "Test Accuracy :0.11180000007152557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il3tD3VIt9r5"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "2SsETkwaufqM",
        "outputId": "372a585b-897b-4e45-97eb-bd6a4695e097"
      },
      "source": [
        "#plotting sparsity vs accuracy \n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.plot(sparsity_wr,acc_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd64321d1d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPycSZY3mNm5"
      },
      "source": [
        "#### Magnitude based untructured pruning with retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lLmyN8ZnNeo"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/model1_fas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9KRFA66wOz2",
        "outputId": "20055058-f2f6-418e-cd6a-9795d5ae7cd1"
      },
      "source": [
        "acc=[0.8896999955177307]\n",
        "sparsity=[1]\n",
        "for i in range(20):\n",
        "  parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.conv3, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "  )\n",
        "\n",
        "  prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        "  )\n",
        "  n_epochs=10\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  train_accuracy=[]\n",
        "  val_accuracy=[]\n",
        "  learning_rate = 0.01\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "  model.train()\n",
        "  for epoch in range(n_epochs):\n",
        "    tr_loss=0\n",
        "    vl_loss=0\n",
        "    print(f\"-----------EPOCH {epoch} ------------------ \")\n",
        "    correct=0\n",
        "    for images, labels in train_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      train = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(train)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tr_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    train_loss.append(tr_loss/len(train_dataset))\n",
        "    train_accuracy.append(correct/len(train_dataset))\n",
        "    print(f\"Training loss :{tr_loss/len(train_dataset)}\")\n",
        "    print(f\"Training Accuracy :{correct/len(train_dataset)}\")\n",
        "    correct=0\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      vl_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "    val_loss.append(vl_loss/len(val_dataset))\n",
        "    val_accuracy.append(correct/len(val_dataset))\n",
        "    print(f\"Validation loss :{vl_loss/len(val_dataset)}\")\n",
        "    print(f\"Validation Accuracy :{correct/len(val_dataset)}\")\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  tloss=0\n",
        "  correct=0\n",
        "  for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tloss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "  print(f\"Test loss :{tloss/len(test_dataset)}\")\n",
        "  print(f\"Test Accuracy :{correct/len(test_dataset)}\")\n",
        "  sparsity.append((1-0.2)**(i+1))\n",
        "  acc.append(correct/len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5073880262756347\n",
            "Training Accuracy :0.9547199606895447\n",
            "Validation loss :1.564076488494873\n",
            "Validation Accuracy :0.8967999815940857\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5058715196990966\n",
            "Training Accuracy :0.9560999870300293\n",
            "Validation loss :1.5638316165924073\n",
            "Validation Accuracy :0.897599995136261\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5054880042266845\n",
            "Training Accuracy :0.9563199877738953\n",
            "Validation loss :1.5637301959991454\n",
            "Validation Accuracy :0.8974999785423279\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5052196309661865\n",
            "Training Accuracy :0.956559956073761\n",
            "Validation loss :1.5633393642425537\n",
            "Validation Accuracy :0.8984999656677246\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5050400049591064\n",
            "Training Accuracy :0.9566599726676941\n",
            "Validation loss :1.5634446647644042\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5048895248794556\n",
            "Training Accuracy :0.9568399786949158\n",
            "Validation loss :1.5632573657989501\n",
            "Validation Accuracy :0.8981999754905701\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5047645994949341\n",
            "Training Accuracy :0.9569999575614929\n",
            "Validation loss :1.5638747993469237\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.504676237716675\n",
            "Training Accuracy :0.9571599960327148\n",
            "Validation loss :1.5637811813354492\n",
            "Validation Accuracy :0.8973999619483948\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5046029246902466\n",
            "Training Accuracy :0.9572399854660034\n",
            "Validation loss :1.5632335456848145\n",
            "Validation Accuracy :0.8982999920845032\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5044841555023194\n",
            "Training Accuracy :0.9573400020599365\n",
            "Validation loss :1.5631725254058837\n",
            "Validation Accuracy :0.8978999853134155\n",
            "Test loss :1.5677253883361817\n",
            "Test Accuracy :0.8934999704360962\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5056288425064086\n",
            "Training Accuracy :0.9567999839782715\n",
            "Validation loss :1.5638821865081787\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5049890349960326\n",
            "Training Accuracy :0.957319974899292\n",
            "Validation loss :1.5637472801208496\n",
            "Validation Accuracy :0.8967999815940857\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5047540311431884\n",
            "Training Accuracy :0.9574599862098694\n",
            "Validation loss :1.5639437259674072\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5045804595184327\n",
            "Training Accuracy :0.957539975643158\n",
            "Validation loss :1.563386012649536\n",
            "Validation Accuracy :0.8977999687194824\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5044585471343994\n",
            "Training Accuracy :0.9577199816703796\n",
            "Validation loss :1.5634677917480468\n",
            "Validation Accuracy :0.8973000049591064\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.504368715171814\n",
            "Training Accuracy :0.9577999711036682\n",
            "Validation loss :1.5632249755859375\n",
            "Validation Accuracy :0.8973999619483948\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.504297511253357\n",
            "Training Accuracy :0.9577199816703796\n",
            "Validation loss :1.5633738563537598\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.504198193321228\n",
            "Training Accuracy :0.9578799605369568\n",
            "Validation loss :1.5635834968566895\n",
            "Validation Accuracy :0.8973000049591064\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5041377346801759\n",
            "Training Accuracy :0.9579799771308899\n",
            "Validation loss :1.563318161392212\n",
            "Validation Accuracy :0.8973999619483948\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5040741220855713\n",
            "Training Accuracy :0.9580000042915344\n",
            "Validation loss :1.563369842147827\n",
            "Validation Accuracy :0.8973000049591064\n",
            "Test loss :1.568757378387451\n",
            "Test Accuracy :0.8912999629974365\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5085080574035645\n",
            "Training Accuracy :0.9546999931335449\n",
            "Validation loss :1.5642872081756591\n",
            "Validation Accuracy :0.8974999785423279\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5065817450714112\n",
            "Training Accuracy :0.9564599990844727\n",
            "Validation loss :1.5643641578674317\n",
            "Validation Accuracy :0.8974999785423279\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5059652376937867\n",
            "Training Accuracy :0.9570199847221375\n",
            "Validation loss :1.5645249195098876\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5055106174468995\n",
            "Training Accuracy :0.9575999975204468\n",
            "Validation loss :1.5644465091705322\n",
            "Validation Accuracy :0.8974999785423279\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.505227711791992\n",
            "Training Accuracy :0.9576799869537354\n",
            "Validation loss :1.5645180271148682\n",
            "Validation Accuracy :0.8966999650001526\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.505035311279297\n",
            "Training Accuracy :0.9578199982643127\n",
            "Validation loss :1.56430340423584\n",
            "Validation Accuracy :0.8973000049591064\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5048424090194703\n",
            "Training Accuracy :0.9579799771308899\n",
            "Validation loss :1.5640473377227784\n",
            "Validation Accuracy :0.8976999521255493\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5047115642547608\n",
            "Training Accuracy :0.9579599499702454\n",
            "Validation loss :1.5640196224212646\n",
            "Validation Accuracy :0.8977999687194824\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5046042398071289\n",
            "Training Accuracy :0.9581599831581116\n",
            "Validation loss :1.5638541618347168\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5044780724334716\n",
            "Training Accuracy :0.9581599831581116\n",
            "Validation loss :1.563714133453369\n",
            "Validation Accuracy :0.898099958896637\n",
            "Test loss :1.5695574653625488\n",
            "Test Accuracy :0.8913999795913696\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5140502513504028\n",
            "Training Accuracy :0.9494199752807617\n",
            "Validation loss :1.5666004487991334\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5101468914413452\n",
            "Training Accuracy :0.9536399841308594\n",
            "Validation loss :1.5667579280853272\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5088852368927002\n",
            "Training Accuracy :0.9549399614334106\n",
            "Validation loss :1.5665783084869385\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5080057763671875\n",
            "Training Accuracy :0.9556799530982971\n",
            "Validation loss :1.5658682216644286\n",
            "Validation Accuracy :0.8953999876976013\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.507456011199951\n",
            "Training Accuracy :0.9562000036239624\n",
            "Validation loss :1.5665416839599609\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.507057473564148\n",
            "Training Accuracy :0.9566199779510498\n",
            "Validation loss :1.5660024921417237\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5067578530120849\n",
            "Training Accuracy :0.9568199515342712\n",
            "Validation loss :1.5658454650878906\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5064216271209716\n",
            "Training Accuracy :0.9572599530220032\n",
            "Validation loss :1.5658135051727295\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.50618789352417\n",
            "Training Accuracy :0.9573400020599365\n",
            "Validation loss :1.5660139793395995\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.506005276184082\n",
            "Training Accuracy :0.9575799703598022\n",
            "Validation loss :1.5660702838897704\n",
            "Validation Accuracy :0.8944000005722046\n",
            "Test loss :1.569420436859131\n",
            "Test Accuracy :0.890999972820282\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5225429264450072\n",
            "Training Accuracy :0.9406999945640564\n",
            "Validation loss :1.5671720497131347\n",
            "Validation Accuracy :0.8935999870300293\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5156209337997437\n",
            "Training Accuracy :0.9481399655342102\n",
            "Validation loss :1.5666727844238282\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5136251446914673\n",
            "Training Accuracy :0.950279951095581\n",
            "Validation loss :1.5661611766815187\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.512295754470825\n",
            "Training Accuracy :0.9519199728965759\n",
            "Validation loss :1.566325226211548\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5114703311157227\n",
            "Training Accuracy :0.9530999660491943\n",
            "Validation loss :1.5660302551269532\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.510733629875183\n",
            "Training Accuracy :0.9535799622535706\n",
            "Validation loss :1.5665321060180664\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5102012657165527\n",
            "Training Accuracy :0.954259991645813\n",
            "Validation loss :1.566094916152954\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5098301500320435\n",
            "Training Accuracy :0.9546200037002563\n",
            "Validation loss :1.5661457920074462\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5093613411712647\n",
            "Training Accuracy :0.9551399946212769\n",
            "Validation loss :1.5658506446838378\n",
            "Validation Accuracy :0.8949999809265137\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5091044031524659\n",
            "Training Accuracy :0.9555799961090088\n",
            "Validation loss :1.566128165435791\n",
            "Validation Accuracy :0.8953999876976013\n",
            "Test loss :1.5704253791809082\n",
            "Test Accuracy :0.8912999629974365\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5342087269973754\n",
            "Training Accuracy :0.9291599988937378\n",
            "Validation loss :1.5703769313812257\n",
            "Validation Accuracy :0.8908999562263489\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.524242442741394\n",
            "Training Accuracy :0.9396999478340149\n",
            "Validation loss :1.5693311466217041\n",
            "Validation Accuracy :0.8921999931335449\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.521254959564209\n",
            "Training Accuracy :0.943120002746582\n",
            "Validation loss :1.5686470428466797\n",
            "Validation Accuracy :0.8920999765396118\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5192893770217895\n",
            "Training Accuracy :0.9453199505805969\n",
            "Validation loss :1.5679043462753295\n",
            "Validation Accuracy :0.8937999606132507\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5179381889724732\n",
            "Training Accuracy :0.9466599822044373\n",
            "Validation loss :1.5677839624404908\n",
            "Validation Accuracy :0.8937000036239624\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5168451237869263\n",
            "Training Accuracy :0.9477599859237671\n",
            "Validation loss :1.5673988775253296\n",
            "Validation Accuracy :0.8948999643325806\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5159872503662108\n",
            "Training Accuracy :0.9488599896430969\n",
            "Validation loss :1.5674754371643067\n",
            "Validation Accuracy :0.8941999673843384\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5152865689849853\n",
            "Training Accuracy :0.9497999548912048\n",
            "Validation loss :1.5671279825210571\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5147312339019776\n",
            "Training Accuracy :0.9501599669456482\n",
            "Validation loss :1.5671845705032348\n",
            "Validation Accuracy :0.8944999575614929\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.514222889022827\n",
            "Training Accuracy :0.9508799910545349\n",
            "Validation loss :1.5669395765304566\n",
            "Validation Accuracy :0.8949999809265137\n",
            "Test loss :1.5707795587539672\n",
            "Test Accuracy :0.8896999955177307\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5495714827346803\n",
            "Training Accuracy :0.9135400056838989\n",
            "Validation loss :1.5732629459381104\n",
            "Validation Accuracy :0.887499988079071\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5327154884338379\n",
            "Training Accuracy :0.9314000010490417\n",
            "Validation loss :1.5705306003570556\n",
            "Validation Accuracy :0.8901999592781067\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5282798797607422\n",
            "Training Accuracy :0.9365599751472473\n",
            "Validation loss :1.569196688079834\n",
            "Validation Accuracy :0.8919999599456787\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5258771350860596\n",
            "Training Accuracy :0.9386599659919739\n",
            "Validation loss :1.568933179283142\n",
            "Validation Accuracy :0.8932999968528748\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.524431704864502\n",
            "Training Accuracy :0.9402999877929688\n",
            "Validation loss :1.5687242458343507\n",
            "Validation Accuracy :0.8925999999046326\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5230900356292725\n",
            "Training Accuracy :0.9419999718666077\n",
            "Validation loss :1.568355825805664\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5220877326202393\n",
            "Training Accuracy :0.9431799650192261\n",
            "Validation loss :1.5684539611816406\n",
            "Validation Accuracy :0.8930000066757202\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.521250258140564\n",
            "Training Accuracy :0.9440599679946899\n",
            "Validation loss :1.5681623315811157\n",
            "Validation Accuracy :0.8934999704360962\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5205276012039184\n",
            "Training Accuracy :0.9450799822807312\n",
            "Validation loss :1.568351339149475\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.520010574874878\n",
            "Training Accuracy :0.9455599784851074\n",
            "Validation loss :1.567855492591858\n",
            "Validation Accuracy :0.8941999673843384\n",
            "Test loss :1.5728619266510009\n",
            "Test Accuracy :0.8878999948501587\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5682190840148926\n",
            "Training Accuracy :0.8951799869537354\n",
            "Validation loss :1.5787723512649536\n",
            "Validation Accuracy :0.8833999633789062\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.547580740814209\n",
            "Training Accuracy :0.9159799814224243\n",
            "Validation loss :1.5736885789871216\n",
            "Validation Accuracy :0.8876000046730042\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5414409859085083\n",
            "Training Accuracy :0.9224599599838257\n",
            "Validation loss :1.5712740184783935\n",
            "Validation Accuracy :0.8901999592781067\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5378682398605346\n",
            "Training Accuracy :0.9267199635505676\n",
            "Validation loss :1.570017350959778\n",
            "Validation Accuracy :0.8924999833106995\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5354341728973389\n",
            "Training Accuracy :0.9293799996376038\n",
            "Validation loss :1.5695435913085938\n",
            "Validation Accuracy :0.8924999833106995\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5336189968490601\n",
            "Training Accuracy :0.9312199950218201\n",
            "Validation loss :1.5688164333343506\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5321158503723145\n",
            "Training Accuracy :0.9330799579620361\n",
            "Validation loss :1.56862064704895\n",
            "Validation Accuracy :0.8923999667167664\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5308790996170043\n",
            "Training Accuracy :0.9345799684524536\n",
            "Validation loss :1.568307700920105\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.530011428756714\n",
            "Training Accuracy :0.9352799654006958\n",
            "Validation loss :1.5680855659484862\n",
            "Validation Accuracy :0.8932999968528748\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.529119002456665\n",
            "Training Accuracy :0.9362999796867371\n",
            "Validation loss :1.5679396890640258\n",
            "Validation Accuracy :0.8939999938011169\n",
            "Test loss :1.5750474061965942\n",
            "Test Accuracy :0.8866999745368958\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5939238793182373\n",
            "Training Accuracy :0.8698199987411499\n",
            "Validation loss :1.585929201889038\n",
            "Validation Accuracy :0.8763999938964844\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5578448229980468\n",
            "Training Accuracy :0.9062999486923218\n",
            "Validation loss :1.5787782510757447\n",
            "Validation Accuracy :0.8841999769210815\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.550743611946106\n",
            "Training Accuracy :0.9137199521064758\n",
            "Validation loss :1.5753068479537964\n",
            "Validation Accuracy :0.8866999745368958\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5468799820327759\n",
            "Training Accuracy :0.9177799820899963\n",
            "Validation loss :1.5733056337356568\n",
            "Validation Accuracy :0.8894000053405762\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5443744654083251\n",
            "Training Accuracy :0.9207199811935425\n",
            "Validation loss :1.5721235879898072\n",
            "Validation Accuracy :0.8896999955177307\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5422796306991577\n",
            "Training Accuracy :0.9226199984550476\n",
            "Validation loss :1.5717529275894164\n",
            "Validation Accuracy :0.8910999894142151\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.540991541671753\n",
            "Training Accuracy :0.9242799878120422\n",
            "Validation loss :1.5708344583511353\n",
            "Validation Accuracy :0.8919000029563904\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5397104105377197\n",
            "Training Accuracy :0.9251399636268616\n",
            "Validation loss :1.5699439407348632\n",
            "Validation Accuracy :0.8922999501228333\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5386682257843018\n",
            "Training Accuracy :0.9264199733734131\n",
            "Validation loss :1.5695532106399537\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5377581368255615\n",
            "Training Accuracy :0.9276999831199646\n",
            "Validation loss :1.569446522140503\n",
            "Validation Accuracy :0.8930000066757202\n",
            "Test loss :1.5741820514678955\n",
            "Test Accuracy :0.8880999684333801\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.612932165260315\n",
            "Training Accuracy :0.850339949131012\n",
            "Validation loss :1.5975718605041505\n",
            "Validation Accuracy :0.864799976348877\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5750000020217896\n",
            "Training Accuracy :0.8885200023651123\n",
            "Validation loss :1.5871731243133544\n",
            "Validation Accuracy :0.875499963760376\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.564491935043335\n",
            "Training Accuracy :0.9000399708747864\n",
            "Validation loss :1.5824429708480834\n",
            "Validation Accuracy :0.8795999884605408\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5590735010910035\n",
            "Training Accuracy :0.9057599902153015\n",
            "Validation loss :1.5793115718841553\n",
            "Validation Accuracy :0.8827999830245972\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5555922649002074\n",
            "Training Accuracy :0.9088799953460693\n",
            "Validation loss :1.5775189548492432\n",
            "Validation Accuracy :0.8844999670982361\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.55301124584198\n",
            "Training Accuracy :0.9112399816513062\n",
            "Validation loss :1.5763178031921388\n",
            "Validation Accuracy :0.8858000040054321\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.550921379585266\n",
            "Training Accuracy :0.9142199754714966\n",
            "Validation loss :1.5752072856903077\n",
            "Validation Accuracy :0.8869999647140503\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5493136149215698\n",
            "Training Accuracy :0.9157599806785583\n",
            "Validation loss :1.5743378911972046\n",
            "Validation Accuracy :0.887499988079071\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5480198665618896\n",
            "Training Accuracy :0.9173199534416199\n",
            "Validation loss :1.5738498735427857\n",
            "Validation Accuracy :0.8885999917984009\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5469856890106202\n",
            "Training Accuracy :0.9181599617004395\n",
            "Validation loss :1.5735607692718505\n",
            "Validation Accuracy :0.8888999819755554\n",
            "Test loss :1.5786053455352784\n",
            "Test Accuracy :0.883899986743927\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6143293611907958\n",
            "Training Accuracy :0.8503599762916565\n",
            "Validation loss :1.5971200387954712\n",
            "Validation Accuracy :0.8684999942779541\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5737246578216553\n",
            "Training Accuracy :0.8916199803352356\n",
            "Validation loss :1.5881209602355957\n",
            "Validation Accuracy :0.8761000037193298\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.566042672958374\n",
            "Training Accuracy :0.8992599844932556\n",
            "Validation loss :1.583688628578186\n",
            "Validation Accuracy :0.8798999786376953\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5619756813049317\n",
            "Training Accuracy :0.9034199714660645\n",
            "Validation loss :1.5813256633758546\n",
            "Validation Accuracy :0.882599949836731\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5592949532699585\n",
            "Training Accuracy :0.9059999585151672\n",
            "Validation loss :1.5798502435684205\n",
            "Validation Accuracy :0.8841999769210815\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5575008150482177\n",
            "Training Accuracy :0.9082599878311157\n",
            "Validation loss :1.578481789970398\n",
            "Validation Accuracy :0.8859999775886536\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5562154852294923\n",
            "Training Accuracy :0.9092599749565125\n",
            "Validation loss :1.5778591835021973\n",
            "Validation Accuracy :0.8865000009536743\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.555031927986145\n",
            "Training Accuracy :0.9104999899864197\n",
            "Validation loss :1.5771115060806273\n",
            "Validation Accuracy :0.8860999941825867\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5540534885406494\n",
            "Training Accuracy :0.9117599725723267\n",
            "Validation loss :1.576627371406555\n",
            "Validation Accuracy :0.8877999782562256\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5533497109985352\n",
            "Training Accuracy :0.912839949131012\n",
            "Validation loss :1.5758232807159425\n",
            "Validation Accuracy :0.887499988079071\n",
            "Test loss :1.5801003759384156\n",
            "Test Accuracy :0.8847000002861023\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.628469246520996\n",
            "Training Accuracy :0.837179958820343\n",
            "Validation loss :1.6077309564590454\n",
            "Validation Accuracy :0.857699990272522\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5914882332992553\n",
            "Training Accuracy :0.8745599985122681\n",
            "Validation loss :1.5965281322479248\n",
            "Validation Accuracy :0.8668999671936035\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5816742311096192\n",
            "Training Accuracy :0.8845199942588806\n",
            "Validation loss :1.590144246482849\n",
            "Validation Accuracy :0.8752999901771545\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5757329793167114\n",
            "Training Accuracy :0.8903599977493286\n",
            "Validation loss :1.5869159248352052\n",
            "Validation Accuracy :0.8787999749183655\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5713461687088013\n",
            "Training Accuracy :0.8954799771308899\n",
            "Validation loss :1.5848101797103882\n",
            "Validation Accuracy :0.8806999921798706\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5685659865951538\n",
            "Training Accuracy :0.8981999754905701\n",
            "Validation loss :1.583013303375244\n",
            "Validation Accuracy :0.8830999732017517\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.566396358833313\n",
            "Training Accuracy :0.9004799723625183\n",
            "Validation loss :1.582067486190796\n",
            "Validation Accuracy :0.8833999633789062\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.564881537590027\n",
            "Training Accuracy :0.9021999835968018\n",
            "Validation loss :1.5814251876831054\n",
            "Validation Accuracy :0.8840999603271484\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5636788544845581\n",
            "Training Accuracy :0.9033799767494202\n",
            "Validation loss :1.5808124225616456\n",
            "Validation Accuracy :0.8835999965667725\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5625039262008666\n",
            "Training Accuracy :0.9045999646186829\n",
            "Validation loss :1.580095733642578\n",
            "Validation Accuracy :0.8848999738693237\n",
            "Test loss :1.585764246559143\n",
            "Test Accuracy :0.8789999485015869\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6261440629196167\n",
            "Training Accuracy :0.8427199721336365\n",
            "Validation loss :1.607771072769165\n",
            "Validation Accuracy :0.8592999577522278\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5908497145843505\n",
            "Training Accuracy :0.8777999877929688\n",
            "Validation loss :1.5995830032348632\n",
            "Validation Accuracy :0.8654999732971191\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5850126958847046\n",
            "Training Accuracy :0.8830599784851074\n",
            "Validation loss :1.5955826581954955\n",
            "Validation Accuracy :0.8700000047683716\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5817408738327026\n",
            "Training Accuracy :0.886199951171875\n",
            "Validation loss :1.5927833711624146\n",
            "Validation Accuracy :0.873699963092804\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5791284050750733\n",
            "Training Accuracy :0.8885599970817566\n",
            "Validation loss :1.5903202459335326\n",
            "Validation Accuracy :0.875\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5768537384414674\n",
            "Training Accuracy :0.8905400037765503\n",
            "Validation loss :1.5887294185638428\n",
            "Validation Accuracy :0.8774999976158142\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5747341208267212\n",
            "Training Accuracy :0.8927800059318542\n",
            "Validation loss :1.5872117126464844\n",
            "Validation Accuracy :0.8788999915122986\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.573073264465332\n",
            "Training Accuracy :0.8947199583053589\n",
            "Validation loss :1.585917469406128\n",
            "Validation Accuracy :0.8810999989509583\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5717103871536255\n",
            "Training Accuracy :0.8962000012397766\n",
            "Validation loss :1.5849749988555908\n",
            "Validation Accuracy :0.8807999491691589\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5705902835845946\n",
            "Training Accuracy :0.8979599475860596\n",
            "Validation loss :1.584303169631958\n",
            "Validation Accuracy :0.8807999491691589\n",
            "Test loss :1.5909916271209716\n",
            "Test Accuracy :0.876800000667572\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6312968026733399\n",
            "Training Accuracy :0.840939998626709\n",
            "Validation loss :1.6150388843536376\n",
            "Validation Accuracy :0.8538999557495117\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5999120196151733\n",
            "Training Accuracy :0.8712799549102783\n",
            "Validation loss :1.6062651987075807\n",
            "Validation Accuracy :0.8624999523162842\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5938115082550048\n",
            "Training Accuracy :0.8764599561691284\n",
            "Validation loss :1.6017621824264527\n",
            "Validation Accuracy :0.8675999641418457\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5900494329452515\n",
            "Training Accuracy :0.879859983921051\n",
            "Validation loss :1.5985223218917846\n",
            "Validation Accuracy :0.8718999624252319\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5872472816085816\n",
            "Training Accuracy :0.8829599618911743\n",
            "Validation loss :1.5961156120300293\n",
            "Validation Accuracy :0.871999979019165\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5850623835754394\n",
            "Training Accuracy :0.8853399753570557\n",
            "Validation loss :1.5949568252563477\n",
            "Validation Accuracy :0.8730999827384949\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5834208478164673\n",
            "Training Accuracy :0.8860799670219421\n",
            "Validation loss :1.5932775279998779\n",
            "Validation Accuracy :0.8747999668121338\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5819656287002564\n",
            "Training Accuracy :0.8878399729728699\n",
            "Validation loss :1.5923621181488037\n",
            "Validation Accuracy :0.8738999962806702\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.580860869064331\n",
            "Training Accuracy :0.8884599804878235\n",
            "Validation loss :1.591261174583435\n",
            "Validation Accuracy :0.8750999569892883\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5800776866912842\n",
            "Training Accuracy :0.8898400068283081\n",
            "Validation loss :1.5906193809509277\n",
            "Validation Accuracy :0.8762999773025513\n",
            "Test loss :1.5979983863830567\n",
            "Test Accuracy :0.8698999881744385\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6380412355804443\n",
            "Training Accuracy :0.8346399664878845\n",
            "Validation loss :1.6180748582839966\n",
            "Validation Accuracy :0.8535999655723572\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6060752078247071\n",
            "Training Accuracy :0.8653199672698975\n",
            "Validation loss :1.6105317987442016\n",
            "Validation Accuracy :0.8589999675750732\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6004563201904296\n",
            "Training Accuracy :0.8695600032806396\n",
            "Validation loss :1.6066629760742188\n",
            "Validation Accuracy :0.8623999953269958\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5970068822479249\n",
            "Training Accuracy :0.8725799918174744\n",
            "Validation loss :1.6040386302947998\n",
            "Validation Accuracy :0.8644999861717224\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5945430229568482\n",
            "Training Accuracy :0.8752599954605103\n",
            "Validation loss :1.6021471927642823\n",
            "Validation Accuracy :0.8661999702453613\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.592532818374634\n",
            "Training Accuracy :0.8774999976158142\n",
            "Validation loss :1.6004534353256226\n",
            "Validation Accuracy :0.8679999709129333\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5909958980941772\n",
            "Training Accuracy :0.8791799545288086\n",
            "Validation loss :1.5992019636154176\n",
            "Validation Accuracy :0.8687999844551086\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5897118371200563\n",
            "Training Accuracy :0.8798399567604065\n",
            "Validation loss :1.5983125095367432\n",
            "Validation Accuracy :0.8690999746322632\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5886445450592042\n",
            "Training Accuracy :0.8809599876403809\n",
            "Validation loss :1.597141356086731\n",
            "Validation Accuracy :0.8709999918937683\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5876317016220092\n",
            "Training Accuracy :0.8818599581718445\n",
            "Validation loss :1.596418897628784\n",
            "Validation Accuracy :0.871399998664856\n",
            "Test loss :1.602837463760376\n",
            "Test Accuracy :0.8646000027656555\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.648392691307068\n",
            "Training Accuracy :0.8268799781799316\n",
            "Validation loss :1.6353982542037964\n",
            "Validation Accuracy :0.840399980545044\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6265612417984008\n",
            "Training Accuracy :0.8476199507713318\n",
            "Validation loss :1.6260681825637817\n",
            "Validation Accuracy :0.8479999899864197\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.619556919555664\n",
            "Training Accuracy :0.8532399535179138\n",
            "Validation loss :1.6204537616729737\n",
            "Validation Accuracy :0.8534999489784241\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.614997969932556\n",
            "Training Accuracy :0.8565199971199036\n",
            "Validation loss :1.6165975887298585\n",
            "Validation Accuracy :0.8567000031471252\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6115057238388062\n",
            "Training Accuracy :0.8595799803733826\n",
            "Validation loss :1.6135161863327026\n",
            "Validation Accuracy :0.858299970626831\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6087778954315186\n",
            "Training Accuracy :0.8619399666786194\n",
            "Validation loss :1.6106488344192504\n",
            "Validation Accuracy :0.8604999780654907\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.606487511405945\n",
            "Training Accuracy :0.8643800020217896\n",
            "Validation loss :1.608570008087158\n",
            "Validation Accuracy :0.863099992275238\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.604541880531311\n",
            "Training Accuracy :0.8658599853515625\n",
            "Validation loss :1.6069010913848878\n",
            "Validation Accuracy :0.8644999861717224\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6028688500213624\n",
            "Training Accuracy :0.8677999973297119\n",
            "Validation loss :1.6054909852981567\n",
            "Validation Accuracy :0.8649999499320984\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6014053204727172\n",
            "Training Accuracy :0.8691799640655518\n",
            "Validation loss :1.6041351989746093\n",
            "Validation Accuracy :0.8671999573707581\n",
            "Test loss :1.6131632789611816\n",
            "Test Accuracy :0.8560999631881714\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6567810440826416\n",
            "Training Accuracy :0.8270399570465088\n",
            "Validation loss :1.6367884845733642\n",
            "Validation Accuracy :0.8412999510765076\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6312691537475585\n",
            "Training Accuracy :0.8476199507713318\n",
            "Validation loss :1.628633350944519\n",
            "Validation Accuracy :0.8479999899864197\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.625090707435608\n",
            "Training Accuracy :0.8512199521064758\n",
            "Validation loss :1.6241937294006348\n",
            "Validation Accuracy :0.8507999777793884\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6212091764068604\n",
            "Training Accuracy :0.8537999987602234\n",
            "Validation loss :1.620932751083374\n",
            "Validation Accuracy :0.8542999625205994\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6183365445709228\n",
            "Training Accuracy :0.8556399941444397\n",
            "Validation loss :1.6187999187469482\n",
            "Validation Accuracy :0.8551999926567078\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6160660787200927\n",
            "Training Accuracy :0.8579399585723877\n",
            "Validation loss :1.6171343212127685\n",
            "Validation Accuracy :0.856499969959259\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6141761435317994\n",
            "Training Accuracy :0.8581399917602539\n",
            "Validation loss :1.615008016395569\n",
            "Validation Accuracy :0.8574999570846558\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.612667763710022\n",
            "Training Accuracy :0.8595199584960938\n",
            "Validation loss :1.613890493774414\n",
            "Validation Accuracy :0.8589999675750732\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6113134439468384\n",
            "Training Accuracy :0.8611399531364441\n",
            "Validation loss :1.6127365552902222\n",
            "Validation Accuracy :0.8610999584197998\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6100191425323487\n",
            "Training Accuracy :0.8619999885559082\n",
            "Validation loss :1.6116282867431642\n",
            "Validation Accuracy :0.85999995470047\n",
            "Test loss :1.6205137260437013\n",
            "Test Accuracy :0.8486999869346619\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6791603357696534\n",
            "Training Accuracy :0.8011999726295471\n",
            "Validation loss :1.6596937984466553\n",
            "Validation Accuracy :0.8185999989509583\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6468545431518555\n",
            "Training Accuracy :0.8312399983406067\n",
            "Validation loss :1.6468447135925293\n",
            "Validation Accuracy :0.830299973487854\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6387946349716187\n",
            "Training Accuracy :0.8385599851608276\n",
            "Validation loss :1.6406920621871948\n",
            "Validation Accuracy :0.8359000086784363\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6341051503753663\n",
            "Training Accuracy :0.8419199585914612\n",
            "Validation loss :1.6361413764953614\n",
            "Validation Accuracy :0.8380999565124512\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6306666391372682\n",
            "Training Accuracy :0.8452000021934509\n",
            "Validation loss :1.6328125352859497\n",
            "Validation Accuracy :0.8412999510765076\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6280840336990356\n",
            "Training Accuracy :0.8469199538230896\n",
            "Validation loss :1.6305853912353516\n",
            "Validation Accuracy :0.8432999849319458\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6261251410675048\n",
            "Training Accuracy :0.8479599952697754\n",
            "Validation loss :1.6283982877731322\n",
            "Validation Accuracy :0.8456999659538269\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6242618375015259\n",
            "Training Accuracy :0.8495399951934814\n",
            "Validation loss :1.626884081840515\n",
            "Validation Accuracy :0.8449999690055847\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6226896966934203\n",
            "Training Accuracy :0.8510800004005432\n",
            "Validation loss :1.6249517314910888\n",
            "Validation Accuracy :0.847599983215332\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6213130220794678\n",
            "Training Accuracy :0.8524399995803833\n",
            "Validation loss :1.623459822845459\n",
            "Validation Accuracy :0.8489999771118164\n",
            "Test loss :1.6332888544082642\n",
            "Test Accuracy :0.8399999737739563\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6986338883209229\n",
            "Training Accuracy :0.7902799844741821\n",
            "Validation loss :1.6600580184936524\n",
            "Validation Accuracy :0.8258000016212463\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6536057625961305\n",
            "Training Accuracy :0.8296200037002563\n",
            "Validation loss :1.6483831630706787\n",
            "Validation Accuracy :0.8337000012397766\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6449833615875245\n",
            "Training Accuracy :0.8359799981117249\n",
            "Validation loss :1.642905592918396\n",
            "Validation Accuracy :0.8366999626159668\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.64025816822052\n",
            "Training Accuracy :0.8382799625396729\n",
            "Validation loss :1.639131032562256\n",
            "Validation Accuracy :0.8391000032424927\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.636858447265625\n",
            "Training Accuracy :0.8405399918556213\n",
            "Validation loss :1.6363873546600343\n",
            "Validation Accuracy :0.8399999737739563\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6343374810409546\n",
            "Training Accuracy :0.8420000076293945\n",
            "Validation loss :1.6343513828277587\n",
            "Validation Accuracy :0.8420999646186829\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6323645963287354\n",
            "Training Accuracy :0.8428399562835693\n",
            "Validation loss :1.6333717136383057\n",
            "Validation Accuracy :0.8429999947547913\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6308749475479125\n",
            "Training Accuracy :0.8438999652862549\n",
            "Validation loss :1.6314349950790406\n",
            "Validation Accuracy :0.843999981880188\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.629423118247986\n",
            "Training Accuracy :0.8447999954223633\n",
            "Validation loss :1.6302969232559203\n",
            "Validation Accuracy :0.8435999751091003\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.628273218612671\n",
            "Training Accuracy :0.8457199931144714\n",
            "Validation loss :1.6296259733200074\n",
            "Validation Accuracy :0.8446999788284302\n",
            "Test loss :1.6396197019577026\n",
            "Test Accuracy :0.8341999650001526\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6699085259246826\n",
            "Training Accuracy :0.818619966506958\n",
            "Validation loss :1.657019563293457\n",
            "Validation Accuracy :0.8274999856948853\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6528946535873412\n",
            "Training Accuracy :0.8308999538421631\n",
            "Validation loss :1.6502661615371703\n",
            "Validation Accuracy :0.8315999507904053\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6477643773269652\n",
            "Training Accuracy :0.8327399492263794\n",
            "Validation loss :1.6458214372634887\n",
            "Validation Accuracy :0.8331999778747559\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6444144784545898\n",
            "Training Accuracy :0.8349599838256836\n",
            "Validation loss :1.643875731086731\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6421049143218993\n",
            "Training Accuracy :0.8362999558448792\n",
            "Validation loss :1.6415231538772583\n",
            "Validation Accuracy :0.8346999883651733\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6403511930465697\n",
            "Training Accuracy :0.8364399671554565\n",
            "Validation loss :1.6399216442108153\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6388892739868164\n",
            "Training Accuracy :0.8372600078582764\n",
            "Validation loss :1.6386552305221558\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6376785829925538\n",
            "Training Accuracy :0.8383399844169617\n",
            "Validation loss :1.6376308660507202\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6366573935699462\n",
            "Training Accuracy :0.8387399911880493\n",
            "Validation loss :1.6365756046295166\n",
            "Validation Accuracy :0.8384999632835388\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6356329592895509\n",
            "Training Accuracy :0.8397799730300903\n",
            "Validation loss :1.6358760803222656\n",
            "Validation Accuracy :0.8374999761581421\n",
            "Test loss :1.645497029876709\n",
            "Test Accuracy :0.8290999531745911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "WOzjUhKd2KLZ",
        "outputId": "e4f85e26-2c78-42e8-b782-1aecb2bc8a9a"
      },
      "source": [
        "#plot of sparsity vs accuracy\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(0,1)\n",
        "plt.plot(sparsity,acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd6b2091a90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "USP_OyWnCorO",
        "outputId": "ca18cd3f-ac9a-44e0-8b47-2f673e823cb7"
      },
      "source": [
        "#comparing sparsity vs accuracy with and without retraining\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "\n",
        "\n",
        "plt.plot(sparsity,acc)\n",
        "plt.plot(sparsity_wr,acc_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd642cdd110>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrUz25BNC5w8",
        "outputId": "ea27b888-5da5-4149-fb17-89de3051d5bc"
      },
      "source": [
        "sparsity_wr,acc_wr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.8,\n",
              "  0.6400000000000001,\n",
              "  0.5120000000000001,\n",
              "  0.4096000000000001,\n",
              "  0.3276800000000001,\n",
              "  0.2621440000000001,\n",
              "  0.20971520000000007,\n",
              "  0.1677721600000001,\n",
              "  0.13421772800000006,\n",
              "  0.10737418240000006,\n",
              "  0.08589934592000005,\n",
              "  0.06871947673600004,\n",
              "  0.054975581388800036,\n",
              "  0.043980465111040035,\n",
              "  0.03518437208883203,\n",
              "  0.028147497671065624,\n",
              "  0.022517998136852502,\n",
              "  0.018014398509482003,\n",
              "  0.014411518807585602,\n",
              "  0.011529215046068483],\n",
              " [0.8896999955177307,\n",
              "  tensor(0.8912, device='cuda:0'),\n",
              "  tensor(0.8881, device='cuda:0'),\n",
              "  tensor(0.8828, device='cuda:0'),\n",
              "  tensor(0.8779, device='cuda:0'),\n",
              "  tensor(0.8714, device='cuda:0'),\n",
              "  tensor(0.8516, device='cuda:0'),\n",
              "  tensor(0.8374, device='cuda:0'),\n",
              "  tensor(0.7979, device='cuda:0'),\n",
              "  tensor(0.7030, device='cuda:0'),\n",
              "  tensor(0.6179, device='cuda:0'),\n",
              "  tensor(0.5089, device='cuda:0'),\n",
              "  tensor(0.4159, device='cuda:0'),\n",
              "  tensor(0.2838, device='cuda:0'),\n",
              "  tensor(0.1676, device='cuda:0'),\n",
              "  tensor(0.1623, device='cuda:0'),\n",
              "  tensor(0.1220, device='cuda:0'),\n",
              "  tensor(0.1371, device='cuda:0'),\n",
              "  tensor(0.1747, device='cuda:0'),\n",
              "  tensor(0.1421, device='cuda:0'),\n",
              "  tensor(0.1118, device='cuda:0')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Xj5Nu626vQ",
        "outputId": "2849cd39-843a-4bf3-afc9-61a10a6789f4"
      },
      "source": [
        "sparsity,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.8,\n",
              "  0.6400000000000001,\n",
              "  0.5120000000000001,\n",
              "  0.4096000000000001,\n",
              "  0.3276800000000001,\n",
              "  0.2621440000000001,\n",
              "  0.20971520000000007,\n",
              "  0.1677721600000001,\n",
              "  0.13421772800000006,\n",
              "  0.10737418240000006,\n",
              "  0.08589934592000005,\n",
              "  0.06871947673600004,\n",
              "  0.054975581388800036,\n",
              "  0.043980465111040035,\n",
              "  0.03518437208883203,\n",
              "  0.028147497671065624,\n",
              "  0.022517998136852502,\n",
              "  0.018014398509482003,\n",
              "  0.014411518807585602,\n",
              "  0.011529215046068483],\n",
              " [0.8896999955177307,\n",
              "  tensor(0.8935, device='cuda:0'),\n",
              "  tensor(0.8913, device='cuda:0'),\n",
              "  tensor(0.8914, device='cuda:0'),\n",
              "  tensor(0.8910, device='cuda:0'),\n",
              "  tensor(0.8913, device='cuda:0'),\n",
              "  tensor(0.8897, device='cuda:0'),\n",
              "  tensor(0.8879, device='cuda:0'),\n",
              "  tensor(0.8867, device='cuda:0'),\n",
              "  tensor(0.8881, device='cuda:0'),\n",
              "  tensor(0.8839, device='cuda:0'),\n",
              "  tensor(0.8847, device='cuda:0'),\n",
              "  tensor(0.8790, device='cuda:0'),\n",
              "  tensor(0.8768, device='cuda:0'),\n",
              "  tensor(0.8699, device='cuda:0'),\n",
              "  tensor(0.8646, device='cuda:0'),\n",
              "  tensor(0.8561, device='cuda:0'),\n",
              "  tensor(0.8487, device='cuda:0'),\n",
              "  tensor(0.8400, device='cuda:0'),\n",
              "  tensor(0.8342, device='cuda:0'),\n",
              "  tensor(0.8291, device='cuda:0')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4zNaCjLnf_I"
      },
      "source": [
        "#### L1 norm based structured pruning without retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE9hV7VcnmEO"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/model1_fas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khrIc11w-ffH",
        "outputId": "ab10ff72-5c26-44d9-f00e-2d609eb4766f"
      },
      "source": [
        "acc_wr=[0.8896999955177307]\n",
        "sparsity_wr=[1]\n",
        "for i in range(20):\n",
        "  #prune.ln_structured(model.conv1,'weight',amount=0.2,dim=0,n=1)\n",
        "  prune.ln_structured(model.conv2,'weight',amount=0.2,dim=0,n=1)\n",
        "  prune.ln_structured(model.conv3,'weight',amount=0.2,dim=0,n=1)\n",
        "  prune.ln_structured(model.fc1,'weight',amount=0.2,dim=0,n=1)\n",
        "  #prune.ln_structured(model.fc2,'weight',amount=0.2,dim=0,n=1)\n",
        "  #computing no of removed parameters\n",
        "  no_removed=0\n",
        "  for i in range(model.conv2.state_dict()['weight_mask'].shape[0]):\n",
        "    if model.conv2.state_dict()['weight_mask'][i][0][0][0]==0:\n",
        "      no_removed+=torch.numel(model.conv2.state_dict()['weight_mask'][i])\n",
        "  for i in range(model.conv3.state_dict()['weight_mask'].shape[0]):\n",
        "    if model.conv3.state_dict()['weight_mask'][i][0][0][0]==0:\n",
        "      no_removed+=torch.numel(model.conv3.state_dict()['weight_mask'][i])\n",
        "  for i in range(model.fc1.state_dict()['weight_mask'].shape[0]):\n",
        "    if model.fc1.state_dict()['weight_mask'][i][0]==0:\n",
        "      no_removed+=torch.numel(model.fc1.state_dict()['weight_mask'][i])\n",
        "  \n",
        "  print(f\"Sparsity= : {1-(no_removed/44164)}\")\n",
        "  \n",
        "  model.eval()\n",
        "  tloss=0\n",
        "  correct=0\n",
        "  for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tloss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "  print(f\"Test loss :{tloss/len(test_dataset)}\")\n",
        "  print(f\"Test Accuracy :{correct/len(test_dataset)}\")\n",
        "  sparsity_wr.append(1-(no_removed/44164))\n",
        "  acc_wr.append(correct/len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity= : 0.8072185490444705\n",
            "Test loss :1.675094066810608\n",
            "Test Accuracy :0.7907999753952026\n",
            "Sparsity= : 0.651571415632642\n",
            "Test loss :1.9541144653320313\n",
            "Test Accuracy :0.5059999823570251\n",
            "Sparsity= : 0.5279413096639798\n",
            "Test loss :2.14024631729126\n",
            "Test Accuracy :0.30809998512268066\n",
            "Sparsity= : 0.4298523684448873\n",
            "Test loss :2.2183764430999755\n",
            "Test Accuracy :0.22909998893737793\n",
            "Sparsity= : 0.34947015668870574\n",
            "Test loss :2.2493384590148926\n",
            "Test Accuracy :0.1973000019788742\n",
            "Sparsity= : 0.28611538809890413\n",
            "Test loss :2.3262636711120606\n",
            "Test Accuracy :0.12409999966621399\n",
            "Sparsity= : 0.23707091748935782\n",
            "Test loss :2.349740808105469\n",
            "Test Accuracy :0.10300000011920929\n",
            "Sparsity= : 0.19382302327687706\n",
            "Test loss :2.3464868816375732\n",
            "Test Accuracy :0.09269999712705612\n",
            "Sparsity= : 0.16248528213024183\n",
            "Test loss :2.3392502464294433\n",
            "Test Accuracy :0.09839999675750732\n",
            "Sparsity= : 0.13966126256679645\n",
            "Test loss :2.331182717514038\n",
            "Test Accuracy :0.09129999577999115\n",
            "Sparsity= : 0.11683724300335119\n",
            "Test loss :2.3264488872528077\n",
            "Test Accuracy :0.09629999846220016\n",
            "Sparsity= : 0.10252694502309578\n",
            "Test loss :2.3239041385650636\n",
            "Test Accuracy :0.09569999575614929\n",
            "Sparsity= : 0.08821664704284027\n",
            "Test loss :2.3301336433410644\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.07970292545965041\n",
            "Test loss :2.330270046234131\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.07118920387646044\n",
            "Test loss :2.327572077178955\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.06267548229327058\n",
            "Test loss :2.3271649559020995\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.056878905896205034\n",
            "Test loss :2.327148762893677\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.0510823294991396\n",
            "Test loss :2.3269643013000487\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.0510823294991396\n",
            "Test loss :2.3269643013000487\n",
            "Test Accuracy :0.09999999403953552\n",
            "Sparsity= : 0.0510823294991396\n",
            "Test loss :2.3269643013000487\n",
            "Test Accuracy :0.09999999403953552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "Ry4tyEvO_eLX",
        "outputId": "b0ea8aa9-9e35-4adb-9df2-a48b894e0d16"
      },
      "source": [
        "#plotting sparsity vs accuracy\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(0,1)\n",
        "plt.plot(sparsity_wr,acc_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5e3411d950>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZj-NdFmnw-B"
      },
      "source": [
        "#### L1 norm based structured pruning with retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zIQAGEInu5X"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/model1_fas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnB25wXR_i8B",
        "outputId": "9cf491bf-7254-4f10-b4c9-eb3827b9171d"
      },
      "source": [
        "acc=[0.8896999955177307]\n",
        "sparsity=[1]\n",
        "for i in range(20):\n",
        "  #prune.ln_structured(model.conv1,'weight',amount=0.2,dim=0,n=1)\n",
        "  prune.ln_structured(model.conv2,'weight',amount=0.2,dim=0,n=1)\n",
        "  prune.ln_structured(model.conv3,'weight',amount=0.2,dim=0,n=1)\n",
        "  prune.ln_structured(model.fc1,'weight',amount=0.2,dim=0,n=1)\n",
        "  #prune.ln_structured(model.fc2,'weight',amount=0.2,dim=0,n=1)\n",
        "  no_removed=0\n",
        "  for i in range(model.conv2.state_dict()['weight_mask'].shape[0]):\n",
        "    if model.conv2.state_dict()['weight_mask'][i][0][0][0]==0:\n",
        "      no_removed+=torch.numel(model.conv2.state_dict()['weight_mask'][i])\n",
        "  for i in range(model.conv3.state_dict()['weight_mask'].shape[0]):\n",
        "    if model.conv3.state_dict()['weight_mask'][i][0][0][0]==0:\n",
        "      no_removed+=torch.numel(model.conv3.state_dict()['weight_mask'][i])\n",
        "  for i in range(model.fc1.state_dict()['weight_mask'].shape[0]):\n",
        "    if model.fc1.state_dict()['weight_mask'][i][0]==0:\n",
        "      no_removed+=torch.numel(model.fc1.state_dict()['weight_mask'][i])\n",
        "  \n",
        "  print(f\"Sparsity= : {1-(no_removed/44164)}\")\n",
        "  model.conv2.state_dict()['weight_mask']\n",
        "  n_epochs=12\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  train_accuracy=[]\n",
        "  val_accuracy=[]\n",
        "  learning_rate = 0.01\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "  model.train()\n",
        "  for epoch in range(n_epochs):\n",
        "    tr_loss=0\n",
        "    vl_loss=0\n",
        "    print(f\"-----------EPOCH {epoch} ------------------ \")\n",
        "    correct=0\n",
        "    for images, labels in train_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      train = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(train)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tr_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    train_loss.append(tr_loss/len(train_dataset))\n",
        "    train_accuracy.append(correct/len(train_dataset))\n",
        "    print(f\"Training loss :{tr_loss/len(train_dataset)}\")\n",
        "    print(f\"Training Accuracy :{correct/len(train_dataset)}\")\n",
        "    correct=0\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      vl_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "    val_loss.append(vl_loss/len(val_dataset))\n",
        "    val_accuracy.append(correct/len(val_dataset))\n",
        "    print(f\"Validation loss :{vl_loss/len(val_dataset)}\")\n",
        "    print(f\"Validation Accuracy :{correct/len(val_dataset)}\")\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  tloss=0\n",
        "  correct=0\n",
        "  for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tloss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "  print(f\"Test loss :{tloss/len(test_dataset)}\")\n",
        "  print(f\"Test Accuracy :{correct/len(test_dataset)}\")\n",
        "  sparsity.append(1-(no_removed/44164))\n",
        "  acc.append(correct/len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity= : 0.8072185490444705\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.5638346886825563\n",
            "Training Accuracy :0.9016599655151367\n",
            "Validation loss :1.5820186803817748\n",
            "Validation Accuracy :0.8810999989509583\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5396437678909303\n",
            "Training Accuracy :0.9241799712181091\n",
            "Validation loss :1.5754200410842896\n",
            "Validation Accuracy :0.8869999647140503\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5325206251907348\n",
            "Training Accuracy :0.9318199753761292\n",
            "Validation loss :1.572770984840393\n",
            "Validation Accuracy :0.8894999623298645\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5282317353439332\n",
            "Training Accuracy :0.9358599781990051\n",
            "Validation loss :1.5713110046386718\n",
            "Validation Accuracy :0.8902999758720398\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5255624327468873\n",
            "Training Accuracy :0.9386799931526184\n",
            "Validation loss :1.5703036165237427\n",
            "Validation Accuracy :0.8912000060081482\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5235686484527589\n",
            "Training Accuracy :0.9406599998474121\n",
            "Validation loss :1.5698508037567138\n",
            "Validation Accuracy :0.8919000029563904\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5222737937164306\n",
            "Training Accuracy :0.9417999982833862\n",
            "Validation loss :1.5690262218475342\n",
            "Validation Accuracy :0.8926999568939209\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5207242944717407\n",
            "Training Accuracy :0.9434999823570251\n",
            "Validation loss :1.5689023107528686\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5195606212615966\n",
            "Training Accuracy :0.9447799921035767\n",
            "Validation loss :1.568469701576233\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5186909253692626\n",
            "Training Accuracy :0.9456999897956848\n",
            "Validation loss :1.5685451694488526\n",
            "Validation Accuracy :0.8937000036239624\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5176868523406983\n",
            "Training Accuracy :0.9468399882316589\n",
            "Validation loss :1.5686334966659545\n",
            "Validation Accuracy :0.892799973487854\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5170098139190673\n",
            "Training Accuracy :0.9473999738693237\n",
            "Validation loss :1.568691046142578\n",
            "Validation Accuracy :0.8934999704360962\n",
            "Test loss :1.5756651811599731\n",
            "Test Accuracy :0.8855999708175659\n",
            "Sparsity= : 0.651571415632642\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6074111920547485\n",
            "Training Accuracy :0.8593800067901611\n",
            "Validation loss :1.597685111808777\n",
            "Validation Accuracy :0.8676999807357788\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5665383343505859\n",
            "Training Accuracy :0.8985599875450134\n",
            "Validation loss :1.589258819770813\n",
            "Validation Accuracy :0.8733999729156494\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5579953404998779\n",
            "Training Accuracy :0.9067599773406982\n",
            "Validation loss :1.5856115190505982\n",
            "Validation Accuracy :0.8775999546051025\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.552994591255188\n",
            "Training Accuracy :0.9120799899101257\n",
            "Validation loss :1.5836740901947022\n",
            "Validation Accuracy :0.8791999816894531\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5494859477996825\n",
            "Training Accuracy :0.9155199527740479\n",
            "Validation loss :1.582042557144165\n",
            "Validation Accuracy :0.87909996509552\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5468295595550536\n",
            "Training Accuracy :0.9182800054550171\n",
            "Validation loss :1.581476505279541\n",
            "Validation Accuracy :0.8817999958992004\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5445679295349122\n",
            "Training Accuracy :0.9206799864768982\n",
            "Validation loss :1.5796587200164796\n",
            "Validation Accuracy :0.8827999830245972\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.542807063369751\n",
            "Training Accuracy :0.9222599864006042\n",
            "Validation loss :1.5793689178466797\n",
            "Validation Accuracy :0.8826999664306641\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5411111444473267\n",
            "Training Accuracy :0.9245599508285522\n",
            "Validation loss :1.5785607921600342\n",
            "Validation Accuracy :0.8847000002861023\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5397539531326294\n",
            "Training Accuracy :0.9265599846839905\n",
            "Validation loss :1.5777431522369385\n",
            "Validation Accuracy :0.885699987411499\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5386566032409668\n",
            "Training Accuracy :0.9268999695777893\n",
            "Validation loss :1.577467395210266\n",
            "Validation Accuracy :0.8852999806404114\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5374263288116454\n",
            "Training Accuracy :0.9286800026893616\n",
            "Validation loss :1.5773850185394287\n",
            "Validation Accuracy :0.8855999708175659\n",
            "Test loss :1.5839457384109497\n",
            "Test Accuracy :0.8775999546051025\n",
            "Sparsity= : 0.5279413096639798\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6258736544799806\n",
            "Training Accuracy :0.8473599553108215\n",
            "Validation loss :1.606259656715393\n",
            "Validation Accuracy :0.8623999953269958\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5832050384140015\n",
            "Training Accuracy :0.8852399587631226\n",
            "Validation loss :1.597478692817688\n",
            "Validation Accuracy :0.8700999617576599\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.57433245098114\n",
            "Training Accuracy :0.8928999900817871\n",
            "Validation loss :1.5928660736083984\n",
            "Validation Accuracy :0.8739999532699585\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.5689536653137206\n",
            "Training Accuracy :0.8987999558448792\n",
            "Validation loss :1.5905694942474364\n",
            "Validation Accuracy :0.8752999901771545\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.5649126916503906\n",
            "Training Accuracy :0.9020199775695801\n",
            "Validation loss :1.5873417091369628\n",
            "Validation Accuracy :0.8786999583244324\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5619469940948487\n",
            "Training Accuracy :0.9053999781608582\n",
            "Validation loss :1.5856196363449098\n",
            "Validation Accuracy :0.8804000020027161\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5598093761444092\n",
            "Training Accuracy :0.9075999855995178\n",
            "Validation loss :1.584970917892456\n",
            "Validation Accuracy :0.8806999921798706\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5576550267410278\n",
            "Training Accuracy :0.9091799855232239\n",
            "Validation loss :1.583356025314331\n",
            "Validation Accuracy :0.8815999627113342\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5560545250320434\n",
            "Training Accuracy :0.9107199907302856\n",
            "Validation loss :1.5824165214538575\n",
            "Validation Accuracy :0.8815000057220459\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5547200956344605\n",
            "Training Accuracy :0.9123199582099915\n",
            "Validation loss :1.582960897064209\n",
            "Validation Accuracy :0.8804999589920044\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5533366673278808\n",
            "Training Accuracy :0.9140799641609192\n",
            "Validation loss :1.5834943542480469\n",
            "Validation Accuracy :0.8805999755859375\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.552196598587036\n",
            "Training Accuracy :0.9150599837303162\n",
            "Validation loss :1.5806978227615356\n",
            "Validation Accuracy :0.8831999897956848\n",
            "Test loss :1.5879897443771362\n",
            "Test Accuracy :0.8750999569892883\n",
            "Sparsity= : 0.4298523684448873\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6317552400588988\n",
            "Training Accuracy :0.842199981212616\n",
            "Validation loss :1.6152855180740358\n",
            "Validation Accuracy :0.8522999882698059\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.5986184691619874\n",
            "Training Accuracy :0.8705799579620361\n",
            "Validation loss :1.6065359031677247\n",
            "Validation Accuracy :0.8628999590873718\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.590509548149109\n",
            "Training Accuracy :0.8776399493217468\n",
            "Validation loss :1.600948028564453\n",
            "Validation Accuracy :0.8657000064849854\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.585651184463501\n",
            "Training Accuracy :0.88264000415802\n",
            "Validation loss :1.5981514087677002\n",
            "Validation Accuracy :0.8689999580383301\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.581632146949768\n",
            "Training Accuracy :0.8865599632263184\n",
            "Validation loss :1.5948715057373046\n",
            "Validation Accuracy :0.8703999519348145\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.579309765853882\n",
            "Training Accuracy :0.8885200023651123\n",
            "Validation loss :1.5926148551940917\n",
            "Validation Accuracy :0.8725000023841858\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.576993600845337\n",
            "Training Accuracy :0.8906999826431274\n",
            "Validation loss :1.5914863925933838\n",
            "Validation Accuracy :0.8730999827384949\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5750484972763061\n",
            "Training Accuracy :0.8930799961090088\n",
            "Validation loss :1.5902347537994386\n",
            "Validation Accuracy :0.875\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.573247412071228\n",
            "Training Accuracy :0.895039975643158\n",
            "Validation loss :1.5901138362884522\n",
            "Validation Accuracy :0.875\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5720956377792359\n",
            "Training Accuracy :0.895799994468689\n",
            "Validation loss :1.5882169227600098\n",
            "Validation Accuracy :0.8758999705314636\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.570757459640503\n",
            "Training Accuracy :0.8965799808502197\n",
            "Validation loss :1.5880332019805907\n",
            "Validation Accuracy :0.8756999969482422\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5693702184677123\n",
            "Training Accuracy :0.8983799815177917\n",
            "Validation loss :1.5871977174758911\n",
            "Validation Accuracy :0.876800000667572\n",
            "Test loss :1.594133853340149\n",
            "Test Accuracy :0.871399998664856\n",
            "Sparsity= : 0.34947015668870574\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6218646059417725\n",
            "Training Accuracy :0.8595399856567383\n",
            "Validation loss :1.6153494220733642\n",
            "Validation Accuracy :0.8604999780654907\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.601793915939331\n",
            "Training Accuracy :0.8737399578094482\n",
            "Validation loss :1.6081119150161742\n",
            "Validation Accuracy :0.8642999529838562\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.5954245532989502\n",
            "Training Accuracy :0.8773799538612366\n",
            "Validation loss :1.6033075750350951\n",
            "Validation Accuracy :0.8679999709129333\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.591517516593933\n",
            "Training Accuracy :0.8804799914360046\n",
            "Validation loss :1.6010095405578613\n",
            "Validation Accuracy :0.8678999543190002\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.588142391204834\n",
            "Training Accuracy :0.8831999897956848\n",
            "Validation loss :1.5985140810012817\n",
            "Validation Accuracy :0.8703999519348145\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.5862923233413697\n",
            "Training Accuracy :0.8846799731254578\n",
            "Validation loss :1.5978730596542359\n",
            "Validation Accuracy :0.8698999881744385\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.584327742996216\n",
            "Training Accuracy :0.8858000040054321\n",
            "Validation loss :1.5952865406036376\n",
            "Validation Accuracy :0.8718999624252319\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5829718521881104\n",
            "Training Accuracy :0.8868399858474731\n",
            "Validation loss :1.595147363090515\n",
            "Validation Accuracy :0.8721999526023865\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5808922201156617\n",
            "Training Accuracy :0.8889600038528442\n",
            "Validation loss :1.5931642177581786\n",
            "Validation Accuracy :0.8732999563217163\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5801740075683595\n",
            "Training Accuracy :0.8894000053405762\n",
            "Validation loss :1.594815347480774\n",
            "Validation Accuracy :0.8716999888420105\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5785142235565186\n",
            "Training Accuracy :0.8906599879264832\n",
            "Validation loss :1.5918249025344848\n",
            "Validation Accuracy :0.8750999569892883\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5773462732696533\n",
            "Training Accuracy :0.8916399478912354\n",
            "Validation loss :1.5902825660705566\n",
            "Validation Accuracy :0.8759999871253967\n",
            "Test loss :1.598730676460266\n",
            "Test Accuracy :0.8689000010490417\n",
            "Sparsity= : 0.28611538809890413\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.7139860471343995\n",
            "Training Accuracy :0.7749599814414978\n",
            "Validation loss :1.6469801038742065\n",
            "Validation Accuracy :0.8388999700546265\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6329693380355834\n",
            "Training Accuracy :0.8486199975013733\n",
            "Validation loss :1.6310916534423827\n",
            "Validation Accuracy :0.848800003528595\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6221978211212158\n",
            "Training Accuracy :0.8556599617004395\n",
            "Validation loss :1.6245125703811645\n",
            "Validation Accuracy :0.8519999980926514\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6159088165664672\n",
            "Training Accuracy :0.8602799773216248\n",
            "Validation loss :1.6208540269851686\n",
            "Validation Accuracy :0.8556999564170837\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6115966769790648\n",
            "Training Accuracy :0.863599956035614\n",
            "Validation loss :1.615415584564209\n",
            "Validation Accuracy :0.8593999743461609\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6082686713027954\n",
            "Training Accuracy :0.8662199974060059\n",
            "Validation loss :1.6140275869369507\n",
            "Validation Accuracy :0.8592000007629395\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6051565908813477\n",
            "Training Accuracy :0.8674599528312683\n",
            "Validation loss :1.611464765739441\n",
            "Validation Accuracy :0.8610999584197998\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6029345806503297\n",
            "Training Accuracy :0.8695799708366394\n",
            "Validation loss :1.611567848777771\n",
            "Validation Accuracy :0.8611999750137329\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6011065406036378\n",
            "Training Accuracy :0.8708800077438354\n",
            "Validation loss :1.608110817718506\n",
            "Validation Accuracy :0.8639000058174133\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.599534956817627\n",
            "Training Accuracy :0.8722999691963196\n",
            "Validation loss :1.6064934549331664\n",
            "Validation Accuracy :0.8633999824523926\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5977438846588135\n",
            "Training Accuracy :0.8739399909973145\n",
            "Validation loss :1.6063379619598388\n",
            "Validation Accuracy :0.8637999892234802\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5960351763153076\n",
            "Training Accuracy :0.8760199546813965\n",
            "Validation loss :1.603361681175232\n",
            "Validation Accuracy :0.8675999641418457\n",
            "Test loss :1.6129129219055176\n",
            "Test Accuracy :0.8535999655723572\n",
            "Sparsity= : 0.23707091748935782\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6561326214981078\n",
            "Training Accuracy :0.832859992980957\n",
            "Validation loss :1.6446977052688598\n",
            "Validation Accuracy :0.8352999687194824\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6315710470581055\n",
            "Training Accuracy :0.8496999740600586\n",
            "Validation loss :1.6377014636993408\n",
            "Validation Accuracy :0.8396999835968018\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.625208171043396\n",
            "Training Accuracy :0.8535400032997131\n",
            "Validation loss :1.6296089321136475\n",
            "Validation Accuracy :0.8454999923706055\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6209142024230958\n",
            "Training Accuracy :0.85589998960495\n",
            "Validation loss :1.6255704303741456\n",
            "Validation Accuracy :0.8483999967575073\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6175442861175537\n",
            "Training Accuracy :0.8579399585723877\n",
            "Validation loss :1.6234452131271362\n",
            "Validation Accuracy :0.848800003528595\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6152244137954712\n",
            "Training Accuracy :0.8596799969673157\n",
            "Validation loss :1.6204098468780517\n",
            "Validation Accuracy :0.8529999852180481\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6124307677459717\n",
            "Training Accuracy :0.8617199659347534\n",
            "Validation loss :1.6184002948760987\n",
            "Validation Accuracy :0.8536999821662903\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6108047373962402\n",
            "Training Accuracy :0.8626999855041504\n",
            "Validation loss :1.6173506088256835\n",
            "Validation Accuracy :0.854200005531311\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.608720392074585\n",
            "Training Accuracy :0.8650999665260315\n",
            "Validation loss :1.615748360824585\n",
            "Validation Accuracy :0.8560000061988831\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6073133520889282\n",
            "Training Accuracy :0.8657999634742737\n",
            "Validation loss :1.6146640972137452\n",
            "Validation Accuracy :0.8567000031471252\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6061984465789796\n",
            "Training Accuracy :0.8659799695014954\n",
            "Validation loss :1.6136812215805054\n",
            "Validation Accuracy :0.8567999601364136\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6047608319091797\n",
            "Training Accuracy :0.8669799566268921\n",
            "Validation loss :1.6140622549057007\n",
            "Validation Accuracy :0.8551999926567078\n",
            "Test loss :1.6172353771209718\n",
            "Test Accuracy :0.8519999980926514\n",
            "Sparsity= : 0.19382302327687706\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.722469212036133\n",
            "Training Accuracy :0.7754999995231628\n",
            "Validation loss :1.6813220685958863\n",
            "Validation Accuracy :0.8064999580383301\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6718784136581422\n",
            "Training Accuracy :0.8148199915885925\n",
            "Validation loss :1.6685286380767823\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6615709796142577\n",
            "Training Accuracy :0.8206200003623962\n",
            "Validation loss :1.661550882911682\n",
            "Validation Accuracy :0.8166999816894531\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6557918291854858\n",
            "Training Accuracy :0.823199987411499\n",
            "Validation loss :1.6568955492019652\n",
            "Validation Accuracy :0.8199999928474426\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.651646787185669\n",
            "Training Accuracy :0.8267799615859985\n",
            "Validation loss :1.6530006795883179\n",
            "Validation Accuracy :0.8219999670982361\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6479292059326172\n",
            "Training Accuracy :0.8286799788475037\n",
            "Validation loss :1.6500972778320313\n",
            "Validation Accuracy :0.8227999806404114\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6448151559448243\n",
            "Training Accuracy :0.8306399583816528\n",
            "Validation loss :1.6514608116149903\n",
            "Validation Accuracy :0.8198999762535095\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6428869900512695\n",
            "Training Accuracy :0.8315399885177612\n",
            "Validation loss :1.6455141496658325\n",
            "Validation Accuracy :0.8279999494552612\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6410755249404907\n",
            "Training Accuracy :0.833139955997467\n",
            "Validation loss :1.6441526973724365\n",
            "Validation Accuracy :0.8283999562263489\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6389831143951417\n",
            "Training Accuracy :0.8346999883651733\n",
            "Validation loss :1.6422183197021485\n",
            "Validation Accuracy :0.8295999765396118\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6374908943939208\n",
            "Training Accuracy :0.8355799913406372\n",
            "Validation loss :1.6413816289901733\n",
            "Validation Accuracy :0.8271999955177307\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6357673451995849\n",
            "Training Accuracy :0.8368799686431885\n",
            "Validation loss :1.639466205215454\n",
            "Validation Accuracy :0.8303999900817871\n",
            "Test loss :1.6437405828475953\n",
            "Test Accuracy :0.828499972820282\n",
            "Sparsity= : 0.16248528213024183\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6756730270004272\n",
            "Training Accuracy :0.8247199654579163\n",
            "Validation loss :1.6625489133834839\n",
            "Validation Accuracy :0.825499951839447\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6553831592178345\n",
            "Training Accuracy :0.8321200013160706\n",
            "Validation loss :1.6547575748443604\n",
            "Validation Accuracy :0.8294999599456787\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6491634574127196\n",
            "Training Accuracy :0.8335199952125549\n",
            "Validation loss :1.6536745347976685\n",
            "Validation Accuracy :0.823699951171875\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6454362170410157\n",
            "Training Accuracy :0.8344599604606628\n",
            "Validation loss :1.6470452344894408\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.641796632041931\n",
            "Training Accuracy :0.837119996547699\n",
            "Validation loss :1.645963586807251\n",
            "Validation Accuracy :0.8299999833106995\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6391810013580321\n",
            "Training Accuracy :0.8376799821853638\n",
            "Validation loss :1.6427082506179809\n",
            "Validation Accuracy :0.8325999975204468\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6373377813339234\n",
            "Training Accuracy :0.8386399745941162\n",
            "Validation loss :1.641785384941101\n",
            "Validation Accuracy :0.8307999968528748\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6352230918121338\n",
            "Training Accuracy :0.8392999768257141\n",
            "Validation loss :1.6408913837432861\n",
            "Validation Accuracy :0.8313999772071838\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6333235707855225\n",
            "Training Accuracy :0.8410199880599976\n",
            "Validation loss :1.638402398300171\n",
            "Validation Accuracy :0.8325999975204468\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6319936560058594\n",
            "Training Accuracy :0.8415199518203735\n",
            "Validation loss :1.6368088132858276\n",
            "Validation Accuracy :0.8353999853134155\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.630822363357544\n",
            "Training Accuracy :0.8411799669265747\n",
            "Validation loss :1.6356048637390137\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6295818801879882\n",
            "Training Accuracy :0.8429999947547913\n",
            "Validation loss :1.6345944946289062\n",
            "Validation Accuracy :0.835599958896637\n",
            "Test loss :1.640968554878235\n",
            "Test Accuracy :0.8294999599456787\n",
            "Sparsity= : 0.13966126256679645\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.6681862671279908\n",
            "Training Accuracy :0.8223999738693237\n",
            "Validation loss :1.6601486331939697\n",
            "Validation Accuracy :0.8251999616622925\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6524011437988282\n",
            "Training Accuracy :0.8304399847984314\n",
            "Validation loss :1.654690497970581\n",
            "Validation Accuracy :0.8241999745368958\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6472596096801757\n",
            "Training Accuracy :0.8325999975204468\n",
            "Validation loss :1.6493661949157714\n",
            "Validation Accuracy :0.8283999562263489\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6430732010269165\n",
            "Training Accuracy :0.8349199891090393\n",
            "Validation loss :1.646450842475891\n",
            "Validation Accuracy :0.8298999667167664\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6395480657958985\n",
            "Training Accuracy :0.8373399972915649\n",
            "Validation loss :1.643855500793457\n",
            "Validation Accuracy :0.8306999802589417\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.637294761390686\n",
            "Training Accuracy :0.8389599919319153\n",
            "Validation loss :1.6445771911621094\n",
            "Validation Accuracy :0.8279999494552612\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6356584301757813\n",
            "Training Accuracy :0.8396199941635132\n",
            "Validation loss :1.6413853870391846\n",
            "Validation Accuracy :0.8300999999046326\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6333066919708252\n",
            "Training Accuracy :0.8416599631309509\n",
            "Validation loss :1.639048731803894\n",
            "Validation Accuracy :0.8317999839782715\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6320306047058106\n",
            "Training Accuracy :0.8413999676704407\n",
            "Validation loss :1.6373144538879394\n",
            "Validation Accuracy :0.8342999815940857\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6305961052703857\n",
            "Training Accuracy :0.8419599533081055\n",
            "Validation loss :1.6363669050216674\n",
            "Validation Accuracy :0.8342999815940857\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6287582730102539\n",
            "Training Accuracy :0.8434000015258789\n",
            "Validation loss :1.6371017866134643\n",
            "Validation Accuracy :0.8341999650001526\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6280143884277343\n",
            "Training Accuracy :0.844819962978363\n",
            "Validation loss :1.6339082077026368\n",
            "Validation Accuracy :0.835099995136261\n",
            "Test loss :1.6377633365631104\n",
            "Test Accuracy :0.8345999717712402\n",
            "Sparsity= : 0.11683724300335119\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.7015998206329346\n",
            "Training Accuracy :0.8077200055122375\n",
            "Validation loss :1.6805882419586182\n",
            "Validation Accuracy :0.8156999945640564\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6672111423110962\n",
            "Training Accuracy :0.8260399699211121\n",
            "Validation loss :1.6671967569351196\n",
            "Validation Accuracy :0.8209999799728394\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6590547869491576\n",
            "Training Accuracy :0.8297999501228333\n",
            "Validation loss :1.6600358623504639\n",
            "Validation Accuracy :0.8247999548912048\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.652825030822754\n",
            "Training Accuracy :0.8322399854660034\n",
            "Validation loss :1.6560361011505127\n",
            "Validation Accuracy :0.8251000046730042\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.648716357688904\n",
            "Training Accuracy :0.8341000080108643\n",
            "Validation loss :1.6518331398010253\n",
            "Validation Accuracy :0.8269999623298645\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6458451363372804\n",
            "Training Accuracy :0.8337799906730652\n",
            "Validation loss :1.6521869983673096\n",
            "Validation Accuracy :0.8258999586105347\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6436219057846069\n",
            "Training Accuracy :0.8351799845695496\n",
            "Validation loss :1.6497283504486084\n",
            "Validation Accuracy :0.8276999592781067\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6404855780029297\n",
            "Training Accuracy :0.8372799754142761\n",
            "Validation loss :1.6466467754364014\n",
            "Validation Accuracy :0.8285999894142151\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6382369662475587\n",
            "Training Accuracy :0.8385599851608276\n",
            "Validation loss :1.642683353614807\n",
            "Validation Accuracy :0.8323999643325806\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6366948929214478\n",
            "Training Accuracy :0.8393999934196472\n",
            "Validation loss :1.6416723627090455\n",
            "Validation Accuracy :0.8321999907493591\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6356695412445068\n",
            "Training Accuracy :0.8392999768257141\n",
            "Validation loss :1.6401459327697754\n",
            "Validation Accuracy :0.8341000080108643\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.634339542274475\n",
            "Training Accuracy :0.8400399684906006\n",
            "Validation loss :1.6418423135757447\n",
            "Validation Accuracy :0.833899974822998\n",
            "Test loss :1.6472505430221558\n",
            "Test Accuracy :0.8267999887466431\n",
            "Sparsity= : 0.10252694502309578\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.7990964879989624\n",
            "Training Accuracy :0.7062399983406067\n",
            "Validation loss :1.7577240629196167\n",
            "Validation Accuracy :0.73499995470047\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7486641763305664\n",
            "Training Accuracy :0.7423200011253357\n",
            "Validation loss :1.723470648574829\n",
            "Validation Accuracy :0.7723000049591064\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6954524431610107\n",
            "Training Accuracy :0.7960799932479858\n",
            "Validation loss :1.6858125705718994\n",
            "Validation Accuracy :0.802299976348877\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.675337445449829\n",
            "Training Accuracy :0.8115800023078918\n",
            "Validation loss :1.6733823581695557\n",
            "Validation Accuracy :0.810699999332428\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6680136101913452\n",
            "Training Accuracy :0.8149600028991699\n",
            "Validation loss :1.6684366134643556\n",
            "Validation Accuracy :0.8111000061035156\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.661912924156189\n",
            "Training Accuracy :0.8194400072097778\n",
            "Validation loss :1.666365567779541\n",
            "Validation Accuracy :0.8134999871253967\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6574884915542603\n",
            "Training Accuracy :0.8222799897193909\n",
            "Validation loss :1.6626312656402589\n",
            "Validation Accuracy :0.8139999508857727\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.65524805519104\n",
            "Training Accuracy :0.8224200010299683\n",
            "Validation loss :1.6580865388870238\n",
            "Validation Accuracy :0.81659996509552\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6522710103988647\n",
            "Training Accuracy :0.8249399662017822\n",
            "Validation loss :1.6591112686157226\n",
            "Validation Accuracy :0.8173999786376953\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6495412618637084\n",
            "Training Accuracy :0.8266399502754211\n",
            "Validation loss :1.6539258794784546\n",
            "Validation Accuracy :0.8197000026702881\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6479794101715088\n",
            "Training Accuracy :0.8273800015449524\n",
            "Validation loss :1.6506259380340575\n",
            "Validation Accuracy :0.8226999640464783\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.646345526046753\n",
            "Training Accuracy :0.8286399841308594\n",
            "Validation loss :1.652302320098877\n",
            "Validation Accuracy :0.8216999769210815\n",
            "Test loss :1.6602254987716676\n",
            "Test Accuracy :0.8136999607086182\n",
            "Sparsity= : 0.08821664704284027\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.7268164184188843\n",
            "Training Accuracy :0.7859599590301514\n",
            "Validation loss :1.6883086406707764\n",
            "Validation Accuracy :0.8151999711990356\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.6797132294082642\n",
            "Training Accuracy :0.8196600079536438\n",
            "Validation loss :1.6779878828048707\n",
            "Validation Accuracy :0.8165000081062317\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.670559264755249\n",
            "Training Accuracy :0.8216599822044373\n",
            "Validation loss :1.6732609725952148\n",
            "Validation Accuracy :0.8152999877929688\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6644897547149657\n",
            "Training Accuracy :0.825439989566803\n",
            "Validation loss :1.6680679285049438\n",
            "Validation Accuracy :0.8174999952316284\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.660179845275879\n",
            "Training Accuracy :0.8253999948501587\n",
            "Validation loss :1.6643741271972656\n",
            "Validation Accuracy :0.8167999982833862\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6557834231185913\n",
            "Training Accuracy :0.8284800052642822\n",
            "Validation loss :1.660156314277649\n",
            "Validation Accuracy :0.8217999935150146\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6532317725753785\n",
            "Training Accuracy :0.8288999795913696\n",
            "Validation loss :1.6573114112854004\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6506853689956664\n",
            "Training Accuracy :0.830299973487854\n",
            "Validation loss :1.655605707168579\n",
            "Validation Accuracy :0.8228999972343445\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.648853662071228\n",
            "Training Accuracy :0.8305599689483643\n",
            "Validation loss :1.6557583118438721\n",
            "Validation Accuracy :0.8211999535560608\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6475772826385497\n",
            "Training Accuracy :0.8301199674606323\n",
            "Validation loss :1.6536937610626221\n",
            "Validation Accuracy :0.8222999572753906\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6450936435699464\n",
            "Training Accuracy :0.8322799801826477\n",
            "Validation loss :1.6517308368682861\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.643511940689087\n",
            "Training Accuracy :0.8334199786186218\n",
            "Validation loss :1.6563233207702637\n",
            "Validation Accuracy :0.8202999830245972\n",
            "Test loss :1.6592355361938476\n",
            "Test Accuracy :0.8163999915122986\n",
            "Sparsity= : 0.07970292545965041\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.8304808172988891\n",
            "Training Accuracy :0.694379985332489\n",
            "Validation loss :1.7888957397460938\n",
            "Validation Accuracy :0.7407000064849854\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7634912097930908\n",
            "Training Accuracy :0.7668600082397461\n",
            "Validation loss :1.751008341217041\n",
            "Validation Accuracy :0.7759999632835388\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.7332209078216552\n",
            "Training Accuracy :0.7868799567222595\n",
            "Validation loss :1.7252567373275758\n",
            "Validation Accuracy :0.7888000011444092\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.7133939206695556\n",
            "Training Accuracy :0.7976599931716919\n",
            "Validation loss :1.7121706634521485\n",
            "Validation Accuracy :0.7944999933242798\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.702806301612854\n",
            "Training Accuracy :0.8018800020217896\n",
            "Validation loss :1.7041252746582032\n",
            "Validation Accuracy :0.7944999933242798\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.69535110786438\n",
            "Training Accuracy :0.8042199611663818\n",
            "Validation loss :1.69749644947052\n",
            "Validation Accuracy :0.7989999651908875\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.688884758605957\n",
            "Training Accuracy :0.8068199753761292\n",
            "Validation loss :1.6926602863311768\n",
            "Validation Accuracy :0.799299955368042\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6831889003753662\n",
            "Training Accuracy :0.8104999661445618\n",
            "Validation loss :1.6862812549591064\n",
            "Validation Accuracy :0.8054999709129333\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.68039085811615\n",
            "Training Accuracy :0.8104400038719177\n",
            "Validation loss :1.6830043256759644\n",
            "Validation Accuracy :0.8084999918937683\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6765697622299194\n",
            "Training Accuracy :0.8121999502182007\n",
            "Validation loss :1.6834368448257446\n",
            "Validation Accuracy :0.804099977016449\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6726603964614868\n",
            "Training Accuracy :0.8136999607086182\n",
            "Validation loss :1.6762341686248778\n",
            "Validation Accuracy :0.8071999549865723\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.669277024307251\n",
            "Training Accuracy :0.814799964427948\n",
            "Validation loss :1.6742098728179933\n",
            "Validation Accuracy :0.8080999851226807\n",
            "Test loss :1.679101131439209\n",
            "Test Accuracy :0.8032999634742737\n",
            "Sparsity= : 0.07118920387646044\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.000783275299072\n",
            "Training Accuracy :0.47217997908592224\n",
            "Validation loss :1.9945900814056396\n",
            "Validation Accuracy :0.49939998984336853\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.971139977645874\n",
            "Training Accuracy :0.5417400002479553\n",
            "Validation loss :1.9605142755508422\n",
            "Validation Accuracy :0.5539999604225159\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.938969080543518\n",
            "Training Accuracy :0.5636399984359741\n",
            "Validation loss :1.934962255859375\n",
            "Validation Accuracy :0.557200014591217\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.9211688988494873\n",
            "Training Accuracy :0.5658800005912781\n",
            "Validation loss :1.9235749109268188\n",
            "Validation Accuracy :0.5591999888420105\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.9120922134399414\n",
            "Training Accuracy :0.5674799680709839\n",
            "Validation loss :1.9165304584503173\n",
            "Validation Accuracy :0.5598999857902527\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.9065385009384155\n",
            "Training Accuracy :0.5690999627113342\n",
            "Validation loss :1.912800295829773\n",
            "Validation Accuracy :0.5607999563217163\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.9027989624404906\n",
            "Training Accuracy :0.5697399973869324\n",
            "Validation loss :1.9092090803146362\n",
            "Validation Accuracy :0.5618000030517578\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.9005204140472411\n",
            "Training Accuracy :0.5703999996185303\n",
            "Validation loss :1.906068155860901\n",
            "Validation Accuracy :0.5633999705314636\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.8979975466918946\n",
            "Training Accuracy :0.5715999603271484\n",
            "Validation loss :1.9048483297348022\n",
            "Validation Accuracy :0.5638999938964844\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.8963140398788452\n",
            "Training Accuracy :0.5724799633026123\n",
            "Validation loss :1.9031914081573487\n",
            "Validation Accuracy :0.5654000043869019\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.894836921005249\n",
            "Training Accuracy :0.5730599761009216\n",
            "Validation loss :1.9024007564544678\n",
            "Validation Accuracy :0.5647000074386597\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.8935066833114624\n",
            "Training Accuracy :0.5737199783325195\n",
            "Validation loss :1.9006209424972533\n",
            "Validation Accuracy :0.5659999847412109\n",
            "Test loss :1.8959731746673585\n",
            "Test Accuracy :0.5709999799728394\n",
            "Sparsity= : 0.06267548229327058\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.08189882522583\n",
            "Training Accuracy :0.36368000507354736\n",
            "Validation loss :2.0707275131225584\n",
            "Validation Accuracy :0.3730999827384949\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.0690681664276123\n",
            "Training Accuracy :0.3792800009250641\n",
            "Validation loss :2.0682147151947023\n",
            "Validation Accuracy :0.38519999384880066\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.0670129666900636\n",
            "Training Accuracy :0.3840999901294708\n",
            "Validation loss :2.066518196105957\n",
            "Validation Accuracy :0.38449999690055847\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.065978034439087\n",
            "Training Accuracy :0.38515999913215637\n",
            "Validation loss :2.0660090183258055\n",
            "Validation Accuracy :0.3847000002861023\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.0652627882385253\n",
            "Training Accuracy :0.3852599859237671\n",
            "Validation loss :2.0648620670318603\n",
            "Validation Accuracy :0.3854999840259552\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.0643336669158936\n",
            "Training Accuracy :0.3882800042629242\n",
            "Validation loss :2.064741322517395\n",
            "Validation Accuracy :0.38589999079704285\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.063908963661194\n",
            "Training Accuracy :0.3885599970817566\n",
            "Validation loss :2.06299925365448\n",
            "Validation Accuracy :0.3944999873638153\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.062769837188721\n",
            "Training Accuracy :0.3911399841308594\n",
            "Validation loss :2.0624669878005983\n",
            "Validation Accuracy :0.3928999900817871\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.062081272277832\n",
            "Training Accuracy :0.39455997943878174\n",
            "Validation loss :2.0615745031356814\n",
            "Validation Accuracy :0.398499995470047\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.0611599645996095\n",
            "Training Accuracy :0.3994999825954437\n",
            "Validation loss :2.0605963373184206\n",
            "Validation Accuracy :0.46779999136924744\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.056807832183838\n",
            "Training Accuracy :0.4373599886894226\n",
            "Validation loss :2.0509592739105225\n",
            "Validation Accuracy :0.4115999937057495\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.039764139175415\n",
            "Training Accuracy :0.4759399890899658\n",
            "Validation loss :2.0318568168640136\n",
            "Validation Accuracy :0.4765999913215637\n",
            "Test loss :2.032456283950806\n",
            "Test Accuracy :0.47759997844696045\n",
            "Sparsity= : 0.056878905896205034\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.0633701482391356\n",
            "Training Accuracy :0.4426399767398834\n",
            "Validation loss :2.046185795211792\n",
            "Validation Accuracy :0.46149998903274536\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.0412988092803954\n",
            "Training Accuracy :0.4651399850845337\n",
            "Validation loss :2.0380632011413575\n",
            "Validation Accuracy :0.4634999930858612\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.0336153774261474\n",
            "Training Accuracy :0.4679199755191803\n",
            "Validation loss :2.031595625114441\n",
            "Validation Accuracy :0.46480000019073486\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.0276679686737062\n",
            "Training Accuracy :0.4701399803161621\n",
            "Validation loss :2.0270048902511597\n",
            "Validation Accuracy :0.4667999744415283\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.0229266822052003\n",
            "Training Accuracy :0.4720200002193451\n",
            "Validation loss :2.022437150192261\n",
            "Validation Accuracy :0.4706999957561493\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.0191107041931153\n",
            "Training Accuracy :0.4733799993991852\n",
            "Validation loss :2.0184281368255617\n",
            "Validation Accuracy :0.4713999927043915\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.015815743560791\n",
            "Training Accuracy :0.4746999740600586\n",
            "Validation loss :2.01605322933197\n",
            "Validation Accuracy :0.4705999791622162\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.013132198867798\n",
            "Training Accuracy :0.47516000270843506\n",
            "Validation loss :2.0132253505706785\n",
            "Validation Accuracy :0.47200000286102295\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.0107497631072997\n",
            "Training Accuracy :0.4756999909877777\n",
            "Validation loss :2.0109692617416384\n",
            "Validation Accuracy :0.47439998388290405\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.0086861485290526\n",
            "Training Accuracy :0.4768799841403961\n",
            "Validation loss :2.0093202617645263\n",
            "Validation Accuracy :0.47439998388290405\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.0067707154083254\n",
            "Training Accuracy :0.47721999883651733\n",
            "Validation loss :2.0077585231781008\n",
            "Validation Accuracy :0.47589999437332153\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.005128692855835\n",
            "Training Accuracy :0.47825998067855835\n",
            "Validation loss :2.0076916984558104\n",
            "Validation Accuracy :0.47209998965263367\n",
            "Test loss :2.0076149673461914\n",
            "Test Accuracy :0.4732999801635742\n",
            "Sparsity= : 0.0510823294991396\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.0613327183532717\n",
            "Training Accuracy :0.4187999963760376\n",
            "Validation loss :2.044908603286743\n",
            "Validation Accuracy :0.4380999803543091\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.0370237422943114\n",
            "Training Accuracy :0.45003998279571533\n",
            "Validation loss :2.032156047439575\n",
            "Validation Accuracy :0.45479997992515564\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.0306210443878174\n",
            "Training Accuracy :0.4559199810028076\n",
            "Validation loss :2.0268158096313478\n",
            "Validation Accuracy :0.45809999108314514\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.024622762069702\n",
            "Training Accuracy :0.46121999621391296\n",
            "Validation loss :2.024584154319763\n",
            "Validation Accuracy :0.4626999795436859\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.0201810707855223\n",
            "Training Accuracy :0.4646399915218353\n",
            "Validation loss :2.026230375671387\n",
            "Validation Accuracy :0.45829999446868896\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.0148076555633545\n",
            "Training Accuracy :0.4675599932670593\n",
            "Validation loss :2.01192237701416\n",
            "Validation Accuracy :0.46779999136924744\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.011235747528076\n",
            "Training Accuracy :0.46963998675346375\n",
            "Validation loss :2.0102690603256224\n",
            "Validation Accuracy :0.46859997510910034\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.0094739053344726\n",
            "Training Accuracy :0.46983999013900757\n",
            "Validation loss :2.008770400047302\n",
            "Validation Accuracy :0.46889999508857727\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.0066288903808593\n",
            "Training Accuracy :0.4713599979877472\n",
            "Validation loss :2.0093593120574953\n",
            "Validation Accuracy :0.46709999442100525\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.0049979847717285\n",
            "Training Accuracy :0.4720799922943115\n",
            "Validation loss :2.004778639984131\n",
            "Validation Accuracy :0.4712999761104584\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.003932872314453\n",
            "Training Accuracy :0.4727199971675873\n",
            "Validation loss :2.004623122406006\n",
            "Validation Accuracy :0.47099998593330383\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.002531119918823\n",
            "Training Accuracy :0.47311997413635254\n",
            "Validation loss :2.003293770980835\n",
            "Validation Accuracy :0.47079998254776\n",
            "Test loss :2.00363588886261\n",
            "Test Accuracy :0.4705999791622162\n",
            "Sparsity= : 0.0510823294991396\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.0013967948913574\n",
            "Training Accuracy :0.4733399748802185\n",
            "Validation loss :2.0032066133499145\n",
            "Validation Accuracy :0.47079998254776\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.0001269216918947\n",
            "Training Accuracy :0.4732999801635742\n",
            "Validation loss :2.001508862686157\n",
            "Validation Accuracy :0.47119998931884766\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.9991738327789306\n",
            "Training Accuracy :0.47391998767852783\n",
            "Validation loss :2.0003838205337523\n",
            "Validation Accuracy :0.4715999960899353\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.9978206760025023\n",
            "Training Accuracy :0.47453999519348145\n",
            "Validation loss :1.9996566495895385\n",
            "Validation Accuracy :0.4715999960899353\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.996999242286682\n",
            "Training Accuracy :0.4748999774456024\n",
            "Validation loss :1.9983778797149658\n",
            "Validation Accuracy :0.47189998626708984\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.996631185951233\n",
            "Training Accuracy :0.4750399887561798\n",
            "Validation loss :1.9980218524932862\n",
            "Validation Accuracy :0.47189998626708984\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.995505702896118\n",
            "Training Accuracy :0.4753199815750122\n",
            "Validation loss :2.0004089756011965\n",
            "Validation Accuracy :0.47049999237060547\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.9949380834960937\n",
            "Training Accuracy :0.4754999876022339\n",
            "Validation loss :1.9966422039031981\n",
            "Validation Accuracy :0.47200000286102295\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.9940945916748047\n",
            "Training Accuracy :0.47613999247550964\n",
            "Validation loss :1.995544680595398\n",
            "Validation Accuracy :0.47279998660087585\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.9932596142196655\n",
            "Training Accuracy :0.4767199754714966\n",
            "Validation loss :1.9957831581115724\n",
            "Validation Accuracy :0.4724999964237213\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.9925694135284424\n",
            "Training Accuracy :0.4765999913215637\n",
            "Validation loss :1.9946724584579467\n",
            "Validation Accuracy :0.4737999737262726\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.9918741551971435\n",
            "Training Accuracy :0.4771599769592285\n",
            "Validation loss :1.9940136499404908\n",
            "Validation Accuracy :0.47360000014305115\n",
            "Test loss :1.9949475816726685\n",
            "Test Accuracy :0.47269999980926514\n",
            "Sparsity= : 0.0510823294991396\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :1.9916581735229493\n",
            "Training Accuracy :0.477539986371994\n",
            "Validation loss :1.9934111284255982\n",
            "Validation Accuracy :0.47369998693466187\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.9908515935516358\n",
            "Training Accuracy :0.47766000032424927\n",
            "Validation loss :1.994388704109192\n",
            "Validation Accuracy :0.4733999967575073\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.9905967931747437\n",
            "Training Accuracy :0.47811999917030334\n",
            "Validation loss :1.992954147529602\n",
            "Validation Accuracy :0.47360000014305115\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.9901831052017211\n",
            "Training Accuracy :0.4777999818325043\n",
            "Validation loss :1.9922868816375732\n",
            "Validation Accuracy :0.47419998049736023\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.9893656661987305\n",
            "Training Accuracy :0.47835999727249146\n",
            "Validation loss :1.9928484615325928\n",
            "Validation Accuracy :0.4738999903202057\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.9893753118896484\n",
            "Training Accuracy :0.47825998067855835\n",
            "Validation loss :1.993242608833313\n",
            "Validation Accuracy :0.4738999903202057\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.9888917906188965\n",
            "Training Accuracy :0.47843998670578003\n",
            "Validation loss :1.9927207122802735\n",
            "Validation Accuracy :0.4745999872684479\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.988533327407837\n",
            "Training Accuracy :0.4785799980163574\n",
            "Validation loss :1.9919113262176513\n",
            "Validation Accuracy :0.47360000014305115\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.988751561050415\n",
            "Training Accuracy :0.4781799912452698\n",
            "Validation loss :1.991318201828003\n",
            "Validation Accuracy :0.47429999709129333\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.9877773131561278\n",
            "Training Accuracy :0.4791199862957001\n",
            "Validation loss :1.9910958112716675\n",
            "Validation Accuracy :0.47450000047683716\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.9873879452133179\n",
            "Training Accuracy :0.47909998893737793\n",
            "Validation loss :1.9902923166275024\n",
            "Validation Accuracy :0.4754999876022339\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.987221743850708\n",
            "Training Accuracy :0.47915998101234436\n",
            "Validation loss :1.9907137336730958\n",
            "Validation Accuracy :0.4755999743938446\n",
            "Test loss :1.9906100574493408\n",
            "Test Accuracy :0.4757999777793884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "SX3ZpJ5lAFPt",
        "outputId": "9ab11d20-4dfc-40e7-899b-218ac2518e9b"
      },
      "source": [
        "#plotting sparsity vs accuracy\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(0,1)\n",
        "plt.plot(sparsity,acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5e327075d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "N5nwp0vQAKCH",
        "outputId": "74d88521-ef67-44c4-fd33-cd6903288430"
      },
      "source": [
        "#comparing the method with and without retraining\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "\n",
        "\n",
        "plt.plot(sparsity,acc)\n",
        "plt.plot(sparsity_wr,acc_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5e32ffacd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr144P74Emsp",
        "outputId": "0d34501e-23d1-49ce-c23b-725714b1eb40"
      },
      "source": [
        "sparsity_wr,acc_wr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.8072185490444705,\n",
              "  0.651571415632642,\n",
              "  0.5279413096639798,\n",
              "  0.4298523684448873,\n",
              "  0.34947015668870574,\n",
              "  0.28611538809890413,\n",
              "  0.23707091748935782,\n",
              "  0.19382302327687706,\n",
              "  0.16248528213024183,\n",
              "  0.13966126256679645,\n",
              "  0.11683724300335119,\n",
              "  0.10252694502309578,\n",
              "  0.08821664704284027,\n",
              "  0.07970292545965041,\n",
              "  0.07118920387646044,\n",
              "  0.06267548229327058,\n",
              "  0.056878905896205034,\n",
              "  0.0510823294991396,\n",
              "  0.0510823294991396,\n",
              "  0.0510823294991396],\n",
              " [0.8896999955177307,\n",
              "  tensor(0.7908, device='cuda:0'),\n",
              "  tensor(0.5060, device='cuda:0'),\n",
              "  tensor(0.3081, device='cuda:0'),\n",
              "  tensor(0.2291, device='cuda:0'),\n",
              "  tensor(0.1973, device='cuda:0'),\n",
              "  tensor(0.1241, device='cuda:0'),\n",
              "  tensor(0.1030, device='cuda:0'),\n",
              "  tensor(0.0927, device='cuda:0'),\n",
              "  tensor(0.0984, device='cuda:0'),\n",
              "  tensor(0.0913, device='cuda:0'),\n",
              "  tensor(0.0963, device='cuda:0'),\n",
              "  tensor(0.0957, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0'),\n",
              "  tensor(0.1000, device='cuda:0')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61FuyN99Eq2k",
        "outputId": "b95c49da-5bb2-46d8-c81c-7f62c76f1825"
      },
      "source": [
        "sparsity,acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.8072185490444705,\n",
              "  0.651571415632642,\n",
              "  0.5279413096639798,\n",
              "  0.4298523684448873,\n",
              "  0.34947015668870574,\n",
              "  0.28611538809890413,\n",
              "  0.23707091748935782,\n",
              "  0.19382302327687706,\n",
              "  0.16248528213024183,\n",
              "  0.13966126256679645,\n",
              "  0.11683724300335119,\n",
              "  0.10252694502309578,\n",
              "  0.08821664704284027,\n",
              "  0.07970292545965041,\n",
              "  0.07118920387646044,\n",
              "  0.06267548229327058,\n",
              "  0.056878905896205034,\n",
              "  0.0510823294991396,\n",
              "  0.0510823294991396,\n",
              "  0.0510823294991396],\n",
              " [0.8896999955177307,\n",
              "  tensor(0.8856, device='cuda:0'),\n",
              "  tensor(0.8776, device='cuda:0'),\n",
              "  tensor(0.8751, device='cuda:0'),\n",
              "  tensor(0.8714, device='cuda:0'),\n",
              "  tensor(0.8689, device='cuda:0'),\n",
              "  tensor(0.8536, device='cuda:0'),\n",
              "  tensor(0.8520, device='cuda:0'),\n",
              "  tensor(0.8285, device='cuda:0'),\n",
              "  tensor(0.8295, device='cuda:0'),\n",
              "  tensor(0.8346, device='cuda:0'),\n",
              "  tensor(0.8268, device='cuda:0'),\n",
              "  tensor(0.8137, device='cuda:0'),\n",
              "  tensor(0.8164, device='cuda:0'),\n",
              "  tensor(0.8033, device='cuda:0'),\n",
              "  tensor(0.5710, device='cuda:0'),\n",
              "  tensor(0.4776, device='cuda:0'),\n",
              "  tensor(0.4733, device='cuda:0'),\n",
              "  tensor(0.4706, device='cuda:0'),\n",
              "  tensor(0.4727, device='cuda:0'),\n",
              "  tensor(0.4758, device='cuda:0')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc70FNXs7Dv_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Rre_MXZixn"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/model1_fas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvoopwzix6C"
      },
      "source": [
        "#### Applying lottery ticket based method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWh0PIEkixRD"
      },
      "source": [
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yule2EweHPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7d2cfe-bd83-40a1-c937-39dc74771a52"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (average1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (average2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=120, out_features=82, bias=True)\n",
              "  (fc2): Linear(in_features=82, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiZz7aCjTTV"
      },
      "source": [
        "init_weights=model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Nfa7zujW_F"
      },
      "source": [
        "#saving initializations for retraining\n",
        "torch.save(init_weights,\"/content/drive/MyDrive/ml project/fashion_lotteryinit\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XATRkObBjcKF"
      },
      "source": [
        "learning_rate = 0.1\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "crieteria=nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3aztfyojfcF"
      },
      "source": [
        "best_acc=0\n",
        "early_stop=0\n",
        "n_epochs=60\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "train_accuracy=[]\n",
        "val_accuracy=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfiRI87Kj1oo",
        "outputId": "1ae4f943-b95a-46be-e7ea-bfc69f8e0b8b"
      },
      "source": [
        "#training and saving early stopping\n",
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "  tr_loss=0\n",
        "  vl_loss=0\n",
        "  print(f\"-----------EPOCH {epoch} ------------------ \")\n",
        "  correct=0\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    train = Variable(images.view(len(images), 1, 28, 28))\n",
        "    labels = Variable(labels)\n",
        "    outputs = model(train)\n",
        "    loss = crieteria(outputs, labels)\n",
        "    tr_loss+=loss.item()*len(images)\n",
        "    predictions = torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss.append(tr_loss/len(train_dataset))\n",
        "  train_accuracy.append(correct/len(train_dataset))\n",
        "  print(f\"Training loss :{tr_loss/len(train_dataset)}\")\n",
        "  print(f\"Training Accuracy :{correct/len(train_dataset)}\")\n",
        "  correct=0\n",
        "  for images, labels in val_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    val = Variable(images.view(len(images), 1, 28, 28))\n",
        "    labels = Variable(labels)\n",
        "    outputs = model(val)\n",
        "    loss = crieteria(outputs, labels)\n",
        "    vl_loss+=loss.item()*len(images)\n",
        "    predictions = torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum()\n",
        "  val_loss.append(vl_loss/len(val_dataset))\n",
        "  val_accuracy.append(correct/len(val_dataset))\n",
        "  print(f\"Validation loss :{vl_loss/len(val_dataset)}\")\n",
        "  print(f\"Validation Accuracy :{correct/len(val_dataset)}\")\n",
        "  if correct/len(val_dataset) > best_acc:\n",
        "    best_acc=correct/len(val_dataset)\n",
        "    early_stop=epoch\n",
        "    torch.save(model,\"/content/drive/MyDrive/ml project/fashion_lotterytrain\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.0092479375457764\n",
            "Training Accuracy :0.48677998781204224\n",
            "Validation loss :1.7469022062301636\n",
            "Validation Accuracy :0.7235999703407288\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7175901782989502\n",
            "Training Accuracy :0.7501800060272217\n",
            "Validation loss :1.6880689916610718\n",
            "Validation Accuracy :0.7770000100135803\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6739047386932373\n",
            "Training Accuracy :0.7923199534416199\n",
            "Validation loss :1.659077264213562\n",
            "Validation Accuracy :0.8062999844551086\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6466971934509278\n",
            "Training Accuracy :0.8181799650192261\n",
            "Validation loss :1.6423980323791505\n",
            "Validation Accuracy :0.8226000070571899\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6289335662460327\n",
            "Training Accuracy :0.8356399536132812\n",
            "Validation loss :1.624289900779724\n",
            "Validation Accuracy :0.839199960231781\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6204587384796143\n",
            "Training Accuracy :0.8421599864959717\n",
            "Validation loss :1.6154596466064453\n",
            "Validation Accuracy :0.8473999500274658\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6127844998931884\n",
            "Training Accuracy :0.8500199913978577\n",
            "Validation loss :1.6102365739822389\n",
            "Validation Accuracy :0.8499999642372131\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6057529108428954\n",
            "Training Accuracy :0.8572199940681458\n",
            "Validation loss :1.6115777618408202\n",
            "Validation Accuracy :0.8508999943733215\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6022461977767943\n",
            "Training Accuracy :0.8591399788856506\n",
            "Validation loss :1.6050180852890015\n",
            "Validation Accuracy :0.8560000061988831\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5968905777740479\n",
            "Training Accuracy :0.8654999732971191\n",
            "Validation loss :1.6008285112380982\n",
            "Validation Accuracy :0.8611999750137329\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5948172368621827\n",
            "Training Accuracy :0.8675999641418457\n",
            "Validation loss :1.6048652145385742\n",
            "Validation Accuracy :0.858199954032898\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5901041089630128\n",
            "Training Accuracy :0.8721599578857422\n",
            "Validation loss :1.6050495006561278\n",
            "Validation Accuracy :0.8568999767303467\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.5883141865539552\n",
            "Training Accuracy :0.8742599487304688\n",
            "Validation loss :1.5932815349578857\n",
            "Validation Accuracy :0.8694999814033508\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.5834613915252687\n",
            "Training Accuracy :0.8792399764060974\n",
            "Validation loss :1.591990138053894\n",
            "Validation Accuracy :0.8689999580383301\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.580899855117798\n",
            "Training Accuracy :0.8820199966430664\n",
            "Validation loss :1.586747481918335\n",
            "Validation Accuracy :0.8743000030517578\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.5805556734848023\n",
            "Training Accuracy :0.8812599778175354\n",
            "Validation loss :1.5836034587860108\n",
            "Validation Accuracy :0.8783999681472778\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.577528462638855\n",
            "Training Accuracy :0.8850399851799011\n",
            "Validation loss :1.5832907936096192\n",
            "Validation Accuracy :0.8782999515533447\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.573954536819458\n",
            "Training Accuracy :0.8883000016212463\n",
            "Validation loss :1.585672470474243\n",
            "Validation Accuracy :0.8763999938964844\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.5711820733261108\n",
            "Training Accuracy :0.8913799524307251\n",
            "Validation loss :1.5863821823120117\n",
            "Validation Accuracy :0.875499963760376\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.5693303273773194\n",
            "Training Accuracy :0.8930000066757202\n",
            "Validation loss :1.5818153812408446\n",
            "Validation Accuracy :0.8794999718666077\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5708845137405396\n",
            "Training Accuracy :0.8911399841308594\n",
            "Validation loss :1.5782144262313842\n",
            "Validation Accuracy :0.8827999830245972\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.5683601766204833\n",
            "Training Accuracy :0.8938199877738953\n",
            "Validation loss :1.577620244407654\n",
            "Validation Accuracy :0.8840999603271484\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.5648528519821168\n",
            "Training Accuracy :0.8975799679756165\n",
            "Validation loss :1.5799244815826416\n",
            "Validation Accuracy :0.8822999596595764\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.5644292436981202\n",
            "Training Accuracy :0.8979199528694153\n",
            "Validation loss :1.5774312755584716\n",
            "Validation Accuracy :0.8840999603271484\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5626128909301757\n",
            "Training Accuracy :0.8995199799537659\n",
            "Validation loss :1.5851371990203857\n",
            "Validation Accuracy :0.8759999871253967\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5635588706207275\n",
            "Training Accuracy :0.8994199633598328\n",
            "Validation loss :1.5754280519485473\n",
            "Validation Accuracy :0.8847000002861023\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5607993022537232\n",
            "Training Accuracy :0.9007999897003174\n",
            "Validation loss :1.5791767715454101\n",
            "Validation Accuracy :0.8822000026702881\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.561351771659851\n",
            "Training Accuracy :0.9002999663352966\n",
            "Validation loss :1.573424782180786\n",
            "Validation Accuracy :0.8880999684333801\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5576144739151\n",
            "Training Accuracy :0.9045999646186829\n",
            "Validation loss :1.5747506443023682\n",
            "Validation Accuracy :0.8867999911308289\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5571227866363526\n",
            "Training Accuracy :0.9044599533081055\n",
            "Validation loss :1.5760895374298096\n",
            "Validation Accuracy :0.8852999806404114\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5563761458969116\n",
            "Training Accuracy :0.9060199856758118\n",
            "Validation loss :1.570752865600586\n",
            "Validation Accuracy :0.890999972820282\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.553591190071106\n",
            "Training Accuracy :0.9088799953460693\n",
            "Validation loss :1.5731688524246217\n",
            "Validation Accuracy :0.8883000016212463\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5546968730926514\n",
            "Training Accuracy :0.9073599576950073\n",
            "Validation loss :1.5682598720550538\n",
            "Validation Accuracy :0.8930999636650085\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.551652042388916\n",
            "Training Accuracy :0.9101799726486206\n",
            "Validation loss :1.5713436420440674\n",
            "Validation Accuracy :0.8888999819755554\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.552433957633972\n",
            "Training Accuracy :0.9094799757003784\n",
            "Validation loss :1.5699856433868409\n",
            "Validation Accuracy :0.8915999531745911\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5505849169158936\n",
            "Training Accuracy :0.9122200012207031\n",
            "Validation loss :1.5777256734848022\n",
            "Validation Accuracy :0.8823999762535095\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5519824864578247\n",
            "Training Accuracy :0.9100799560546875\n",
            "Validation loss :1.570377580833435\n",
            "Validation Accuracy :0.8898999691009521\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5504868811798096\n",
            "Training Accuracy :0.9116799831390381\n",
            "Validation loss :1.5755112869262695\n",
            "Validation Accuracy :0.8840999603271484\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5480567583847047\n",
            "Training Accuracy :0.9137799739837646\n",
            "Validation loss :1.5699316341400147\n",
            "Validation Accuracy :0.8919000029563904\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5481856478118896\n",
            "Training Accuracy :0.9136399626731873\n",
            "Validation loss :1.5724841548919677\n",
            "Validation Accuracy :0.8869999647140503\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5444033811950684\n",
            "Training Accuracy :0.917959988117218\n",
            "Validation loss :1.5716792755126954\n",
            "Validation Accuracy :0.8890999555587769\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5448954158020018\n",
            "Training Accuracy :0.9169600009918213\n",
            "Validation loss :1.5702060846328736\n",
            "Validation Accuracy :0.8907999992370605\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5447615358352662\n",
            "Training Accuracy :0.9178999662399292\n",
            "Validation loss :1.5712681034088134\n",
            "Validation Accuracy :0.8887999653816223\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5432171501541139\n",
            "Training Accuracy :0.9190799593925476\n",
            "Validation loss :1.5712035961151123\n",
            "Validation Accuracy :0.8899999856948853\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.541941626663208\n",
            "Training Accuracy :0.9199000000953674\n",
            "Validation loss :1.5667701770782472\n",
            "Validation Accuracy :0.8934999704360962\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.541040803642273\n",
            "Training Accuracy :0.9207800030708313\n",
            "Validation loss :1.5676349870681763\n",
            "Validation Accuracy :0.8935999870300293\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5416490383529664\n",
            "Training Accuracy :0.9205199480056763\n",
            "Validation loss :1.5650382261276246\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5403161973571777\n",
            "Training Accuracy :0.9223999977111816\n",
            "Validation loss :1.5665188665390015\n",
            "Validation Accuracy :0.894599974155426\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.53930091255188\n",
            "Training Accuracy :0.9232800006866455\n",
            "Validation loss :1.5689756614685058\n",
            "Validation Accuracy :0.8921999931335449\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.539247753868103\n",
            "Training Accuracy :0.9229199886322021\n",
            "Validation loss :1.566867008972168\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5400059557724\n",
            "Training Accuracy :0.9220999479293823\n",
            "Validation loss :1.56589206905365\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5388979540252685\n",
            "Training Accuracy :0.9232999682426453\n",
            "Validation loss :1.5661694547653198\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.537376950340271\n",
            "Training Accuracy :0.9247199892997742\n",
            "Validation loss :1.564087229537964\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5361217812347412\n",
            "Training Accuracy :0.92631995677948\n",
            "Validation loss :1.5640801761627197\n",
            "Validation Accuracy :0.8968999981880188\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5354586005401611\n",
            "Training Accuracy :0.9267799854278564\n",
            "Validation loss :1.5664485818862914\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5343615602874756\n",
            "Training Accuracy :0.9276399612426758\n",
            "Validation loss :1.566295665359497\n",
            "Validation Accuracy :0.8939999938011169\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5323627797698975\n",
            "Training Accuracy :0.9293799996376038\n",
            "Validation loss :1.5657021728515625\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5333587273788452\n",
            "Training Accuracy :0.9291399717330933\n",
            "Validation loss :1.5668390491485595\n",
            "Validation Accuracy :0.8949999809265137\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.5323608110046387\n",
            "Training Accuracy :0.9295199513435364\n",
            "Validation loss :1.5669321784973145\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.5323018127441406\n",
            "Training Accuracy :0.9301199913024902\n",
            "Validation loss :1.5666165966033936\n",
            "Validation Accuracy :0.8937000036239624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO5hCDfaj_EV",
        "outputId": "838f2395-5f11-49f0-bb53-868b2968badb"
      },
      "source": [
        "early_stop,best_acc.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, array(0.8971, dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zvukfRskFbv"
      },
      "source": [
        "#loading the initial weights for reinitialization while pruning\n",
        "init_weights=torch.load(\"/content/drive/MyDrive/ml project/fashion_lotteryinit\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_SCCtSckRBa"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/fashion_lotterytrain\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE_9F3bjkVOk"
      },
      "source": [
        "from torch.nn.utils import prune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lotRe_1qkZdU",
        "outputId": "ec1ef2a9-8c19-400a-c0c9-3c8995b9a112"
      },
      "source": [
        "#applying the magnitude based pruning with lottery ticket based initializations\n",
        "sparsity=[1]\n",
        "best_acc_list=[0.8971]\n",
        "early_stop_list=[52]\n",
        "for i in range(20):\n",
        "  parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.conv3, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "  )\n",
        "\n",
        "  prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        "  )\n",
        "  #reloading from init weights\n",
        "  sd=model.conv1.state_dict()\n",
        "  sd[\"bias\"]=init_weights.conv1.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=init_weights.conv1.state_dict()['weight']\n",
        "  model.conv1.load_state_dict(sd)\n",
        "\n",
        "  sd=model.conv2.state_dict()\n",
        "  sd[\"bias\"]=init_weights.conv2.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=init_weights.conv2.state_dict()['weight']\n",
        "  model.conv2.load_state_dict(sd)\n",
        "\n",
        "  sd=model.conv3.state_dict()\n",
        "  sd[\"bias\"]=init_weights.conv3.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=init_weights.conv3.state_dict()['weight']\n",
        "  model.conv3.load_state_dict(sd)\n",
        "\n",
        "  sd=model.fc1.state_dict()\n",
        "  sd[\"bias\"]=init_weights.fc1.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=init_weights.fc1.state_dict()['weight']\n",
        "  model.fc1.load_state_dict(sd)\n",
        "\n",
        "  sd=model.fc2.state_dict()\n",
        "  sd[\"bias\"]=init_weights.fc2.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=init_weights.fc2.state_dict()['weight']\n",
        "  model.fc2.load_state_dict(sd)\n",
        "\n",
        "\n",
        "  print(f\"Sparsity={(1-0.2)**(i+1)}\")\n",
        "  \n",
        "  learning_rate = 0.1\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "  crieteria=nn.CrossEntropyLoss()\n",
        "  best_acc=0\n",
        "  early_stop=0\n",
        "  n_epochs=60\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  train_accuracy=[]\n",
        "  val_accuracy=[]\n",
        "  model.train()\n",
        "  for epoch in range(n_epochs):\n",
        "    tr_loss=0\n",
        "    vl_loss=0\n",
        "    print(f\"-----------EPOCH {epoch} ------------------ \")\n",
        "    correct=0\n",
        "    for images, labels in train_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      train = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(train)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tr_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    train_loss.append(tr_loss/len(train_dataset))\n",
        "    train_accuracy.append(correct/len(train_dataset))\n",
        "    print(f\"Training loss :{tr_loss/len(train_dataset)}\")\n",
        "    print(f\"Training Accuracy :{correct/len(train_dataset)}\")\n",
        "    correct=0\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      vl_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "    val_loss.append(vl_loss/len(val_dataset))\n",
        "    val_accuracy.append(correct/len(val_dataset))\n",
        "    print(f\"Validation loss :{vl_loss/len(val_dataset)}\")\n",
        "    print(f\"Validation Accuracy :{correct/len(val_dataset)}\")\n",
        "    if correct/len(val_dataset) > best_acc:\n",
        "      best_acc=correct/len(val_dataset)\n",
        "      early_stop=epoch\n",
        "  best_acc_list.append(best_acc)\n",
        "  early_stop_list.append(early_stop)\n",
        "  sparsity.append((1-0.2)**(i+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training loss :1.5451351054763793\n",
            "Training Accuracy :0.9180600047111511\n",
            "Validation loss :1.5719850458145141\n",
            "Validation Accuracy :0.8887999653816223\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5451307925415039\n",
            "Training Accuracy :0.9180399775505066\n",
            "Validation loss :1.5690555364608765\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5422625478744507\n",
            "Training Accuracy :0.9207800030708313\n",
            "Validation loss :1.5707945922851563\n",
            "Validation Accuracy :0.8906999826431274\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.54071154296875\n",
            "Training Accuracy :0.922819972038269\n",
            "Validation loss :1.5664227119445802\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.542291462173462\n",
            "Training Accuracy :0.9210399985313416\n",
            "Validation loss :1.56792975730896\n",
            "Validation Accuracy :0.8938999772071838\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5390484957504273\n",
            "Training Accuracy :0.9242199659347534\n",
            "Validation loss :1.5658292419433595\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5373820096588136\n",
            "Training Accuracy :0.9255599975585938\n",
            "Validation loss :1.5659605415344238\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5362114394760131\n",
            "Training Accuracy :0.927299976348877\n",
            "Validation loss :1.5656972465515138\n",
            "Validation Accuracy :0.8971999883651733\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5366843546295166\n",
            "Training Accuracy :0.9263399839401245\n",
            "Validation loss :1.5701437866210937\n",
            "Validation Accuracy :0.8922999501228333\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5347814598464966\n",
            "Training Accuracy :0.9279199838638306\n",
            "Validation loss :1.5668232112884521\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.535901393852234\n",
            "Training Accuracy :0.9277600049972534\n",
            "Validation loss :1.569771282196045\n",
            "Validation Accuracy :0.8919000029563904\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5352175846481324\n",
            "Training Accuracy :0.9275999665260315\n",
            "Validation loss :1.5671766609191895\n",
            "Validation Accuracy :0.8939999938011169\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5340095706176757\n",
            "Training Accuracy :0.9288399815559387\n",
            "Validation loss :1.565622306060791\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5333515391540526\n",
            "Training Accuracy :0.9291999936103821\n",
            "Validation loss :1.5661047924041749\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5322933102416991\n",
            "Training Accuracy :0.9306199550628662\n",
            "Validation loss :1.564301298904419\n",
            "Validation Accuracy :0.8981999754905701\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5312730027770995\n",
            "Training Accuracy :0.9318599700927734\n",
            "Validation loss :1.5656336738586425\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5305886835098266\n",
            "Training Accuracy :0.932379961013794\n",
            "Validation loss :1.5663889316558839\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5302429300308227\n",
            "Training Accuracy :0.9327799677848816\n",
            "Validation loss :1.5676386295318603\n",
            "Validation Accuracy :0.8941999673843384\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5305296775817872\n",
            "Training Accuracy :0.9317599534988403\n",
            "Validation loss :1.5679067443847656\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5281291968917847\n",
            "Training Accuracy :0.9345399737358093\n",
            "Validation loss :1.5661767612457276\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5281452144622802\n",
            "Training Accuracy :0.9351199865341187\n",
            "Validation loss :1.5682558712005614\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5284796437835693\n",
            "Training Accuracy :0.9340999722480774\n",
            "Validation loss :1.5701613189697265\n",
            "Validation Accuracy :0.8902999758720398\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5271979259872437\n",
            "Training Accuracy :0.935259997844696\n",
            "Validation loss :1.5674364276885986\n",
            "Validation Accuracy :0.8924999833106995\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5268113372421264\n",
            "Training Accuracy :0.9360399842262268\n",
            "Validation loss :1.56514893989563\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5270561685943604\n",
            "Training Accuracy :0.9352999925613403\n",
            "Validation loss :1.57260598487854\n",
            "Validation Accuracy :0.8878999948501587\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5263794362258911\n",
            "Training Accuracy :0.9364799857139587\n",
            "Validation loss :1.5666172061920165\n",
            "Validation Accuracy :0.8944999575614929\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5245208032608033\n",
            "Training Accuracy :0.9382599592208862\n",
            "Validation loss :1.5638377586364747\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5248075827789307\n",
            "Training Accuracy :0.9381799697875977\n",
            "Validation loss :1.5666843467712401\n",
            "Validation Accuracy :0.8937999606132507\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5233244467163085\n",
            "Training Accuracy :0.9398399591445923\n",
            "Validation loss :1.5650969329833984\n",
            "Validation Accuracy :0.8960999846458435\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5226445664215087\n",
            "Training Accuracy :0.9404199719429016\n",
            "Validation loss :1.566079347229004\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5237695562362672\n",
            "Training Accuracy :0.9392399787902832\n",
            "Validation loss :1.5657307300567627\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5233561832427978\n",
            "Training Accuracy :0.9391599893569946\n",
            "Validation loss :1.5658493461608887\n",
            "Validation Accuracy :0.8939999938011169\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.521674098930359\n",
            "Training Accuracy :0.9409599900245667\n",
            "Validation loss :1.5640556060791015\n",
            "Validation Accuracy :0.8977999687194824\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5219739126968383\n",
            "Training Accuracy :0.9406999945640564\n",
            "Validation loss :1.5648079216003419\n",
            "Validation Accuracy :0.8959999680519104\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5219218976211548\n",
            "Training Accuracy :0.940559983253479\n",
            "Validation loss :1.5635483596801758\n",
            "Validation Accuracy :0.8974999785423279\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.52120799659729\n",
            "Training Accuracy :0.9417399764060974\n",
            "Validation loss :1.5654938499450683\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.5206116555023192\n",
            "Training Accuracy :0.9422599673271179\n",
            "Validation loss :1.56504047164917\n",
            "Validation Accuracy :0.8955999612808228\n",
            "Sparsity=0.3276800000000001\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.038091841468811\n",
            "Training Accuracy :0.4904399812221527\n",
            "Validation loss :1.7452839725494385\n",
            "Validation Accuracy :0.7295999526977539\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7117928295516969\n",
            "Training Accuracy :0.7575199604034424\n",
            "Validation loss :1.6819601364135741\n",
            "Validation Accuracy :0.7860999703407288\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6648801892852783\n",
            "Training Accuracy :0.8040800094604492\n",
            "Validation loss :1.6456672019958496\n",
            "Validation Accuracy :0.8222000002861023\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6377222847747803\n",
            "Training Accuracy :0.8293399810791016\n",
            "Validation loss :1.6275145805358886\n",
            "Validation Accuracy :0.8402999639511108\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6191871295547486\n",
            "Training Accuracy :0.8455199599266052\n",
            "Validation loss :1.6191980445861816\n",
            "Validation Accuracy :0.8459999561309814\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.606298145980835\n",
            "Training Accuracy :0.8580799698829651\n",
            "Validation loss :1.6077862586975098\n",
            "Validation Accuracy :0.8560999631881714\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5977653633880615\n",
            "Training Accuracy :0.8664799928665161\n",
            "Validation loss :1.604498770713806\n",
            "Validation Accuracy :0.8587999939918518\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5923418026351928\n",
            "Training Accuracy :0.8714199662208557\n",
            "Validation loss :1.599624066543579\n",
            "Validation Accuracy :0.8637999892234802\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5858865781021119\n",
            "Training Accuracy :0.8782199621200562\n",
            "Validation loss :1.5928674114227295\n",
            "Validation Accuracy :0.871399998664856\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5787306525421143\n",
            "Training Accuracy :0.8855599761009216\n",
            "Validation loss :1.5864399742126465\n",
            "Validation Accuracy :0.8774999976158142\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5725359311676026\n",
            "Training Accuracy :0.8919399976730347\n",
            "Validation loss :1.5875316055297852\n",
            "Validation Accuracy :0.8759999871253967\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5687070586395264\n",
            "Training Accuracy :0.895799994468689\n",
            "Validation loss :1.585140873336792\n",
            "Validation Accuracy :0.876800000667572\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.5647293124771118\n",
            "Training Accuracy :0.899679958820343\n",
            "Validation loss :1.5805495656967163\n",
            "Validation Accuracy :0.8812999725341797\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.56181303691864\n",
            "Training Accuracy :0.9023999571800232\n",
            "Validation loss :1.577417974281311\n",
            "Validation Accuracy :0.884399950504303\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.5589343832397462\n",
            "Training Accuracy :0.9045599699020386\n",
            "Validation loss :1.576301436805725\n",
            "Validation Accuracy :0.8865000009536743\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.5566416590118408\n",
            "Training Accuracy :0.9074400067329407\n",
            "Validation loss :1.5775937671661378\n",
            "Validation Accuracy :0.884399950504303\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.5564916579437256\n",
            "Training Accuracy :0.9070199728012085\n",
            "Validation loss :1.5759959495544433\n",
            "Validation Accuracy :0.8865999579429626\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.551874726791382\n",
            "Training Accuracy :0.9119199514389038\n",
            "Validation loss :1.5732164058685303\n",
            "Validation Accuracy :0.8885999917984009\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.5498352143096923\n",
            "Training Accuracy :0.9136799573898315\n",
            "Validation loss :1.5743998491287232\n",
            "Validation Accuracy :0.887999951839447\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.5472997623443603\n",
            "Training Accuracy :0.916700005531311\n",
            "Validation loss :1.5693500284194946\n",
            "Validation Accuracy :0.8924999833106995\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5454980744171143\n",
            "Training Accuracy :0.9177999496459961\n",
            "Validation loss :1.5709224979400636\n",
            "Validation Accuracy :0.8908999562263489\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.5452903051376343\n",
            "Training Accuracy :0.9186199903488159\n",
            "Validation loss :1.5708154266357421\n",
            "Validation Accuracy :0.8906999826431274\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.5430575645828246\n",
            "Training Accuracy :0.9203799962997437\n",
            "Validation loss :1.5669752681732179\n",
            "Validation Accuracy :0.894599974155426\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.5404397506713867\n",
            "Training Accuracy :0.9236999750137329\n",
            "Validation loss :1.5715747327804566\n",
            "Validation Accuracy :0.8905999660491943\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.54006696434021\n",
            "Training Accuracy :0.924019992351532\n",
            "Validation loss :1.5699444221496581\n",
            "Validation Accuracy :0.8917999863624573\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5387840185165405\n",
            "Training Accuracy :0.9251399636268616\n",
            "Validation loss :1.5664595798492431\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5372512739944457\n",
            "Training Accuracy :0.9265999794006348\n",
            "Validation loss :1.5676248008728026\n",
            "Validation Accuracy :0.8932999968528748\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.536836519317627\n",
            "Training Accuracy :0.9266199469566345\n",
            "Validation loss :1.5672701755523681\n",
            "Validation Accuracy :0.8939999938011169\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5358496141815186\n",
            "Training Accuracy :0.927899956703186\n",
            "Validation loss :1.5696882469177247\n",
            "Validation Accuracy :0.890999972820282\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5342101770401\n",
            "Training Accuracy :0.9289999604225159\n",
            "Validation loss :1.5705026248931884\n",
            "Validation Accuracy :0.8908999562263489\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.533801464881897\n",
            "Training Accuracy :0.9295799732208252\n",
            "Validation loss :1.5672511688232422\n",
            "Validation Accuracy :0.8939999938011169\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5324266249465943\n",
            "Training Accuracy :0.9311400055885315\n",
            "Validation loss :1.569877784729004\n",
            "Validation Accuracy :0.8912000060081482\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5322066485977173\n",
            "Training Accuracy :0.9313399791717529\n",
            "Validation loss :1.5669629726409913\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5308027805328368\n",
            "Training Accuracy :0.9329999685287476\n",
            "Validation loss :1.5688689315795898\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.529249172744751\n",
            "Training Accuracy :0.9345600008964539\n",
            "Validation loss :1.5693537227630616\n",
            "Validation Accuracy :0.8915999531745911\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5291723332977294\n",
            "Training Accuracy :0.9339599609375\n",
            "Validation loss :1.5658685596466064\n",
            "Validation Accuracy :0.8960999846458435\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5278760551834107\n",
            "Training Accuracy :0.9358399510383606\n",
            "Validation loss :1.5676466972351075\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5281180420684815\n",
            "Training Accuracy :0.9352999925613403\n",
            "Validation loss :1.5666307350158692\n",
            "Validation Accuracy :0.8949999809265137\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5285311247634887\n",
            "Training Accuracy :0.9347399473190308\n",
            "Validation loss :1.5667332069396973\n",
            "Validation Accuracy :0.8941999673843384\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5261132730865479\n",
            "Training Accuracy :0.9372599720954895\n",
            "Validation loss :1.5672410243988038\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5261749835205078\n",
            "Training Accuracy :0.9371399879455566\n",
            "Validation loss :1.5652514572143554\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.525760281715393\n",
            "Training Accuracy :0.937279999256134\n",
            "Validation loss :1.5659186965942382\n",
            "Validation Accuracy :0.8974999785423279\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5252650840759276\n",
            "Training Accuracy :0.9376800060272217\n",
            "Validation loss :1.5699778106689453\n",
            "Validation Accuracy :0.8919000029563904\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5243239079284667\n",
            "Training Accuracy :0.9388799667358398\n",
            "Validation loss :1.5652288993835448\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5244460844802856\n",
            "Training Accuracy :0.9386799931526184\n",
            "Validation loss :1.5670052005767823\n",
            "Validation Accuracy :0.8935999870300293\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.523660966796875\n",
            "Training Accuracy :0.939579963684082\n",
            "Validation loss :1.56534312210083\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5219498775863647\n",
            "Training Accuracy :0.9411599636077881\n",
            "Validation loss :1.56554010887146\n",
            "Validation Accuracy :0.8962000012397766\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5215974465179443\n",
            "Training Accuracy :0.94159996509552\n",
            "Validation loss :1.5641832221984864\n",
            "Validation Accuracy :0.897599995136261\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5220792723846435\n",
            "Training Accuracy :0.9411199688911438\n",
            "Validation loss :1.5634371452331544\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5215938120269776\n",
            "Training Accuracy :0.9416399598121643\n",
            "Validation loss :1.5666404975891113\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5208234209823608\n",
            "Training Accuracy :0.9423199892044067\n",
            "Validation loss :1.5657241725921631\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5202120783615112\n",
            "Training Accuracy :0.9429399967193604\n",
            "Validation loss :1.5648336334228516\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5202985847854613\n",
            "Training Accuracy :0.9429799914360046\n",
            "Validation loss :1.5649808452606202\n",
            "Validation Accuracy :0.8966999650001526\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5197314408493041\n",
            "Training Accuracy :0.9434199929237366\n",
            "Validation loss :1.5652577976226807\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5189503675460816\n",
            "Training Accuracy :0.9438999891281128\n",
            "Validation loss :1.5639845252990723\n",
            "Validation Accuracy :0.8965999484062195\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5190326757049561\n",
            "Training Accuracy :0.9440599679946899\n",
            "Validation loss :1.564330696105957\n",
            "Validation Accuracy :0.8962000012397766\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5195434636306762\n",
            "Training Accuracy :0.9436399936676025\n",
            "Validation loss :1.5650541706085206\n",
            "Validation Accuracy :0.8955999612808228\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5189192415618897\n",
            "Training Accuracy :0.9439199566841125\n",
            "Validation loss :1.5647067279815674\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.518954333114624\n",
            "Training Accuracy :0.9438599944114685\n",
            "Validation loss :1.5637981678009034\n",
            "Validation Accuracy :0.8971999883651733\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.5169603175354003\n",
            "Training Accuracy :0.9460399746894836\n",
            "Validation loss :1.56465592918396\n",
            "Validation Accuracy :0.8977999687194824\n",
            "Sparsity=0.2621440000000001\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.0821654567718504\n",
            "Training Accuracy :0.4412599802017212\n",
            "Validation loss :1.7648288902282714\n",
            "Validation Accuracy :0.7145000100135803\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7216763698577882\n",
            "Training Accuracy :0.750059962272644\n",
            "Validation loss :1.695931980895996\n",
            "Validation Accuracy :0.7731999754905701\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6714900324249267\n",
            "Training Accuracy :0.7977199554443359\n",
            "Validation loss :1.6554294645309449\n",
            "Validation Accuracy :0.8168999552726746\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6390483813476562\n",
            "Training Accuracy :0.8287799954414368\n",
            "Validation loss :1.6288104804992676\n",
            "Validation Accuracy :0.8389999866485596\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.619901678237915\n",
            "Training Accuracy :0.8466799855232239\n",
            "Validation loss :1.6193995296478272\n",
            "Validation Accuracy :0.8434000015258789\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.605341149559021\n",
            "Training Accuracy :0.8599199652671814\n",
            "Validation loss :1.6087550525665284\n",
            "Validation Accuracy :0.8549000024795532\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.5978218628311158\n",
            "Training Accuracy :0.8666799664497375\n",
            "Validation loss :1.601206004524231\n",
            "Validation Accuracy :0.8613999485969543\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5902166902923585\n",
            "Training Accuracy :0.8742199540138245\n",
            "Validation loss :1.5933642601013183\n",
            "Validation Accuracy :0.8700000047683716\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5842301333999633\n",
            "Training Accuracy :0.8797999620437622\n",
            "Validation loss :1.5883711908340454\n",
            "Validation Accuracy :0.875499963760376\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5775810247421265\n",
            "Training Accuracy :0.8865799903869629\n",
            "Validation loss :1.5861700273513795\n",
            "Validation Accuracy :0.8768999576568604\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5699357118225097\n",
            "Training Accuracy :0.8953799605369568\n",
            "Validation loss :1.5842719926834106\n",
            "Validation Accuracy :0.8797000050544739\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5653059870147705\n",
            "Training Accuracy :0.8996399641036987\n",
            "Validation loss :1.5819954885482788\n",
            "Validation Accuracy :0.8811999559402466\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.5628281901550294\n",
            "Training Accuracy :0.9014599919319153\n",
            "Validation loss :1.5852622793197633\n",
            "Validation Accuracy :0.8768999576568604\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.5600965128707887\n",
            "Training Accuracy :0.903719961643219\n",
            "Validation loss :1.5786049825668336\n",
            "Validation Accuracy :0.8840000033378601\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.5569281552886962\n",
            "Training Accuracy :0.9069199562072754\n",
            "Validation loss :1.5753765659332275\n",
            "Validation Accuracy :0.8870999813079834\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.5537014630508423\n",
            "Training Accuracy :0.9100199937820435\n",
            "Validation loss :1.5726987087249755\n",
            "Validation Accuracy :0.8902999758720398\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.5518794665527345\n",
            "Training Accuracy :0.9124199748039246\n",
            "Validation loss :1.572992778968811\n",
            "Validation Accuracy :0.8894999623298645\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.5499295618057252\n",
            "Training Accuracy :0.914139986038208\n",
            "Validation loss :1.5728662406921388\n",
            "Validation Accuracy :0.8896999955177307\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.5477427227020264\n",
            "Training Accuracy :0.9160799980163574\n",
            "Validation loss :1.5702124849319459\n",
            "Validation Accuracy :0.8914999961853027\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.5450232668685913\n",
            "Training Accuracy :0.9186599850654602\n",
            "Validation loss :1.5700233238220216\n",
            "Validation Accuracy :0.8912999629974365\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5439886936187743\n",
            "Training Accuracy :0.9200599789619446\n",
            "Validation loss :1.5702399936676026\n",
            "Validation Accuracy :0.8912999629974365\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.541787897377014\n",
            "Training Accuracy :0.9223600029945374\n",
            "Validation loss :1.5691659152984618\n",
            "Validation Accuracy :0.8926999568939209\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.539723205871582\n",
            "Training Accuracy :0.9240599870681763\n",
            "Validation loss :1.5685846431732178\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.538747660446167\n",
            "Training Accuracy :0.9252399802207947\n",
            "Validation loss :1.569408925628662\n",
            "Validation Accuracy :0.8925999999046326\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5365999704742432\n",
            "Training Accuracy :0.9274199604988098\n",
            "Validation loss :1.5670570869445801\n",
            "Validation Accuracy :0.8941999673843384\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5358515930175782\n",
            "Training Accuracy :0.9280799627304077\n",
            "Validation loss :1.5674916561126708\n",
            "Validation Accuracy :0.8949999809265137\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5344713372039795\n",
            "Training Accuracy :0.9294399619102478\n",
            "Validation loss :1.565886162185669\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.532924881210327\n",
            "Training Accuracy :0.9313199520111084\n",
            "Validation loss :1.5660723114013673\n",
            "Validation Accuracy :0.8956999778747559\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5321293104553222\n",
            "Training Accuracy :0.9320799708366394\n",
            "Validation loss :1.5653362812042235\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.532814044342041\n",
            "Training Accuracy :0.9309599995613098\n",
            "Validation loss :1.5653262928009033\n",
            "Validation Accuracy :0.8959999680519104\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5311603066253663\n",
            "Training Accuracy :0.9325000047683716\n",
            "Validation loss :1.5650335208892823\n",
            "Validation Accuracy :0.8965999484062195\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5298834313201903\n",
            "Training Accuracy :0.9339399933815002\n",
            "Validation loss :1.5672528633117675\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5295009986114503\n",
            "Training Accuracy :0.9340599775314331\n",
            "Validation loss :1.5653015048980712\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5303127083587647\n",
            "Training Accuracy :0.9332799911499023\n",
            "Validation loss :1.5668037044525147\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5273328455352784\n",
            "Training Accuracy :0.9361000061035156\n",
            "Validation loss :1.5640672412872314\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5255957746124267\n",
            "Training Accuracy :0.9379599690437317\n",
            "Validation loss :1.567732675933838\n",
            "Validation Accuracy :0.8930000066757202\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5262242902374268\n",
            "Training Accuracy :0.9372599720954895\n",
            "Validation loss :1.566181007385254\n",
            "Validation Accuracy :0.8956999778747559\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5265649173355103\n",
            "Training Accuracy :0.9370399713516235\n",
            "Validation loss :1.5647068378448485\n",
            "Validation Accuracy :0.8967999815940857\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5241083768081665\n",
            "Training Accuracy :0.9393199682235718\n",
            "Validation loss :1.5630945503234863\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5239668017959596\n",
            "Training Accuracy :0.9398799538612366\n",
            "Validation loss :1.5640665130615234\n",
            "Validation Accuracy :0.8973999619483948\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5245424063873292\n",
            "Training Accuracy :0.9387999773025513\n",
            "Validation loss :1.5633452056884765\n",
            "Validation Accuracy :0.8991000056266785\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5239055221176148\n",
            "Training Accuracy :0.9395999908447266\n",
            "Validation loss :1.5627488922119142\n",
            "Validation Accuracy :0.8991000056266785\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.521684984703064\n",
            "Training Accuracy :0.9422599673271179\n",
            "Validation loss :1.5650063472747802\n",
            "Validation Accuracy :0.8967999815940857\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5220430447769164\n",
            "Training Accuracy :0.9414999485015869\n",
            "Validation loss :1.5643293102264404\n",
            "Validation Accuracy :0.8968999981880188\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.521566206970215\n",
            "Training Accuracy :0.9420199990272522\n",
            "Validation loss :1.563409141921997\n",
            "Validation Accuracy :0.8985999822616577\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5203649726104735\n",
            "Training Accuracy :0.9431599974632263\n",
            "Validation loss :1.565934614944458\n",
            "Validation Accuracy :0.8948999643325806\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5206806160736084\n",
            "Training Accuracy :0.9423399567604065\n",
            "Validation loss :1.566097974395752\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5201591919326782\n",
            "Training Accuracy :0.9433799982070923\n",
            "Validation loss :1.5662332080841064\n",
            "Validation Accuracy :0.8959999680519104\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5201021518325806\n",
            "Training Accuracy :0.9432599544525146\n",
            "Validation loss :1.5629949295043946\n",
            "Validation Accuracy :0.8992999792098999\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5193284590148926\n",
            "Training Accuracy :0.9437999725341797\n",
            "Validation loss :1.5638866527557373\n",
            "Validation Accuracy :0.8968999981880188\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5185949659729003\n",
            "Training Accuracy :0.9445599913597107\n",
            "Validation loss :1.5626693996429444\n",
            "Validation Accuracy :0.8987999558448792\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5196153714752196\n",
            "Training Accuracy :0.9437599778175354\n",
            "Validation loss :1.566947592163086\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5189240775299073\n",
            "Training Accuracy :0.9443999528884888\n",
            "Validation loss :1.5630196537017822\n",
            "Validation Accuracy :0.8981999754905701\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.518331585960388\n",
            "Training Accuracy :0.9450799822807312\n",
            "Validation loss :1.5667830081939698\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5181268650817872\n",
            "Training Accuracy :0.9449599981307983\n",
            "Validation loss :1.5639051197052003\n",
            "Validation Accuracy :0.897599995136261\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5173054618835449\n",
            "Training Accuracy :0.9458799958229065\n",
            "Validation loss :1.5639303241729736\n",
            "Validation Accuracy :0.8977999687194824\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.516148837890625\n",
            "Training Accuracy :0.9467399716377258\n",
            "Validation loss :1.563613493347168\n",
            "Validation Accuracy :0.8973999619483948\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5168350120925904\n",
            "Training Accuracy :0.9462599754333496\n",
            "Validation loss :1.564680676651001\n",
            "Validation Accuracy :0.8962000012397766\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.5161896968078614\n",
            "Training Accuracy :0.946940004825592\n",
            "Validation loss :1.562879365158081\n",
            "Validation Accuracy :0.8987999558448792\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.5150042097091674\n",
            "Training Accuracy :0.9482599496841431\n",
            "Validation loss :1.564588808441162\n",
            "Validation Accuracy :0.8960999846458435\n",
            "Sparsity=0.20971520000000007\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.1473666231918336\n",
            "Training Accuracy :0.3810199797153473\n",
            "Validation loss :1.8036881107330323\n",
            "Validation Accuracy :0.69159996509552\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7349313088989258\n",
            "Training Accuracy :0.7412199974060059\n",
            "Validation loss :1.6961229803085327\n",
            "Validation Accuracy :0.7746999859809875\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6847325128936768\n",
            "Training Accuracy :0.7820999622344971\n",
            "Validation loss :1.6667561050415038\n",
            "Validation Accuracy :0.7990999817848206\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6541396823883057\n",
            "Training Accuracy :0.8151800036430359\n",
            "Validation loss :1.6385799911499024\n",
            "Validation Accuracy :0.8297999501228333\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6292902949142456\n",
            "Training Accuracy :0.8378599882125854\n",
            "Validation loss :1.6221087240219116\n",
            "Validation Accuracy :0.8442999720573425\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6132590674591065\n",
            "Training Accuracy :0.8524999618530273\n",
            "Validation loss :1.6108810060501098\n",
            "Validation Accuracy :0.8531999588012695\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6021821401977538\n",
            "Training Accuracy :0.8627600073814392\n",
            "Validation loss :1.605922970199585\n",
            "Validation Accuracy :0.858199954032898\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.5933427405548095\n",
            "Training Accuracy :0.8714399933815002\n",
            "Validation loss :1.6046350763320922\n",
            "Validation Accuracy :0.859499990940094\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5877370417785646\n",
            "Training Accuracy :0.8770999908447266\n",
            "Validation loss :1.5972832941055297\n",
            "Validation Accuracy :0.8672999739646912\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.5819724501419068\n",
            "Training Accuracy :0.8830599784851074\n",
            "Validation loss :1.5902704404830932\n",
            "Validation Accuracy :0.8740999698638916\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.5756688972091675\n",
            "Training Accuracy :0.8890199661254883\n",
            "Validation loss :1.5854921447753907\n",
            "Validation Accuracy :0.8769999742507935\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5706828801727295\n",
            "Training Accuracy :0.8935199975967407\n",
            "Validation loss :1.581580355834961\n",
            "Validation Accuracy :0.8819999694824219\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.5651402396011354\n",
            "Training Accuracy :0.8993799686431885\n",
            "Validation loss :1.5797156534194947\n",
            "Validation Accuracy :0.8847999572753906\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.5628359830474854\n",
            "Training Accuracy :0.9010999798774719\n",
            "Validation loss :1.577787109375\n",
            "Validation Accuracy :0.8868999481201172\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.5600491956329345\n",
            "Training Accuracy :0.9042399525642395\n",
            "Validation loss :1.5771336694717408\n",
            "Validation Accuracy :0.8865000009536743\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.5569292398452759\n",
            "Training Accuracy :0.9070599675178528\n",
            "Validation loss :1.574768076133728\n",
            "Validation Accuracy :0.8872999548912048\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.5544289017486572\n",
            "Training Accuracy :0.9092199802398682\n",
            "Validation loss :1.5757021368026733\n",
            "Validation Accuracy :0.8863999843597412\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.5532461492538452\n",
            "Training Accuracy :0.9110199809074402\n",
            "Validation loss :1.574332534980774\n",
            "Validation Accuracy :0.8876999616622925\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.5498293905639648\n",
            "Training Accuracy :0.9143999814987183\n",
            "Validation loss :1.5704137422561646\n",
            "Validation Accuracy :0.8932999968528748\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.5503847688674928\n",
            "Training Accuracy :0.9133599996566772\n",
            "Validation loss :1.5727108661651612\n",
            "Validation Accuracy :0.8894000053405762\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5477552642822265\n",
            "Training Accuracy :0.9160400032997131\n",
            "Validation loss :1.572764214706421\n",
            "Validation Accuracy :0.8901000022888184\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.5458494929122926\n",
            "Training Accuracy :0.9178599715232849\n",
            "Validation loss :1.5693924270629882\n",
            "Validation Accuracy :0.8912999629974365\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.5436549101257324\n",
            "Training Accuracy :0.9202999472618103\n",
            "Validation loss :1.5713268585205078\n",
            "Validation Accuracy :0.8889999985694885\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.5422580419158936\n",
            "Training Accuracy :0.9214999675750732\n",
            "Validation loss :1.5697745250701904\n",
            "Validation Accuracy :0.8921999931335449\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5410622407913208\n",
            "Training Accuracy :0.9229799509048462\n",
            "Validation loss :1.5679025074005126\n",
            "Validation Accuracy :0.8937000036239624\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5393071995162964\n",
            "Training Accuracy :0.9248200058937073\n",
            "Validation loss :1.5669102516174316\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5377969515609742\n",
            "Training Accuracy :0.9262399673461914\n",
            "Validation loss :1.5661687572479248\n",
            "Validation Accuracy :0.8962999582290649\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.5368113939666748\n",
            "Training Accuracy :0.9272799491882324\n",
            "Validation loss :1.5689872299194336\n",
            "Validation Accuracy :0.8916999697685242\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5356554169082641\n",
            "Training Accuracy :0.9281999468803406\n",
            "Validation loss :1.567253387069702\n",
            "Validation Accuracy :0.8948999643325806\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5342206314468383\n",
            "Training Accuracy :0.9297399520874023\n",
            "Validation loss :1.567837931060791\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.532734772796631\n",
            "Training Accuracy :0.9313599467277527\n",
            "Validation loss :1.5667480297088623\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5321350074005127\n",
            "Training Accuracy :0.9312199950218201\n",
            "Validation loss :1.5672429149627685\n",
            "Validation Accuracy :0.8938999772071838\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5312352822113038\n",
            "Training Accuracy :0.9329999685287476\n",
            "Validation loss :1.5652658962249757\n",
            "Validation Accuracy :0.8981999754905701\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5304070485687256\n",
            "Training Accuracy :0.9337799549102783\n",
            "Validation loss :1.5655120334625243\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.528526021232605\n",
            "Training Accuracy :0.9356799721717834\n",
            "Validation loss :1.567490478515625\n",
            "Validation Accuracy :0.8942999839782715\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5276794342803954\n",
            "Training Accuracy :0.9361599683761597\n",
            "Validation loss :1.5677701385498046\n",
            "Validation Accuracy :0.892799973487854\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5280420051193238\n",
            "Training Accuracy :0.9356799721717834\n",
            "Validation loss :1.565665888595581\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5263490927505494\n",
            "Training Accuracy :0.9376199841499329\n",
            "Validation loss :1.5656381622314453\n",
            "Validation Accuracy :0.8959999680519104\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5260888933563233\n",
            "Training Accuracy :0.9376199841499329\n",
            "Validation loss :1.5642309505462646\n",
            "Validation Accuracy :0.8967999815940857\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5245434175491333\n",
            "Training Accuracy :0.9388799667358398\n",
            "Validation loss :1.5641859279632568\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.524824010810852\n",
            "Training Accuracy :0.9387799501419067\n",
            "Validation loss :1.5622995666503907\n",
            "Validation Accuracy :0.8999999761581421\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5238106630706787\n",
            "Training Accuracy :0.9398199915885925\n",
            "Validation loss :1.5649989303588867\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5230832580566407\n",
            "Training Accuracy :0.9406799674034119\n",
            "Validation loss :1.5650633655548096\n",
            "Validation Accuracy :0.8971999883651733\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5230552986526489\n",
            "Training Accuracy :0.9406200051307678\n",
            "Validation loss :1.5656194969177246\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5223095085906981\n",
            "Training Accuracy :0.9419399499893188\n",
            "Validation loss :1.5673183181762695\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5223064503097534\n",
            "Training Accuracy :0.9412999749183655\n",
            "Validation loss :1.5646278568267822\n",
            "Validation Accuracy :0.8953999876976013\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5222910471343993\n",
            "Training Accuracy :0.9408199787139893\n",
            "Validation loss :1.5637830600738525\n",
            "Validation Accuracy :0.897599995136261\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.522837914237976\n",
            "Training Accuracy :0.9407199621200562\n",
            "Validation loss :1.5633922733306884\n",
            "Validation Accuracy :0.898099958896637\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.521484342880249\n",
            "Training Accuracy :0.9418799877166748\n",
            "Validation loss :1.5666099197387695\n",
            "Validation Accuracy :0.8938999772071838\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.520212301673889\n",
            "Training Accuracy :0.9433799982070923\n",
            "Validation loss :1.5642414848327637\n",
            "Validation Accuracy :0.8964999914169312\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.520531146659851\n",
            "Training Accuracy :0.9429599642753601\n",
            "Validation loss :1.5638910537719726\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5202361770248414\n",
            "Training Accuracy :0.9430399537086487\n",
            "Validation loss :1.5658305110931396\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5189318818283082\n",
            "Training Accuracy :0.9444399476051331\n",
            "Validation loss :1.5640881561279296\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5207734344100952\n",
            "Training Accuracy :0.9428399801254272\n",
            "Validation loss :1.5650518283843995\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5186715661621093\n",
            "Training Accuracy :0.944599986076355\n",
            "Validation loss :1.5646409313201903\n",
            "Validation Accuracy :0.8962999582290649\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5186640924835204\n",
            "Training Accuracy :0.9447999596595764\n",
            "Validation loss :1.5642315254211425\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5176290236663819\n",
            "Training Accuracy :0.9456999897956848\n",
            "Validation loss :1.5645045532226562\n",
            "Validation Accuracy :0.8960999846458435\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5181941979598998\n",
            "Training Accuracy :0.9450399875640869\n",
            "Validation loss :1.5658868923187257\n",
            "Validation Accuracy :0.895799994468689\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.516805602798462\n",
            "Training Accuracy :0.9463399648666382\n",
            "Validation loss :1.5638262195587158\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.516924870185852\n",
            "Training Accuracy :0.9462599754333496\n",
            "Validation loss :1.5645702880859376\n",
            "Validation Accuracy :0.8967999815940857\n",
            "Sparsity=0.1677721600000001\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.1962758559799194\n",
            "Training Accuracy :0.3018999993801117\n",
            "Validation loss :1.8684809995651246\n",
            "Validation Accuracy :0.640500009059906\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.7558170278167724\n",
            "Training Accuracy :0.7242599725723267\n",
            "Validation loss :1.7070100271224975\n",
            "Validation Accuracy :0.7617999911308289\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.6902732541275025\n",
            "Training Accuracy :0.777239978313446\n",
            "Validation loss :1.6737836978912353\n",
            "Validation Accuracy :0.793999969959259\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6605949422454833\n",
            "Training Accuracy :0.8088200092315674\n",
            "Validation loss :1.643112348175049\n",
            "Validation Accuracy :0.8260999917984009\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6331660080718995\n",
            "Training Accuracy :0.8347399830818176\n",
            "Validation loss :1.623164624977112\n",
            "Validation Accuracy :0.8432999849319458\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.617001925163269\n",
            "Training Accuracy :0.8497599959373474\n",
            "Validation loss :1.615609997177124\n",
            "Validation Accuracy :0.8513000011444092\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6054795304870606\n",
            "Training Accuracy :0.8600199818611145\n",
            "Validation loss :1.602813961982727\n",
            "Validation Accuracy :0.8606999516487122\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.595550443496704\n",
            "Training Accuracy :0.8692399859428406\n",
            "Validation loss :1.5988957628250122\n",
            "Validation Accuracy :0.8637999892234802\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.5895927196884154\n",
            "Training Accuracy :0.8746799826622009\n",
            "Validation loss :1.5938547315597533\n",
            "Validation Accuracy :0.8704999685287476\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.582928943939209\n",
            "Training Accuracy :0.8818999528884888\n",
            "Validation loss :1.5913469825744628\n",
            "Validation Accuracy :0.8729999661445618\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.576959068069458\n",
            "Training Accuracy :0.8877399563789368\n",
            "Validation loss :1.5883586391448974\n",
            "Validation Accuracy :0.8752999901771545\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.5711842259216309\n",
            "Training Accuracy :0.8940199613571167\n",
            "Validation loss :1.587046556854248\n",
            "Validation Accuracy :0.8763999938964844\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.5684388164520264\n",
            "Training Accuracy :0.8962799906730652\n",
            "Validation loss :1.579560969734192\n",
            "Validation Accuracy :0.8828999996185303\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.5628345653152467\n",
            "Training Accuracy :0.9017399549484253\n",
            "Validation loss :1.5760349782943726\n",
            "Validation Accuracy :0.8873999714851379\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.5604793147277831\n",
            "Training Accuracy :0.9039199948310852\n",
            "Validation loss :1.5773794961929322\n",
            "Validation Accuracy :0.885699987411499\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.5569238401031493\n",
            "Training Accuracy :0.9077000021934509\n",
            "Validation loss :1.5740656642913817\n",
            "Validation Accuracy :0.8894000053405762\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.5549826709365844\n",
            "Training Accuracy :0.9092599749565125\n",
            "Validation loss :1.5725460460662841\n",
            "Validation Accuracy :0.8896999955177307\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.5521826372146605\n",
            "Training Accuracy :0.91239994764328\n",
            "Validation loss :1.5753163959503174\n",
            "Validation Accuracy :0.8880999684333801\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.5498381687545777\n",
            "Training Accuracy :0.9145999550819397\n",
            "Validation loss :1.5742927097320556\n",
            "Validation Accuracy :0.8877999782562256\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.5481763793945313\n",
            "Training Accuracy :0.916379988193512\n",
            "Validation loss :1.5735896808624268\n",
            "Validation Accuracy :0.8884999752044678\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5468872836685181\n",
            "Training Accuracy :0.9174399971961975\n",
            "Validation loss :1.5718912799835205\n",
            "Validation Accuracy :0.8895999789237976\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.5448838161468506\n",
            "Training Accuracy :0.919219970703125\n",
            "Validation loss :1.56872535572052\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.5434491567230224\n",
            "Training Accuracy :0.921019971370697\n",
            "Validation loss :1.571674178314209\n",
            "Validation Accuracy :0.889799952507019\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.5424731062316894\n",
            "Training Accuracy :0.9213599562644958\n",
            "Validation loss :1.5703679603576661\n",
            "Validation Accuracy :0.8898999691009521\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5408358908081055\n",
            "Training Accuracy :0.9236199855804443\n",
            "Validation loss :1.568617234992981\n",
            "Validation Accuracy :0.8935999870300293\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5408578833389281\n",
            "Training Accuracy :0.9234799742698669\n",
            "Validation loss :1.5702597282409667\n",
            "Validation Accuracy :0.8914999961853027\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5392880397033692\n",
            "Training Accuracy :0.9244599938392639\n",
            "Validation loss :1.568543653869629\n",
            "Validation Accuracy :0.8930999636650085\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.5375107977676392\n",
            "Training Accuracy :0.9262999892234802\n",
            "Validation loss :1.5670189323425292\n",
            "Validation Accuracy :0.8940999507904053\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5359753520584107\n",
            "Training Accuracy :0.9274799823760986\n",
            "Validation loss :1.5658079444885253\n",
            "Validation Accuracy :0.8950999975204468\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5350475438690185\n",
            "Training Accuracy :0.928879976272583\n",
            "Validation loss :1.5666513328552245\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5336967447662353\n",
            "Training Accuracy :0.930359959602356\n",
            "Validation loss :1.5677984134674072\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5323088646697998\n",
            "Training Accuracy :0.9316999912261963\n",
            "Validation loss :1.5700448978424073\n",
            "Validation Accuracy :0.8919000029563904\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5325412929153441\n",
            "Training Accuracy :0.9312799572944641\n",
            "Validation loss :1.567431377029419\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5304503620147705\n",
            "Training Accuracy :0.9343199729919434\n",
            "Validation loss :1.5674466857910156\n",
            "Validation Accuracy :0.8930999636650085\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5313893851470948\n",
            "Training Accuracy :0.9330199956893921\n",
            "Validation loss :1.5651992729187012\n",
            "Validation Accuracy :0.8955999612808228\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5290556844711303\n",
            "Training Accuracy :0.9349199533462524\n",
            "Validation loss :1.5648652267456056\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.527714319229126\n",
            "Training Accuracy :0.9365999698638916\n",
            "Validation loss :1.5646812068939209\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.528147971496582\n",
            "Training Accuracy :0.9362999796867371\n",
            "Validation loss :1.5658721828460693\n",
            "Validation Accuracy :0.8948999643325806\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.528278099746704\n",
            "Training Accuracy :0.9357999563217163\n",
            "Validation loss :1.5677619689941407\n",
            "Validation Accuracy :0.8930999636650085\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.528557821159363\n",
            "Training Accuracy :0.9350799918174744\n",
            "Validation loss :1.5693132209777831\n",
            "Validation Accuracy :0.8922999501228333\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5257978942108155\n",
            "Training Accuracy :0.9381399750709534\n",
            "Validation loss :1.5670272789001465\n",
            "Validation Accuracy :0.8937999606132507\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5251886502838135\n",
            "Training Accuracy :0.9390400052070618\n",
            "Validation loss :1.5644975746154786\n",
            "Validation Accuracy :0.8962000012397766\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5239314453125\n",
            "Training Accuracy :0.9401399493217468\n",
            "Validation loss :1.5666155609130858\n",
            "Validation Accuracy :0.8948999643325806\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5238429699325562\n",
            "Training Accuracy :0.9399600028991699\n",
            "Validation loss :1.5664344123840332\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5248098089599609\n",
            "Training Accuracy :0.9388799667358398\n",
            "Validation loss :1.5645428646087647\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5235053115081787\n",
            "Training Accuracy :0.9403599500656128\n",
            "Validation loss :1.567613480758667\n",
            "Validation Accuracy :0.8939999938011169\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5242450304412842\n",
            "Training Accuracy :0.9394399523735046\n",
            "Validation loss :1.5655117137908936\n",
            "Validation Accuracy :0.8962999582290649\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.52214375579834\n",
            "Training Accuracy :0.9415599703788757\n",
            "Validation loss :1.5647785552978515\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5222356024551391\n",
            "Training Accuracy :0.941379964351654\n",
            "Validation loss :1.566888060760498\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5214070029067994\n",
            "Training Accuracy :0.9419599771499634\n",
            "Validation loss :1.5684867389678956\n",
            "Validation Accuracy :0.8921999931335449\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.521010853919983\n",
            "Training Accuracy :0.9429000020027161\n",
            "Validation loss :1.5637234783172607\n",
            "Validation Accuracy :0.8988999724388123\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.521160573654175\n",
            "Training Accuracy :0.9426599740982056\n",
            "Validation loss :1.566279835128784\n",
            "Validation Accuracy :0.894599974155426\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5204225980377197\n",
            "Training Accuracy :0.9426999688148499\n",
            "Validation loss :1.5665562789916991\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5211891018295287\n",
            "Training Accuracy :0.9423999786376953\n",
            "Validation loss :1.5667724391937257\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5199241191864015\n",
            "Training Accuracy :0.9437399506568909\n",
            "Validation loss :1.5660611492156982\n",
            "Validation Accuracy :0.8935999870300293\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5200058701705932\n",
            "Training Accuracy :0.9432399868965149\n",
            "Validation loss :1.5640920196533203\n",
            "Validation Accuracy :0.8968999981880188\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.518797479248047\n",
            "Training Accuracy :0.9443599581718445\n",
            "Validation loss :1.5658901775360108\n",
            "Validation Accuracy :0.8958999514579773\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5189057719421386\n",
            "Training Accuracy :0.9447399973869324\n",
            "Validation loss :1.5648361545562743\n",
            "Validation Accuracy :0.8968999981880188\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.5185785210800171\n",
            "Training Accuracy :0.9449999928474426\n",
            "Validation loss :1.5643656368255616\n",
            "Validation Accuracy :0.8978999853134155\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.518487957687378\n",
            "Training Accuracy :0.9447399973869324\n",
            "Validation loss :1.564425884628296\n",
            "Validation Accuracy :0.8960999846458435\n",
            "Sparsity=0.13421772800000006\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.2634903721618653\n",
            "Training Accuracy :0.2412799894809723\n",
            "Validation loss :2.037907773399353\n",
            "Validation Accuracy :0.5357999801635742\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.8103735628890991\n",
            "Training Accuracy :0.6804199814796448\n",
            "Validation loss :1.725801439666748\n",
            "Validation Accuracy :0.7455999851226807\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.7024704189682007\n",
            "Training Accuracy :0.766759991645813\n",
            "Validation loss :1.6838342586517334\n",
            "Validation Accuracy :0.78329998254776\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6727686682510376\n",
            "Training Accuracy :0.7944599986076355\n",
            "Validation loss :1.6630907527923584\n",
            "Validation Accuracy :0.8023999929428101\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6581826108551025\n",
            "Training Accuracy :0.8070200085639954\n",
            "Validation loss :1.654490142059326\n",
            "Validation Accuracy :0.8093000054359436\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6468877593231201\n",
            "Training Accuracy :0.8180199861526489\n",
            "Validation loss :1.644600189781189\n",
            "Validation Accuracy :0.8205999732017517\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.639441584777832\n",
            "Training Accuracy :0.8251399993896484\n",
            "Validation loss :1.6395840209960937\n",
            "Validation Accuracy :0.8244999647140503\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6348088468933106\n",
            "Training Accuracy :0.8290999531745911\n",
            "Validation loss :1.6418287191390992\n",
            "Validation Accuracy :0.8209999799728394\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6308341180419923\n",
            "Training Accuracy :0.8335399627685547\n",
            "Validation loss :1.6338637493133545\n",
            "Validation Accuracy :0.8276000022888184\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6271029362487792\n",
            "Training Accuracy :0.8363999724388123\n",
            "Validation loss :1.6289624433517456\n",
            "Validation Accuracy :0.8342999815940857\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6244609661865235\n",
            "Training Accuracy :0.8387199640274048\n",
            "Validation loss :1.6283636434555053\n",
            "Validation Accuracy :0.8342999815940857\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6231890042495727\n",
            "Training Accuracy :0.8399399518966675\n",
            "Validation loss :1.628731188774109\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6203364471435546\n",
            "Training Accuracy :0.8425799608230591\n",
            "Validation loss :1.6256715816497802\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6193469026565552\n",
            "Training Accuracy :0.8436399698257446\n",
            "Validation loss :1.627996287918091\n",
            "Validation Accuracy :0.8341000080108643\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6166575998306274\n",
            "Training Accuracy :0.8464399576187134\n",
            "Validation loss :1.623427684020996\n",
            "Validation Accuracy :0.8388999700546265\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6162442406845092\n",
            "Training Accuracy :0.8464199900627136\n",
            "Validation loss :1.6225457515716553\n",
            "Validation Accuracy :0.8399999737739563\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6151180340957643\n",
            "Training Accuracy :0.8472399711608887\n",
            "Validation loss :1.6222551759719848\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6140251316452026\n",
            "Training Accuracy :0.8484399914741516\n",
            "Validation loss :1.6211592166900635\n",
            "Validation Accuracy :0.840399980545044\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6122368895721435\n",
            "Training Accuracy :0.8508999943733215\n",
            "Validation loss :1.622071212387085\n",
            "Validation Accuracy :0.8402999639511108\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6114767417144775\n",
            "Training Accuracy :0.8509999513626099\n",
            "Validation loss :1.6228610090255737\n",
            "Validation Accuracy :0.8393999934196472\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.611541776008606\n",
            "Training Accuracy :0.8511999845504761\n",
            "Validation loss :1.6243080329895019\n",
            "Validation Accuracy :0.8370999693870544\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6099037090301513\n",
            "Training Accuracy :0.8529599905014038\n",
            "Validation loss :1.6224310474395751\n",
            "Validation Accuracy :0.838699996471405\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.609558265914917\n",
            "Training Accuracy :0.8532599806785583\n",
            "Validation loss :1.6201818933486938\n",
            "Validation Accuracy :0.8412999510765076\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6085705429077148\n",
            "Training Accuracy :0.8538599610328674\n",
            "Validation loss :1.6202518348693848\n",
            "Validation Accuracy :0.8417999744415283\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6075436992263794\n",
            "Training Accuracy :0.8550799489021301\n",
            "Validation loss :1.6230943534851074\n",
            "Validation Accuracy :0.8381999731063843\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6076080673980713\n",
            "Training Accuracy :0.854699969291687\n",
            "Validation loss :1.6215125926971437\n",
            "Validation Accuracy :0.8400999903678894\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.606777077293396\n",
            "Training Accuracy :0.8551999926567078\n",
            "Validation loss :1.618762742805481\n",
            "Validation Accuracy :0.8420000076293945\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.598021628112793\n",
            "Training Accuracy :0.8652600049972534\n",
            "Validation loss :1.5914586128234862\n",
            "Validation Accuracy :0.873199999332428\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.574761916770935\n",
            "Training Accuracy :0.889739990234375\n",
            "Validation loss :1.5862125373840332\n",
            "Validation Accuracy :0.877299964427948\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5661324611663818\n",
            "Training Accuracy :0.8981599807739258\n",
            "Validation loss :1.5813038051605224\n",
            "Validation Accuracy :0.8812999725341797\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5600173920440674\n",
            "Training Accuracy :0.9042399525642395\n",
            "Validation loss :1.577777889251709\n",
            "Validation Accuracy :0.8859999775886536\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5552644693374633\n",
            "Training Accuracy :0.9096999764442444\n",
            "Validation loss :1.575485231781006\n",
            "Validation Accuracy :0.8866999745368958\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.552172182006836\n",
            "Training Accuracy :0.9128999710083008\n",
            "Validation loss :1.5718122344970704\n",
            "Validation Accuracy :0.8907999992370605\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5496457653808593\n",
            "Training Accuracy :0.9149399995803833\n",
            "Validation loss :1.573823642349243\n",
            "Validation Accuracy :0.887499988079071\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5479422674179077\n",
            "Training Accuracy :0.9160999655723572\n",
            "Validation loss :1.5710663192749024\n",
            "Validation Accuracy :0.8915999531745911\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.546533632926941\n",
            "Training Accuracy :0.9185199737548828\n",
            "Validation loss :1.573541794013977\n",
            "Validation Accuracy :0.8888999819755554\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.5447241493988038\n",
            "Training Accuracy :0.9193999767303467\n",
            "Validation loss :1.5697118171691895\n",
            "Validation Accuracy :0.8910999894142151\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5427390733337403\n",
            "Training Accuracy :0.9218399524688721\n",
            "Validation loss :1.5692169994354248\n",
            "Validation Accuracy :0.8912999629974365\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5418451175308228\n",
            "Training Accuracy :0.9227199554443359\n",
            "Validation loss :1.569641618347168\n",
            "Validation Accuracy :0.8930000066757202\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5408785472869873\n",
            "Training Accuracy :0.9228799939155579\n",
            "Validation loss :1.567780722427368\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5390578128814698\n",
            "Training Accuracy :0.9254399538040161\n",
            "Validation loss :1.5672136360168456\n",
            "Validation Accuracy :0.8934999704360962\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5375039907455443\n",
            "Training Accuracy :0.9269399642944336\n",
            "Validation loss :1.5674274364471437\n",
            "Validation Accuracy :0.8944999575614929\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.537474546470642\n",
            "Training Accuracy :0.9263599514961243\n",
            "Validation loss :1.5687403232574464\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5372076825332641\n",
            "Training Accuracy :0.9263799786567688\n",
            "Validation loss :1.5680803142547608\n",
            "Validation Accuracy :0.8925999999046326\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5358910389709473\n",
            "Training Accuracy :0.9279599785804749\n",
            "Validation loss :1.5687476058959962\n",
            "Validation Accuracy :0.8925999999046326\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5351807383346558\n",
            "Training Accuracy :0.9289399981498718\n",
            "Validation loss :1.5694069339752197\n",
            "Validation Accuracy :0.892799973487854\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.534956281890869\n",
            "Training Accuracy :0.9289799928665161\n",
            "Validation loss :1.5696764995574952\n",
            "Validation Accuracy :0.8925999999046326\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5340104906845093\n",
            "Training Accuracy :0.9301799535751343\n",
            "Validation loss :1.56867607421875\n",
            "Validation Accuracy :0.8920999765396118\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5341745658874513\n",
            "Training Accuracy :0.9295799732208252\n",
            "Validation loss :1.5645136753082276\n",
            "Validation Accuracy :0.8970999717712402\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.531898882713318\n",
            "Training Accuracy :0.9318999648094177\n",
            "Validation loss :1.564003842163086\n",
            "Validation Accuracy :0.8977999687194824\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5314495763397218\n",
            "Training Accuracy :0.9322399497032166\n",
            "Validation loss :1.5669944019317628\n",
            "Validation Accuracy :0.8944000005722046\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5307271841430663\n",
            "Training Accuracy :0.9332799911499023\n",
            "Validation loss :1.5657711254119873\n",
            "Validation Accuracy :0.8955999612808228\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5309093879699707\n",
            "Training Accuracy :0.9333799481391907\n",
            "Validation loss :1.5658419921875\n",
            "Validation Accuracy :0.8956999778747559\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5294757259368896\n",
            "Training Accuracy :0.9347599744796753\n",
            "Validation loss :1.5660001930236815\n",
            "Validation Accuracy :0.8956999778747559\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5303920840072631\n",
            "Training Accuracy :0.9333599805831909\n",
            "Validation loss :1.563971479034424\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5288209159088135\n",
            "Training Accuracy :0.9349199533462524\n",
            "Validation loss :1.5655301010131837\n",
            "Validation Accuracy :0.8950999975204468\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5277906981658935\n",
            "Training Accuracy :0.935979962348938\n",
            "Validation loss :1.5644122913360596\n",
            "Validation Accuracy :0.8959999680519104\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.5277397380447388\n",
            "Training Accuracy :0.9356399774551392\n",
            "Validation loss :1.566532317352295\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.5258385702896118\n",
            "Training Accuracy :0.9383599758148193\n",
            "Validation loss :1.5646941371917724\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.527348798713684\n",
            "Training Accuracy :0.9365599751472473\n",
            "Validation loss :1.5655416671752929\n",
            "Validation Accuracy :0.8952999711036682\n",
            "Sparsity=0.10737418240000006\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.294344228057861\n",
            "Training Accuracy :0.20081999897956848\n",
            "Validation loss :2.231494101715088\n",
            "Validation Accuracy :0.2295999974012375\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :1.9120823501205444\n",
            "Training Accuracy :0.5908200144767761\n",
            "Validation loss :1.7420249786376953\n",
            "Validation Accuracy :0.733299970626831\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.7135604693603517\n",
            "Training Accuracy :0.757860004901886\n",
            "Validation loss :1.6892111652374266\n",
            "Validation Accuracy :0.7811999917030334\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6774970310211181\n",
            "Training Accuracy :0.7906000018119812\n",
            "Validation loss :1.670246939277649\n",
            "Validation Accuracy :0.7963999509811401\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6590637857437134\n",
            "Training Accuracy :0.8076799511909485\n",
            "Validation loss :1.6613167850494386\n",
            "Validation Accuracy :0.8060999512672424\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6484774087905885\n",
            "Training Accuracy :0.8166799545288086\n",
            "Validation loss :1.6455508586883545\n",
            "Validation Accuracy :0.819599986076355\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6397491944122315\n",
            "Training Accuracy :0.8251799941062927\n",
            "Validation loss :1.641279442024231\n",
            "Validation Accuracy :0.8226999640464783\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6356229806900024\n",
            "Training Accuracy :0.8279199600219727\n",
            "Validation loss :1.6358808538436889\n",
            "Validation Accuracy :0.8271999955177307\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6312401119995117\n",
            "Training Accuracy :0.8324199914932251\n",
            "Validation loss :1.6355265073776246\n",
            "Validation Accuracy :0.8282999992370605\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6286154164886475\n",
            "Training Accuracy :0.8350399732589722\n",
            "Validation loss :1.6321907360076904\n",
            "Validation Accuracy :0.832099974155426\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6256669498062133\n",
            "Training Accuracy :0.8377400040626526\n",
            "Validation loss :1.6288202058792114\n",
            "Validation Accuracy :0.8337999582290649\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6238996781158448\n",
            "Training Accuracy :0.8390399813652039\n",
            "Validation loss :1.6272689891815186\n",
            "Validation Accuracy :0.8352999687194824\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.622310680618286\n",
            "Training Accuracy :0.8405999541282654\n",
            "Validation loss :1.6281707986831666\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6196973546600342\n",
            "Training Accuracy :0.8425999879837036\n",
            "Validation loss :1.6269725257873535\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6188098480224609\n",
            "Training Accuracy :0.8438199758529663\n",
            "Validation loss :1.6241173706054688\n",
            "Validation Accuracy :0.8391000032424927\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6174540869522094\n",
            "Training Accuracy :0.8454399704933167\n",
            "Validation loss :1.6237285831451416\n",
            "Validation Accuracy :0.8385999798774719\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.616165015335083\n",
            "Training Accuracy :0.8464799523353577\n",
            "Validation loss :1.625541382789612\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6148024704742432\n",
            "Training Accuracy :0.8479799628257751\n",
            "Validation loss :1.6223321092605592\n",
            "Validation Accuracy :0.8396999835968018\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6145694696426391\n",
            "Training Accuracy :0.8479599952697754\n",
            "Validation loss :1.6222799877166747\n",
            "Validation Accuracy :0.8394999504089355\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6128159200286865\n",
            "Training Accuracy :0.84961998462677\n",
            "Validation loss :1.6223417976379395\n",
            "Validation Accuracy :0.839199960231781\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6123436743164064\n",
            "Training Accuracy :0.8501799702644348\n",
            "Validation loss :1.6204464084625245\n",
            "Validation Accuracy :0.8412999510765076\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6114053439331055\n",
            "Training Accuracy :0.8512600064277649\n",
            "Validation loss :1.6221369817733764\n",
            "Validation Accuracy :0.8394999504089355\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6109982601547241\n",
            "Training Accuracy :0.8517199754714966\n",
            "Validation loss :1.6207987035751343\n",
            "Validation Accuracy :0.8414999842643738\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6047884363555909\n",
            "Training Accuracy :0.8581399917602539\n",
            "Validation loss :1.5943764169692993\n",
            "Validation Accuracy :0.8718000054359436\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5799354119491578\n",
            "Training Accuracy :0.8848199844360352\n",
            "Validation loss :1.587686552810669\n",
            "Validation Accuracy :0.875\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5722282551574707\n",
            "Training Accuracy :0.892259955406189\n",
            "Validation loss :1.5849929510116578\n",
            "Validation Accuracy :0.8791999816894531\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5660455213928222\n",
            "Training Accuracy :0.8986799716949463\n",
            "Validation loss :1.5811077974319458\n",
            "Validation Accuracy :0.8834999799728394\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.5610479726409912\n",
            "Training Accuracy :0.9039199948310852\n",
            "Validation loss :1.5785445075988769\n",
            "Validation Accuracy :0.8841999769210815\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5586182593917848\n",
            "Training Accuracy :0.9055799841880798\n",
            "Validation loss :1.5779422836303711\n",
            "Validation Accuracy :0.8849999904632568\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5542479204559325\n",
            "Training Accuracy :0.9098399877548218\n",
            "Validation loss :1.5742513160705567\n",
            "Validation Accuracy :0.8869999647140503\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5528846841812134\n",
            "Training Accuracy :0.9116399884223938\n",
            "Validation loss :1.5705584033966065\n",
            "Validation Accuracy :0.8922999501228333\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5505811528778075\n",
            "Training Accuracy :0.9138000011444092\n",
            "Validation loss :1.5707683343887329\n",
            "Validation Accuracy :0.8912000060081482\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5482190958023072\n",
            "Training Accuracy :0.9167999625205994\n",
            "Validation loss :1.570653123474121\n",
            "Validation Accuracy :0.8923999667167664\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.5464021097564697\n",
            "Training Accuracy :0.9177799820899963\n",
            "Validation loss :1.5689331048965454\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5455720626449585\n",
            "Training Accuracy :0.9188999533653259\n",
            "Validation loss :1.567890701675415\n",
            "Validation Accuracy :0.8937000036239624\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5433297368621826\n",
            "Training Accuracy :0.9208999872207642\n",
            "Validation loss :1.569170691871643\n",
            "Validation Accuracy :0.8919999599456787\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.54263928855896\n",
            "Training Accuracy :0.9216799736022949\n",
            "Validation loss :1.569284489440918\n",
            "Validation Accuracy :0.8915999531745911\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5413982592391968\n",
            "Training Accuracy :0.9231199622154236\n",
            "Validation loss :1.5687094593048097\n",
            "Validation Accuracy :0.8920999765396118\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5409785250854493\n",
            "Training Accuracy :0.9235399961471558\n",
            "Validation loss :1.5663446674346924\n",
            "Validation Accuracy :0.8953999876976013\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.539765364189148\n",
            "Training Accuracy :0.9243599772453308\n",
            "Validation loss :1.5668350814819336\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5390807944107057\n",
            "Training Accuracy :0.9248799681663513\n",
            "Validation loss :1.5657637042999268\n",
            "Validation Accuracy :0.8962000012397766\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5388615808105468\n",
            "Training Accuracy :0.9249799847602844\n",
            "Validation loss :1.56711063041687\n",
            "Validation Accuracy :0.8937999606132507\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.5373560969924926\n",
            "Training Accuracy :0.9266999959945679\n",
            "Validation loss :1.5677516162872314\n",
            "Validation Accuracy :0.8934999704360962\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.5368537818908692\n",
            "Training Accuracy :0.9271599650382996\n",
            "Validation loss :1.5661111015319824\n",
            "Validation Accuracy :0.8952999711036682\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5361539979171752\n",
            "Training Accuracy :0.9275999665260315\n",
            "Validation loss :1.5689399219512938\n",
            "Validation Accuracy :0.8914999961853027\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5355472006607056\n",
            "Training Accuracy :0.9284799695014954\n",
            "Validation loss :1.5659841442108153\n",
            "Validation Accuracy :0.8966999650001526\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5343538187408448\n",
            "Training Accuracy :0.9297199845314026\n",
            "Validation loss :1.5666306034088135\n",
            "Validation Accuracy :0.8944999575614929\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5344258586502075\n",
            "Training Accuracy :0.9294799566268921\n",
            "Validation loss :1.5665574905395507\n",
            "Validation Accuracy :0.8959999680519104\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.5338875162124634\n",
            "Training Accuracy :0.9302999973297119\n",
            "Validation loss :1.5650519355773926\n",
            "Validation Accuracy :0.8960999846458435\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.533808187789917\n",
            "Training Accuracy :0.9294999837875366\n",
            "Validation loss :1.5675867588043213\n",
            "Validation Accuracy :0.8946999907493591\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.532663824195862\n",
            "Training Accuracy :0.9312399625778198\n",
            "Validation loss :1.5642865489959716\n",
            "Validation Accuracy :0.8982999920845032\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.531206401939392\n",
            "Training Accuracy :0.932919979095459\n",
            "Validation loss :1.5678623203277589\n",
            "Validation Accuracy :0.8938999772071838\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5312732666397095\n",
            "Training Accuracy :0.9325399994850159\n",
            "Validation loss :1.5651902698516846\n",
            "Validation Accuracy :0.8964999914169312\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.5310970637512207\n",
            "Training Accuracy :0.932479977607727\n",
            "Validation loss :1.5665052700042725\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.531158147315979\n",
            "Training Accuracy :0.9327200055122375\n",
            "Validation loss :1.5640935638427735\n",
            "Validation Accuracy :0.8969999551773071\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.5300038777923584\n",
            "Training Accuracy :0.9338399767875671\n",
            "Validation loss :1.5643607349395752\n",
            "Validation Accuracy :0.8983999490737915\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5293344519042968\n",
            "Training Accuracy :0.9344399571418762\n",
            "Validation loss :1.5637272247314453\n",
            "Validation Accuracy :0.8976999521255493\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.528546109046936\n",
            "Training Accuracy :0.9352200031280518\n",
            "Validation loss :1.5642113079071045\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.5290865480041504\n",
            "Training Accuracy :0.934499979019165\n",
            "Validation loss :1.5646492282867432\n",
            "Validation Accuracy :0.8966999650001526\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.52800137840271\n",
            "Training Accuracy :0.9361199736595154\n",
            "Validation loss :1.5660169506072998\n",
            "Validation Accuracy :0.8956999778747559\n",
            "Sparsity=0.08589934592000005\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.301093093032837\n",
            "Training Accuracy :0.157260000705719\n",
            "Validation loss :2.296796081542969\n",
            "Validation Accuracy :0.29999998211860657\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.1029136410903932\n",
            "Training Accuracy :0.43459999561309814\n",
            "Validation loss :1.8423126638412475\n",
            "Validation Accuracy :0.6588999629020691\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.753690521850586\n",
            "Training Accuracy :0.7269999980926514\n",
            "Validation loss :1.7121649097442626\n",
            "Validation Accuracy :0.7599999904632568\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6926049569702148\n",
            "Training Accuracy :0.7765399813652039\n",
            "Validation loss :1.6809294704437256\n",
            "Validation Accuracy :0.786799967288971\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.670510401573181\n",
            "Training Accuracy :0.7966799736022949\n",
            "Validation loss :1.6642293579101564\n",
            "Validation Accuracy :0.8021999597549438\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6578864263153077\n",
            "Training Accuracy :0.807919979095459\n",
            "Validation loss :1.654834293937683\n",
            "Validation Accuracy :0.8109999895095825\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.64768397895813\n",
            "Training Accuracy :0.8175999522209167\n",
            "Validation loss :1.644387612915039\n",
            "Validation Accuracy :0.8206999897956848\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.639602817993164\n",
            "Training Accuracy :0.8247799873352051\n",
            "Validation loss :1.6397192024230958\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6354209931182861\n",
            "Training Accuracy :0.8286399841308594\n",
            "Validation loss :1.6363682027816773\n",
            "Validation Accuracy :0.8269999623298645\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.632117261695862\n",
            "Training Accuracy :0.8317599892616272\n",
            "Validation loss :1.6317740871429443\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6287394354629516\n",
            "Training Accuracy :0.8352800011634827\n",
            "Validation loss :1.6311374053955079\n",
            "Validation Accuracy :0.8326999545097351\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6268082051849366\n",
            "Training Accuracy :0.8364999890327454\n",
            "Validation loss :1.6334302703857422\n",
            "Validation Accuracy :0.8287000060081482\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6213023823165893\n",
            "Training Accuracy :0.8424399495124817\n",
            "Validation loss :1.6211726282119752\n",
            "Validation Accuracy :0.8470999598503113\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6010502582550048\n",
            "Training Accuracy :0.8651999831199646\n",
            "Validation loss :1.6027034858703613\n",
            "Validation Accuracy :0.8608999848365784\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.5917634106445313\n",
            "Training Accuracy :0.8741799592971802\n",
            "Validation loss :1.59641925945282\n",
            "Validation Accuracy :0.8677999973297119\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.586741718826294\n",
            "Training Accuracy :0.8771799802780151\n",
            "Validation loss :1.5929898488998413\n",
            "Validation Accuracy :0.8712999820709229\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.5813299144363404\n",
            "Training Accuracy :0.8833999633789062\n",
            "Validation loss :1.5898228229522704\n",
            "Validation Accuracy :0.8747999668121338\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.577856993637085\n",
            "Training Accuracy :0.8870999813079834\n",
            "Validation loss :1.5876667539596558\n",
            "Validation Accuracy :0.8762999773025513\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.5728621789169313\n",
            "Training Accuracy :0.8919199705123901\n",
            "Validation loss :1.5847042192459107\n",
            "Validation Accuracy :0.8798999786376953\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.5697316198730469\n",
            "Training Accuracy :0.8949199914932251\n",
            "Validation loss :1.5799030689239502\n",
            "Validation Accuracy :0.8828999996185303\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.5661890448760987\n",
            "Training Accuracy :0.8987199664115906\n",
            "Validation loss :1.5796131254196166\n",
            "Validation Accuracy :0.882599949836731\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.5637758100128174\n",
            "Training Accuracy :0.9001999497413635\n",
            "Validation loss :1.5773528144836426\n",
            "Validation Accuracy :0.8853999972343445\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.5612433544540405\n",
            "Training Accuracy :0.9034799933433533\n",
            "Validation loss :1.5773510889053344\n",
            "Validation Accuracy :0.8851000070571899\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.5588110276412963\n",
            "Training Accuracy :0.9052599668502808\n",
            "Validation loss :1.57838294506073\n",
            "Validation Accuracy :0.8841999769210815\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.5565828993988038\n",
            "Training Accuracy :0.9080199599266052\n",
            "Validation loss :1.5745130451202392\n",
            "Validation Accuracy :0.8881999850273132\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.5556578722000123\n",
            "Training Accuracy :0.9088599681854248\n",
            "Validation loss :1.5743752237319946\n",
            "Validation Accuracy :0.8881999850273132\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.5531834964370728\n",
            "Training Accuracy :0.9107999801635742\n",
            "Validation loss :1.5719432413101195\n",
            "Validation Accuracy :0.890999972820282\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.55169273979187\n",
            "Training Accuracy :0.912839949131012\n",
            "Validation loss :1.5748645376205443\n",
            "Validation Accuracy :0.8878999948501587\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.5504527600860596\n",
            "Training Accuracy :0.9138199687004089\n",
            "Validation loss :1.5731861490249635\n",
            "Validation Accuracy :0.8892999887466431\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.5486617631530761\n",
            "Training Accuracy :0.9161199927330017\n",
            "Validation loss :1.5743272212982178\n",
            "Validation Accuracy :0.8877999782562256\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.5480556370544434\n",
            "Training Accuracy :0.9162999987602234\n",
            "Validation loss :1.5733105487823487\n",
            "Validation Accuracy :0.8894999623298645\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.5472026425933838\n",
            "Training Accuracy :0.9169399738311768\n",
            "Validation loss :1.5703633411407472\n",
            "Validation Accuracy :0.8916999697685242\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.5453420806503295\n",
            "Training Accuracy :0.9189399480819702\n",
            "Validation loss :1.5696000562667847\n",
            "Validation Accuracy :0.8912999629974365\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.544954937057495\n",
            "Training Accuracy :0.9191599488258362\n",
            "Validation loss :1.5691835300445556\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.5436915372467042\n",
            "Training Accuracy :0.921019971370697\n",
            "Validation loss :1.5697585863113404\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.5429745928955079\n",
            "Training Accuracy :0.9211999773979187\n",
            "Validation loss :1.569600242996216\n",
            "Validation Accuracy :0.8912000060081482\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.541541632270813\n",
            "Training Accuracy :0.9229599833488464\n",
            "Validation loss :1.5686665084838867\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.5408613198852539\n",
            "Training Accuracy :0.9231999516487122\n",
            "Validation loss :1.567885094833374\n",
            "Validation Accuracy :0.8933999538421631\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.5392425254440307\n",
            "Training Accuracy :0.9250800013542175\n",
            "Validation loss :1.5692438510894775\n",
            "Validation Accuracy :0.8917999863624573\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.5386518561553955\n",
            "Training Accuracy :0.9254799485206604\n",
            "Validation loss :1.5707182361602783\n",
            "Validation Accuracy :0.890999972820282\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.5386790335464477\n",
            "Training Accuracy :0.9257999658584595\n",
            "Validation loss :1.567741499710083\n",
            "Validation Accuracy :0.892799973487854\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.5381567920684815\n",
            "Training Accuracy :0.925819993019104\n",
            "Validation loss :1.5671945262908935\n",
            "Validation Accuracy :0.8937000036239624\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.538391809425354\n",
            "Training Accuracy :0.9261800050735474\n",
            "Validation loss :1.5710315479278565\n",
            "Validation Accuracy :0.8901000022888184\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.538548405380249\n",
            "Training Accuracy :0.9254999756813049\n",
            "Validation loss :1.5713552989959716\n",
            "Validation Accuracy :0.8892999887466431\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5376754004669189\n",
            "Training Accuracy :0.9263399839401245\n",
            "Validation loss :1.567274515914917\n",
            "Validation Accuracy :0.8948999643325806\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.5362155416107177\n",
            "Training Accuracy :0.927299976348877\n",
            "Validation loss :1.5674055595397949\n",
            "Validation Accuracy :0.8951999545097351\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5361507425308227\n",
            "Training Accuracy :0.9277199506759644\n",
            "Validation loss :1.5672049633026124\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5358210958099365\n",
            "Training Accuracy :0.9281999468803406\n",
            "Validation loss :1.5674903182983397\n",
            "Validation Accuracy :0.8932999968528748\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.535011636543274\n",
            "Training Accuracy :0.9287999868392944\n",
            "Validation loss :1.5664801361083984\n",
            "Validation Accuracy :0.8955000042915344\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5347308597946168\n",
            "Training Accuracy :0.9291999936103821\n",
            "Validation loss :1.5683342311859132\n",
            "Validation Accuracy :0.8919999599456787\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5343502031707763\n",
            "Training Accuracy :0.9295600056648254\n",
            "Validation loss :1.568071877670288\n",
            "Validation Accuracy :0.8930999636650085\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5332187623977662\n",
            "Training Accuracy :0.9307199716567993\n",
            "Validation loss :1.5670414993286133\n",
            "Validation Accuracy :0.8944999575614929\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.533351403579712\n",
            "Training Accuracy :0.9306599497795105\n",
            "Validation loss :1.5658388538360595\n",
            "Validation Accuracy :0.8947999477386475\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.532881718788147\n",
            "Training Accuracy :0.9311599731445312\n",
            "Validation loss :1.5671138515472411\n",
            "Validation Accuracy :0.8941999673843384\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.532694818534851\n",
            "Training Accuracy :0.9306399822235107\n",
            "Validation loss :1.568121420288086\n",
            "Validation Accuracy :0.8928999900817871\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.532464676170349\n",
            "Training Accuracy :0.9309999942779541\n",
            "Validation loss :1.5650444202423095\n",
            "Validation Accuracy :0.896399974822998\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5318188614654542\n",
            "Training Accuracy :0.9317599534988403\n",
            "Validation loss :1.5768050296783447\n",
            "Validation Accuracy :0.8851000070571899\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.532286561088562\n",
            "Training Accuracy :0.9312799572944641\n",
            "Validation loss :1.5641558418273926\n",
            "Validation Accuracy :0.8967999815940857\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.531207724685669\n",
            "Training Accuracy :0.9326799511909485\n",
            "Validation loss :1.5675056690216065\n",
            "Validation Accuracy :0.8931999802589417\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.5319618487930298\n",
            "Training Accuracy :0.9316999912261963\n",
            "Validation loss :1.5653510696411133\n",
            "Validation Accuracy :0.8962000012397766\n",
            "Sparsity=0.06871947673600004\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.301959020080566\n",
            "Training Accuracy :0.11075999587774277\n",
            "Validation loss :2.3007866283416747\n",
            "Validation Accuracy :0.17099998891353607\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.247795046310425\n",
            "Training Accuracy :0.3125799894332886\n",
            "Validation loss :2.036940748786926\n",
            "Validation Accuracy :0.5256999731063843\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.8457467093276978\n",
            "Training Accuracy :0.6444000005722046\n",
            "Validation loss :1.743988104057312\n",
            "Validation Accuracy :0.7351999878883362\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.7178798599243164\n",
            "Training Accuracy :0.7524799704551697\n",
            "Validation loss :1.6980430027008058\n",
            "Validation Accuracy :0.7690999507904053\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6862793124389648\n",
            "Training Accuracy :0.7807999849319458\n",
            "Validation loss :1.6770063734054566\n",
            "Validation Accuracy :0.790399968624115\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6719624673843383\n",
            "Training Accuracy :0.7940399646759033\n",
            "Validation loss :1.6684699745178222\n",
            "Validation Accuracy :0.795699954032898\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.661554084854126\n",
            "Training Accuracy :0.8036199808120728\n",
            "Validation loss :1.6585914232254029\n",
            "Validation Accuracy :0.8054999709129333\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6528175158691407\n",
            "Training Accuracy :0.8118799924850464\n",
            "Validation loss :1.6543841278076172\n",
            "Validation Accuracy :0.8089999556541443\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6461740350723266\n",
            "Training Accuracy :0.8187599778175354\n",
            "Validation loss :1.645090475463867\n",
            "Validation Accuracy :0.8188999891281128\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6424757475280762\n",
            "Training Accuracy :0.8215399980545044\n",
            "Validation loss :1.6419643884658814\n",
            "Validation Accuracy :0.8222999572753906\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6371849825668334\n",
            "Training Accuracy :0.8269000053405762\n",
            "Validation loss :1.63846022605896\n",
            "Validation Accuracy :0.824400007724762\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6344351064300537\n",
            "Training Accuracy :0.8296999931335449\n",
            "Validation loss :1.6374791124343873\n",
            "Validation Accuracy :0.8251999616622925\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6330598505401612\n",
            "Training Accuracy :0.8301799893379211\n",
            "Validation loss :1.6362249071121215\n",
            "Validation Accuracy :0.8256999850273132\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6308588378143312\n",
            "Training Accuracy :0.8321599960327148\n",
            "Validation loss :1.6339971975326537\n",
            "Validation Accuracy :0.8288999795913696\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6286244155502319\n",
            "Training Accuracy :0.8348000049591064\n",
            "Validation loss :1.6341071550369262\n",
            "Validation Accuracy :0.8296999931335449\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6276491369628907\n",
            "Training Accuracy :0.8355199694633484\n",
            "Validation loss :1.6342543102264404\n",
            "Validation Accuracy :0.8281999826431274\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6265225246429444\n",
            "Training Accuracy :0.8363999724388123\n",
            "Validation loss :1.6313368370056152\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6257438608169557\n",
            "Training Accuracy :0.836679995059967\n",
            "Validation loss :1.6310291255950928\n",
            "Validation Accuracy :0.8319000005722046\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6248137294769287\n",
            "Training Accuracy :0.8380199670791626\n",
            "Validation loss :1.6294685054779052\n",
            "Validation Accuracy :0.8330000042915344\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6236097372436524\n",
            "Training Accuracy :0.8387199640274048\n",
            "Validation loss :1.6281998203277588\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6219602004241944\n",
            "Training Accuracy :0.8405999541282654\n",
            "Validation loss :1.6300707263946532\n",
            "Validation Accuracy :0.833299994468689\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.622171539955139\n",
            "Training Accuracy :0.8402799963951111\n",
            "Validation loss :1.6289805397033692\n",
            "Validation Accuracy :0.8330000042915344\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6214302457427978\n",
            "Training Accuracy :0.8406999707221985\n",
            "Validation loss :1.6267291904449463\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6200065824127197\n",
            "Training Accuracy :0.842519998550415\n",
            "Validation loss :1.6292437850952148\n",
            "Validation Accuracy :0.8327999711036682\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6199862056732177\n",
            "Training Accuracy :0.842199981212616\n",
            "Validation loss :1.6293829124450683\n",
            "Validation Accuracy :0.8319000005722046\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6197546826934814\n",
            "Training Accuracy :0.8423399925231934\n",
            "Validation loss :1.6276344806671144\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6187389322280883\n",
            "Training Accuracy :0.8436200022697449\n",
            "Validation loss :1.6269341655731202\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6180983624649048\n",
            "Training Accuracy :0.8443399667739868\n",
            "Validation loss :1.631617008972168\n",
            "Validation Accuracy :0.8314999938011169\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6182496561431885\n",
            "Training Accuracy :0.8440799713134766\n",
            "Validation loss :1.6254034381866456\n",
            "Validation Accuracy :0.8359000086784363\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.617160574913025\n",
            "Training Accuracy :0.8449400067329407\n",
            "Validation loss :1.6257210136413573\n",
            "Validation Accuracy :0.8353999853134155\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6165152768707276\n",
            "Training Accuracy :0.8455199599266052\n",
            "Validation loss :1.6251494777679443\n",
            "Validation Accuracy :0.8357999920845032\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.616572922782898\n",
            "Training Accuracy :0.8458799719810486\n",
            "Validation loss :1.6278547939300536\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6166012978363038\n",
            "Training Accuracy :0.8456400036811829\n",
            "Validation loss :1.6276011638641357\n",
            "Validation Accuracy :0.8337000012397766\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.615555438156128\n",
            "Training Accuracy :0.8464999794960022\n",
            "Validation loss :1.6252950332641602\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.614667098121643\n",
            "Training Accuracy :0.8478800058364868\n",
            "Validation loss :1.627461848449707\n",
            "Validation Accuracy :0.8323999643325806\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6151382665252685\n",
            "Training Accuracy :0.8469399809837341\n",
            "Validation loss :1.6272766117095947\n",
            "Validation Accuracy :0.8339999914169312\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.614530464553833\n",
            "Training Accuracy :0.8476799726486206\n",
            "Validation loss :1.6249529499053954\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6138857469940187\n",
            "Training Accuracy :0.8485999703407288\n",
            "Validation loss :1.6250293285369872\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6137522904205321\n",
            "Training Accuracy :0.8482599854469299\n",
            "Validation loss :1.6257849056243896\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6128074040985108\n",
            "Training Accuracy :0.8496800065040588\n",
            "Validation loss :1.622060605239868\n",
            "Validation Accuracy :0.8405999541282654\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6133579557037354\n",
            "Training Accuracy :0.8484599590301514\n",
            "Validation loss :1.626511849784851\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6123066958236694\n",
            "Training Accuracy :0.8495599627494812\n",
            "Validation loss :1.623740146636963\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6122641234588624\n",
            "Training Accuracy :0.8501600027084351\n",
            "Validation loss :1.6224561614990234\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.61177092048645\n",
            "Training Accuracy :0.8505799770355225\n",
            "Validation loss :1.6234235466003417\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.5988014557266235\n",
            "Training Accuracy :0.8649599552154541\n",
            "Validation loss :1.5989435054779053\n",
            "Validation Accuracy :0.8641999959945679\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.584160361175537\n",
            "Training Accuracy :0.8799399733543396\n",
            "Validation loss :1.592870732498169\n",
            "Validation Accuracy :0.8709999918937683\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.5799776675796509\n",
            "Training Accuracy :0.8838199973106384\n",
            "Validation loss :1.5914693572998047\n",
            "Validation Accuracy :0.8711999654769897\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.5768560363006592\n",
            "Training Accuracy :0.8866399526596069\n",
            "Validation loss :1.5851826652526855\n",
            "Validation Accuracy :0.8780999779701233\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.574716390838623\n",
            "Training Accuracy :0.888439953327179\n",
            "Validation loss :1.5894782608032227\n",
            "Validation Accuracy :0.8732999563217163\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.5724627980804444\n",
            "Training Accuracy :0.8910599946975708\n",
            "Validation loss :1.583304723739624\n",
            "Validation Accuracy :0.8777999877929688\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.5700802897644044\n",
            "Training Accuracy :0.8936399817466736\n",
            "Validation loss :1.5839980464935304\n",
            "Validation Accuracy :0.8779999613761902\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.5685077779769898\n",
            "Training Accuracy :0.8945800065994263\n",
            "Validation loss :1.5849383979797362\n",
            "Validation Accuracy :0.8764999508857727\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.5665506454086304\n",
            "Training Accuracy :0.8971999883651733\n",
            "Validation loss :1.5790865242004395\n",
            "Validation Accuracy :0.8811999559402466\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.565753434829712\n",
            "Training Accuracy :0.8968799710273743\n",
            "Validation loss :1.5793387954711915\n",
            "Validation Accuracy :0.8833999633789062\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.5641930837631226\n",
            "Training Accuracy :0.899459958076477\n",
            "Validation loss :1.5796462886810303\n",
            "Validation Accuracy :0.882099986076355\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.562943377456665\n",
            "Training Accuracy :0.9006999731063843\n",
            "Validation loss :1.583529573059082\n",
            "Validation Accuracy :0.8792999982833862\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.5629617048263549\n",
            "Training Accuracy :0.8998799920082092\n",
            "Validation loss :1.582645645904541\n",
            "Validation Accuracy :0.8797000050544739\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.560676736984253\n",
            "Training Accuracy :0.902239978313446\n",
            "Validation loss :1.580105068588257\n",
            "Validation Accuracy :0.880899965763092\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.5607510260772706\n",
            "Training Accuracy :0.9026599526405334\n",
            "Validation loss :1.5786563358306884\n",
            "Validation Accuracy :0.8845999836921692\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.5602880224609375\n",
            "Training Accuracy :0.9023399949073792\n",
            "Validation loss :1.5790052431106567\n",
            "Validation Accuracy :0.8817999958992004\n",
            "Sparsity=0.054975581388800036\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3023850691223147\n",
            "Training Accuracy :0.10589999705553055\n",
            "Validation loss :2.3021468940734864\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3011070336151125\n",
            "Training Accuracy :0.15987999737262726\n",
            "Validation loss :2.297748403930664\n",
            "Validation Accuracy :0.34939998388290405\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.1952993842315673\n",
            "Training Accuracy :0.33927997946739197\n",
            "Validation loss :1.9316250177383423\n",
            "Validation Accuracy :0.5662999749183655\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.8114466553497315\n",
            "Training Accuracy :0.6732199788093567\n",
            "Validation loss :1.733647026824951\n",
            "Validation Accuracy :0.7418999671936035\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.71161072971344\n",
            "Training Accuracy :0.7594199776649475\n",
            "Validation loss :1.6934544403076173\n",
            "Validation Accuracy :0.7754999995231628\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6842190160369872\n",
            "Training Accuracy :0.7829799652099609\n",
            "Validation loss :1.681302223587036\n",
            "Validation Accuracy :0.7847999930381775\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6716955925750732\n",
            "Training Accuracy :0.7938799858093262\n",
            "Validation loss :1.6686572492599487\n",
            "Validation Accuracy :0.7971999645233154\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6614852044677735\n",
            "Training Accuracy :0.8039199709892273\n",
            "Validation loss :1.6598210376739502\n",
            "Validation Accuracy :0.804099977016449\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.65375918800354\n",
            "Training Accuracy :0.8107799887657166\n",
            "Validation loss :1.6498070177078248\n",
            "Validation Accuracy :0.8152999877929688\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.646035122718811\n",
            "Training Accuracy :0.8183599710464478\n",
            "Validation loss :1.646409408569336\n",
            "Validation Accuracy :0.8180999755859375\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6414148788833618\n",
            "Training Accuracy :0.8229599595069885\n",
            "Validation loss :1.643985390663147\n",
            "Validation Accuracy :0.8194999694824219\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6373723142242431\n",
            "Training Accuracy :0.82669997215271\n",
            "Validation loss :1.6386722999572754\n",
            "Validation Accuracy :0.8255999684333801\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6346543496704102\n",
            "Training Accuracy :0.8285399675369263\n",
            "Validation loss :1.6386053691864013\n",
            "Validation Accuracy :0.8233000040054321\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6319925745391846\n",
            "Training Accuracy :0.8316599726676941\n",
            "Validation loss :1.6376143795013427\n",
            "Validation Accuracy :0.8246999979019165\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6298621142196654\n",
            "Training Accuracy :0.8335599899291992\n",
            "Validation loss :1.632930729484558\n",
            "Validation Accuracy :0.8299999833106995\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6281852836608888\n",
            "Training Accuracy :0.8354600071907043\n",
            "Validation loss :1.6321025812149048\n",
            "Validation Accuracy :0.8309999704360962\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6263891760635376\n",
            "Training Accuracy :0.8369399905204773\n",
            "Validation loss :1.6318805328369141\n",
            "Validation Accuracy :0.8300999999046326\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6263410146713257\n",
            "Training Accuracy :0.8363399505615234\n",
            "Validation loss :1.6338728477478028\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.624505494003296\n",
            "Training Accuracy :0.8384799957275391\n",
            "Validation loss :1.6296751668930054\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.622819129562378\n",
            "Training Accuracy :0.839959979057312\n",
            "Validation loss :1.6266175868988038\n",
            "Validation Accuracy :0.8370999693870544\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6223449014282227\n",
            "Training Accuracy :0.8406800031661987\n",
            "Validation loss :1.627066562461853\n",
            "Validation Accuracy :0.8356999754905701\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.621316339111328\n",
            "Training Accuracy :0.8414799571037292\n",
            "Validation loss :1.626504885864258\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6204528625488281\n",
            "Training Accuracy :0.8416999578475952\n",
            "Validation loss :1.626106072807312\n",
            "Validation Accuracy :0.8357999920845032\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6197700275421143\n",
            "Training Accuracy :0.8425399661064148\n",
            "Validation loss :1.6263400421142578\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.619678203353882\n",
            "Training Accuracy :0.843019962310791\n",
            "Validation loss :1.6270047088623047\n",
            "Validation Accuracy :0.8357999920845032\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6183315334320068\n",
            "Training Accuracy :0.8443199992179871\n",
            "Validation loss :1.6243173547744751\n",
            "Validation Accuracy :0.8378999829292297\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6185412319946288\n",
            "Training Accuracy :0.8436599969863892\n",
            "Validation loss :1.6250660713195801\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.617654023475647\n",
            "Training Accuracy :0.8447200059890747\n",
            "Validation loss :1.624699910736084\n",
            "Validation Accuracy :0.8369999527931213\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6175663836288452\n",
            "Training Accuracy :0.8445799946784973\n",
            "Validation loss :1.623336989402771\n",
            "Validation Accuracy :0.8391000032424927\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6167412329483033\n",
            "Training Accuracy :0.8455999493598938\n",
            "Validation loss :1.624861955833435\n",
            "Validation Accuracy :0.8370999693870544\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6158654961776733\n",
            "Training Accuracy :0.8470199704170227\n",
            "Validation loss :1.623663790512085\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6158440409088135\n",
            "Training Accuracy :0.8464799523353577\n",
            "Validation loss :1.6242431867599487\n",
            "Validation Accuracy :0.836899995803833\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6157468466949463\n",
            "Training Accuracy :0.8467999696731567\n",
            "Validation loss :1.6240954780578614\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6152663558197022\n",
            "Training Accuracy :0.8468799591064453\n",
            "Validation loss :1.6234447801589966\n",
            "Validation Accuracy :0.8381999731063843\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6147915782928466\n",
            "Training Accuracy :0.8471399545669556\n",
            "Validation loss :1.6259504674911498\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6147169134902954\n",
            "Training Accuracy :0.847599983215332\n",
            "Validation loss :1.6254826639175415\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6135380715179444\n",
            "Training Accuracy :0.8484999537467957\n",
            "Validation loss :1.6219425888061523\n",
            "Validation Accuracy :0.8405999541282654\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.614091271095276\n",
            "Training Accuracy :0.848360002040863\n",
            "Validation loss :1.6219726156234742\n",
            "Validation Accuracy :0.8395999670028687\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6137197092437745\n",
            "Training Accuracy :0.8481599688529968\n",
            "Validation loss :1.6222752773284912\n",
            "Validation Accuracy :0.8392999768257141\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6134322860717774\n",
            "Training Accuracy :0.8485400080680847\n",
            "Validation loss :1.6224324241638184\n",
            "Validation Accuracy :0.839199960231781\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6127692545318604\n",
            "Training Accuracy :0.8491599559783936\n",
            "Validation loss :1.6234376050949098\n",
            "Validation Accuracy :0.8371999859809875\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6133121411895752\n",
            "Training Accuracy :0.8485199809074402\n",
            "Validation loss :1.6220018650054933\n",
            "Validation Accuracy :0.8388999700546265\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6115540088272096\n",
            "Training Accuracy :0.8505199551582336\n",
            "Validation loss :1.625536216545105\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6120859088516235\n",
            "Training Accuracy :0.8504199981689453\n",
            "Validation loss :1.6221360088348389\n",
            "Validation Accuracy :0.8399999737739563\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6115432699203491\n",
            "Training Accuracy :0.8506799936294556\n",
            "Validation loss :1.6215008766174317\n",
            "Validation Accuracy :0.8398999571800232\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.611419412879944\n",
            "Training Accuracy :0.8505599498748779\n",
            "Validation loss :1.6209568901062013\n",
            "Validation Accuracy :0.8405999541282654\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.610991350631714\n",
            "Training Accuracy :0.8511799573898315\n",
            "Validation loss :1.6252713130950929\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.610806124305725\n",
            "Training Accuracy :0.8514800071716309\n",
            "Validation loss :1.621668701171875\n",
            "Validation Accuracy :0.8395999670028687\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6110261584854126\n",
            "Training Accuracy :0.850820004940033\n",
            "Validation loss :1.621161067199707\n",
            "Validation Accuracy :0.8405999541282654\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6104195008850097\n",
            "Training Accuracy :0.8517599701881409\n",
            "Validation loss :1.6204610038757323\n",
            "Validation Accuracy :0.8406999707221985\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.610143164291382\n",
            "Training Accuracy :0.8520999550819397\n",
            "Validation loss :1.6216728168487549\n",
            "Validation Accuracy :0.8398999571800232\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.609789097366333\n",
            "Training Accuracy :0.852400004863739\n",
            "Validation loss :1.6209862865447997\n",
            "Validation Accuracy :0.8394999504089355\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6096551313018799\n",
            "Training Accuracy :0.8525599837303162\n",
            "Validation loss :1.621060001373291\n",
            "Validation Accuracy :0.840399980545044\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6095235354232789\n",
            "Training Accuracy :0.8527599573135376\n",
            "Validation loss :1.6213047023773193\n",
            "Validation Accuracy :0.8400999903678894\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6090618558502197\n",
            "Training Accuracy :0.8531999588012695\n",
            "Validation loss :1.6251014434814453\n",
            "Validation Accuracy :0.8362999558448792\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6089443497085572\n",
            "Training Accuracy :0.8531999588012695\n",
            "Validation loss :1.6219753993988038\n",
            "Validation Accuracy :0.8398000001907349\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6088530236434937\n",
            "Training Accuracy :0.8531000018119812\n",
            "Validation loss :1.621168732070923\n",
            "Validation Accuracy :0.840399980545044\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6080883442687988\n",
            "Training Accuracy :0.8543999791145325\n",
            "Validation loss :1.6207022495269776\n",
            "Validation Accuracy :0.8411999940872192\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6085862530899049\n",
            "Training Accuracy :0.8536199927330017\n",
            "Validation loss :1.6207908729553222\n",
            "Validation Accuracy :0.8393999934196472\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6084768450164795\n",
            "Training Accuracy :0.8534199595451355\n",
            "Validation loss :1.6206148666381837\n",
            "Validation Accuracy :0.8400999903678894\n",
            "Sparsity=0.043980465111040035\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3024923835754394\n",
            "Training Accuracy :0.10027999430894852\n",
            "Validation loss :2.302390392303467\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3021992485809326\n",
            "Training Accuracy :0.1092199981212616\n",
            "Validation loss :2.3018639888763426\n",
            "Validation Accuracy :0.13899999856948853\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.2975102614593506\n",
            "Training Accuracy :0.19839999079704285\n",
            "Validation loss :2.2713071842193604\n",
            "Validation Accuracy :0.203699991106987\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.113864306602478\n",
            "Training Accuracy :0.3601199984550476\n",
            "Validation loss :1.885970547103882\n",
            "Validation Accuracy :0.5902999639511108\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.7904636480331422\n",
            "Training Accuracy :0.6947599649429321\n",
            "Validation loss :1.7320926630020141\n",
            "Validation Accuracy :0.7422999739646912\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.706834186630249\n",
            "Training Accuracy :0.7646399736404419\n",
            "Validation loss :1.6912139108657838\n",
            "Validation Accuracy :0.777999997138977\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.681767805557251\n",
            "Training Accuracy :0.7863399982452393\n",
            "Validation loss :1.6779678380966188\n",
            "Validation Accuracy :0.7888999581336975\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6695482166290283\n",
            "Training Accuracy :0.7963799834251404\n",
            "Validation loss :1.667518982887268\n",
            "Validation Accuracy :0.7968999743461609\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.660632940673828\n",
            "Training Accuracy :0.804919958114624\n",
            "Validation loss :1.6576750156402589\n",
            "Validation Accuracy :0.807699978351593\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6522458832168578\n",
            "Training Accuracy :0.81277996301651\n",
            "Validation loss :1.6508884740829468\n",
            "Validation Accuracy :0.8136000037193298\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6458283633041382\n",
            "Training Accuracy :0.8192600011825562\n",
            "Validation loss :1.6452507820129394\n",
            "Validation Accuracy :0.8183000087738037\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.641058292160034\n",
            "Training Accuracy :0.8231799602508545\n",
            "Validation loss :1.6434447053909302\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.637552131729126\n",
            "Training Accuracy :0.8266399502754211\n",
            "Validation loss :1.6409031967163086\n",
            "Validation Accuracy :0.8217999935150146\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6351701852035523\n",
            "Training Accuracy :0.8291400074958801\n",
            "Validation loss :1.6366587690353394\n",
            "Validation Accuracy :0.825499951839447\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6331902181243896\n",
            "Training Accuracy :0.8298599720001221\n",
            "Validation loss :1.6373300144195557\n",
            "Validation Accuracy :0.8252999782562256\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6318757223129272\n",
            "Training Accuracy :0.831279993057251\n",
            "Validation loss :1.6387748723983764\n",
            "Validation Accuracy :0.8245999813079834\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6302791736221314\n",
            "Training Accuracy :0.832859992980957\n",
            "Validation loss :1.6400312215805053\n",
            "Validation Accuracy :0.821899950504303\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6285591980743408\n",
            "Training Accuracy :0.8343799710273743\n",
            "Validation loss :1.63283896484375\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6272158352279662\n",
            "Training Accuracy :0.8350200057029724\n",
            "Validation loss :1.6325016246795654\n",
            "Validation Accuracy :0.8289999961853027\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.625733334388733\n",
            "Training Accuracy :0.8369799852371216\n",
            "Validation loss :1.6330780687332154\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6248268450164796\n",
            "Training Accuracy :0.8378799557685852\n",
            "Validation loss :1.6329071434020996\n",
            "Validation Accuracy :0.8300999999046326\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.623808211402893\n",
            "Training Accuracy :0.839199960231781\n",
            "Validation loss :1.629986798095703\n",
            "Validation Accuracy :0.8321999907493591\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.623513328590393\n",
            "Training Accuracy :0.8390199542045593\n",
            "Validation loss :1.6289273349761964\n",
            "Validation Accuracy :0.8337000012397766\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6220575173568725\n",
            "Training Accuracy :0.840999960899353\n",
            "Validation loss :1.6294786558151244\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.62197760017395\n",
            "Training Accuracy :0.8402000069618225\n",
            "Validation loss :1.6295843086242676\n",
            "Validation Accuracy :0.8323000073432922\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6206155111312865\n",
            "Training Accuracy :0.8418799638748169\n",
            "Validation loss :1.6326977657318116\n",
            "Validation Accuracy :0.8285999894142151\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6204290853118897\n",
            "Training Accuracy :0.8419399857521057\n",
            "Validation loss :1.62917156124115\n",
            "Validation Accuracy :0.8331999778747559\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6202697259521484\n",
            "Training Accuracy :0.8419599533081055\n",
            "Validation loss :1.627653074645996\n",
            "Validation Accuracy :0.8327999711036682\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6191523017120362\n",
            "Training Accuracy :0.843459963798523\n",
            "Validation loss :1.6288460760116577\n",
            "Validation Accuracy :0.8328999876976013\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6185373761749267\n",
            "Training Accuracy :0.844219982624054\n",
            "Validation loss :1.6295088788986205\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6180227124404907\n",
            "Training Accuracy :0.8446399569511414\n",
            "Validation loss :1.626156489753723\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.617286678237915\n",
            "Training Accuracy :0.8455399870872498\n",
            "Validation loss :1.6278099262237549\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.617250651283264\n",
            "Training Accuracy :0.8454999923706055\n",
            "Validation loss :1.6258412712097168\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6172501355743407\n",
            "Training Accuracy :0.8455399870872498\n",
            "Validation loss :1.6268670194625854\n",
            "Validation Accuracy :0.8344999551773071\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6160681914901733\n",
            "Training Accuracy :0.8463799953460693\n",
            "Validation loss :1.6293631355285645\n",
            "Validation Accuracy :0.833299994468689\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.616032656211853\n",
            "Training Accuracy :0.8466399908065796\n",
            "Validation loss :1.6277166177749633\n",
            "Validation Accuracy :0.8339999914169312\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6158273135757446\n",
            "Training Accuracy :0.8460999727249146\n",
            "Validation loss :1.6269828435897826\n",
            "Validation Accuracy :0.8337000012397766\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6149117269515991\n",
            "Training Accuracy :0.8471599817276001\n",
            "Validation loss :1.6251925134658813\n",
            "Validation Accuracy :0.8366999626159668\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6152871225738525\n",
            "Training Accuracy :0.8469799757003784\n",
            "Validation loss :1.6258659063339234\n",
            "Validation Accuracy :0.8341999650001526\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6151325533294678\n",
            "Training Accuracy :0.847000002861023\n",
            "Validation loss :1.6251823062896729\n",
            "Validation Accuracy :0.8363999724388123\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.614127073059082\n",
            "Training Accuracy :0.8481199741363525\n",
            "Validation loss :1.6259332195281981\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6136540463638305\n",
            "Training Accuracy :0.8488399982452393\n",
            "Validation loss :1.626243931388855\n",
            "Validation Accuracy :0.8353999853134155\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6133841860961915\n",
            "Training Accuracy :0.8491599559783936\n",
            "Validation loss :1.6252086952209472\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.613464261703491\n",
            "Training Accuracy :0.8488799929618835\n",
            "Validation loss :1.6248087726593017\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6133169595336914\n",
            "Training Accuracy :0.8490399718284607\n",
            "Validation loss :1.6251009237289429\n",
            "Validation Accuracy :0.8349999785423279\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6129366032409669\n",
            "Training Accuracy :0.84961998462677\n",
            "Validation loss :1.624265679359436\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6126861178207397\n",
            "Training Accuracy :0.8500799536705017\n",
            "Validation loss :1.626821627807617\n",
            "Validation Accuracy :0.8345999717712402\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.61231395778656\n",
            "Training Accuracy :0.8501399755477905\n",
            "Validation loss :1.6258842393875121\n",
            "Validation Accuracy :0.8341000080108643\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.612036898880005\n",
            "Training Accuracy :0.8502999544143677\n",
            "Validation loss :1.6240259757995605\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.611620903892517\n",
            "Training Accuracy :0.8509799838066101\n",
            "Validation loss :1.6244165969848632\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6114280724716186\n",
            "Training Accuracy :0.8510400056838989\n",
            "Validation loss :1.6237316303253173\n",
            "Validation Accuracy :0.836899995803833\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6118274277114868\n",
            "Training Accuracy :0.8507199883460999\n",
            "Validation loss :1.624224605178833\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6110823798370362\n",
            "Training Accuracy :0.8513199687004089\n",
            "Validation loss :1.6258022499084472\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6117039404678344\n",
            "Training Accuracy :0.8506199717521667\n",
            "Validation loss :1.6228925457000734\n",
            "Validation Accuracy :0.8381999731063843\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6110876176071167\n",
            "Training Accuracy :0.8515799641609192\n",
            "Validation loss :1.6230422828674316\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.61050922454834\n",
            "Training Accuracy :0.851639986038208\n",
            "Validation loss :1.6239333557128905\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.611119366798401\n",
            "Training Accuracy :0.8513599634170532\n",
            "Validation loss :1.627366558456421\n",
            "Validation Accuracy :0.8337000012397766\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6112128143692017\n",
            "Training Accuracy :0.8505399823188782\n",
            "Validation loss :1.6239918285369872\n",
            "Validation Accuracy :0.8366999626159668\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6108245156860352\n",
            "Training Accuracy :0.851639986038208\n",
            "Validation loss :1.6242720769882202\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.610049221801758\n",
            "Training Accuracy :0.8519799709320068\n",
            "Validation loss :1.6234935466766358\n",
            "Validation Accuracy :0.8366000056266785\n",
            "Sparsity=0.03518437208883203\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3025688842010497\n",
            "Training Accuracy :0.10199999809265137\n",
            "Validation loss :2.302521376800537\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3024876483917236\n",
            "Training Accuracy :0.10576000064611435\n",
            "Validation loss :2.302472222137451\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3023255770874025\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3022198585510254\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3014835195159913\n",
            "Training Accuracy :0.14839999377727509\n",
            "Validation loss :2.2997461959838867\n",
            "Validation Accuracy :0.1462000012397766\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.2513047676086426\n",
            "Training Accuracy :0.21164000034332275\n",
            "Validation loss :2.1872278549194335\n",
            "Validation Accuracy :0.3450999855995178\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.980889595298767\n",
            "Training Accuracy :0.5095199942588806\n",
            "Validation loss :1.8340234466552734\n",
            "Validation Accuracy :0.6444000005722046\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.753223395690918\n",
            "Training Accuracy :0.7308200001716614\n",
            "Validation loss :1.7085768842697144\n",
            "Validation Accuracy :0.7674999833106995\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6935676009750367\n",
            "Training Accuracy :0.7781400084495544\n",
            "Validation loss :1.6848995040893555\n",
            "Validation Accuracy :0.7842999696731567\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6767791247177124\n",
            "Training Accuracy :0.7912600040435791\n",
            "Validation loss :1.6730519220352174\n",
            "Validation Accuracy :0.7953000068664551\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6657547995758057\n",
            "Training Accuracy :0.80131995677948\n",
            "Validation loss :1.665040291595459\n",
            "Validation Accuracy :0.8024999499320984\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.657793041305542\n",
            "Training Accuracy :0.8081600069999695\n",
            "Validation loss :1.6561467725753785\n",
            "Validation Accuracy :0.8108999729156494\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6528547296524048\n",
            "Training Accuracy :0.8130599856376648\n",
            "Validation loss :1.6511372203826904\n",
            "Validation Accuracy :0.814799964427948\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6465570824813842\n",
            "Training Accuracy :0.8179399967193604\n",
            "Validation loss :1.6473872596740722\n",
            "Validation Accuracy :0.8176999688148499\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6420256642913817\n",
            "Training Accuracy :0.8232199549674988\n",
            "Validation loss :1.6445827854156494\n",
            "Validation Accuracy :0.8192999958992004\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6391769119262696\n",
            "Training Accuracy :0.8251799941062927\n",
            "Validation loss :1.6432730491638183\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6368979750823975\n",
            "Training Accuracy :0.8275399804115295\n",
            "Validation loss :1.638738791847229\n",
            "Validation Accuracy :0.8237999677658081\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.634127529067993\n",
            "Training Accuracy :0.8299199938774109\n",
            "Validation loss :1.6437973617553712\n",
            "Validation Accuracy :0.8192999958992004\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6326411447525024\n",
            "Training Accuracy :0.8309599757194519\n",
            "Validation loss :1.637051263999939\n",
            "Validation Accuracy :0.8248999714851379\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6301820337295532\n",
            "Training Accuracy :0.8336799740791321\n",
            "Validation loss :1.6351041738510133\n",
            "Validation Accuracy :0.8274999856948853\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6286706783294678\n",
            "Training Accuracy :0.8342199921607971\n",
            "Validation loss :1.6366303287506103\n",
            "Validation Accuracy :0.8258999586105347\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6275047826766968\n",
            "Training Accuracy :0.8352599740028381\n",
            "Validation loss :1.63413662109375\n",
            "Validation Accuracy :0.8285999894142151\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6258740047454834\n",
            "Training Accuracy :0.8368600010871887\n",
            "Validation loss :1.6314702474594116\n",
            "Validation Accuracy :0.8317999839782715\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6249000255966186\n",
            "Training Accuracy :0.8380399942398071\n",
            "Validation loss :1.634612388420105\n",
            "Validation Accuracy :0.8274999856948853\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6240822722625732\n",
            "Training Accuracy :0.8385599851608276\n",
            "Validation loss :1.630195088005066\n",
            "Validation Accuracy :0.8319000005722046\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6239761986923218\n",
            "Training Accuracy :0.8386399745941162\n",
            "Validation loss :1.628990961265564\n",
            "Validation Accuracy :0.8330999612808228\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6235645220565795\n",
            "Training Accuracy :0.8392999768257141\n",
            "Validation loss :1.6300934453964233\n",
            "Validation Accuracy :0.8319999575614929\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6222382845687866\n",
            "Training Accuracy :0.8402199745178223\n",
            "Validation loss :1.6290087152481079\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6206689986801148\n",
            "Training Accuracy :0.8425799608230591\n",
            "Validation loss :1.6299927312850953\n",
            "Validation Accuracy :0.8315999507904053\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6209418811416625\n",
            "Training Accuracy :0.8417399525642395\n",
            "Validation loss :1.6299564052581788\n",
            "Validation Accuracy :0.8314999938011169\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6203531579208375\n",
            "Training Accuracy :0.8421199917793274\n",
            "Validation loss :1.6293366739273072\n",
            "Validation Accuracy :0.8325999975204468\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6199749295425414\n",
            "Training Accuracy :0.842519998550415\n",
            "Validation loss :1.6272156194686889\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6188567176055908\n",
            "Training Accuracy :0.8436599969863892\n",
            "Validation loss :1.6270470993041992\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6177443494033814\n",
            "Training Accuracy :0.8446199893951416\n",
            "Validation loss :1.627580842781067\n",
            "Validation Accuracy :0.8326999545097351\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6175897142028808\n",
            "Training Accuracy :0.8449999690055847\n",
            "Validation loss :1.626764638519287\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.617733037147522\n",
            "Training Accuracy :0.8445599675178528\n",
            "Validation loss :1.6304177621841431\n",
            "Validation Accuracy :0.8308999538421631\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6171934860992432\n",
            "Training Accuracy :0.8452999591827393\n",
            "Validation loss :1.6279027738571168\n",
            "Validation Accuracy :0.8341000080108643\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6165722127914428\n",
            "Training Accuracy :0.845579981803894\n",
            "Validation loss :1.6277724214553833\n",
            "Validation Accuracy :0.8330000042915344\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6160560631942749\n",
            "Training Accuracy :0.8466599583625793\n",
            "Validation loss :1.62902255859375\n",
            "Validation Accuracy :0.8310999870300293\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6150272104644776\n",
            "Training Accuracy :0.8475799560546875\n",
            "Validation loss :1.629359601020813\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6155721279144286\n",
            "Training Accuracy :0.8465999960899353\n",
            "Validation loss :1.62711702003479\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.614779338684082\n",
            "Training Accuracy :0.8473999500274658\n",
            "Validation loss :1.6272673629760743\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.614718286895752\n",
            "Training Accuracy :0.8473399877548218\n",
            "Validation loss :1.6261504734039307\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6140024472427368\n",
            "Training Accuracy :0.8485999703407288\n",
            "Validation loss :1.626847257232666\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6139058066940308\n",
            "Training Accuracy :0.848639965057373\n",
            "Validation loss :1.6283383955001831\n",
            "Validation Accuracy :0.8330999612808228\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6142170352935792\n",
            "Training Accuracy :0.8478399515151978\n",
            "Validation loss :1.6276142398834228\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6143053924179078\n",
            "Training Accuracy :0.848360002040863\n",
            "Validation loss :1.6263872886657715\n",
            "Validation Accuracy :0.8352999687194824\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.613911834411621\n",
            "Training Accuracy :0.8484799861907959\n",
            "Validation loss :1.6253110641479491\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.613549600868225\n",
            "Training Accuracy :0.8489599823951721\n",
            "Validation loss :1.6260939746856689\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6130713512420654\n",
            "Training Accuracy :0.8492799997329712\n",
            "Validation loss :1.6258754978179932\n",
            "Validation Accuracy :0.8346999883651733\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6131725286102294\n",
            "Training Accuracy :0.8497200012207031\n",
            "Validation loss :1.6258356243133545\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6125929824066163\n",
            "Training Accuracy :0.8500199913978577\n",
            "Validation loss :1.6259669357299804\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6123431414031983\n",
            "Training Accuracy :0.8499199748039246\n",
            "Validation loss :1.625951831817627\n",
            "Validation Accuracy :0.8348000049591064\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6128173696899415\n",
            "Training Accuracy :0.8498199582099915\n",
            "Validation loss :1.6272705966949463\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6120820538330078\n",
            "Training Accuracy :0.8502799868583679\n",
            "Validation loss :1.6248741905212403\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6117180318450928\n",
            "Training Accuracy :0.8507999777793884\n",
            "Validation loss :1.6250701503753662\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6117251290512085\n",
            "Training Accuracy :0.850879967212677\n",
            "Validation loss :1.6258718570709227\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6118827755355836\n",
            "Training Accuracy :0.8503999710083008\n",
            "Validation loss :1.626575085067749\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6118093077468871\n",
            "Training Accuracy :0.8505199551582336\n",
            "Validation loss :1.626127505493164\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.611172667579651\n",
            "Training Accuracy :0.8516199588775635\n",
            "Validation loss :1.625170213699341\n",
            "Validation Accuracy :0.8353999853134155\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6112680099487304\n",
            "Training Accuracy :0.8508599996566772\n",
            "Validation loss :1.6245998603820802\n",
            "Validation Accuracy :0.8361999988555908\n",
            "Sparsity=0.028147497671065624\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3025944245910646\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.3025482181549073\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302563384552002\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.3025574737548826\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302522169647217\n",
            "Training Accuracy :0.10151999443769455\n",
            "Validation loss :2.302562636947632\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3024605891418455\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3024914695739747\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.302289999847412\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3022167114257814\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.300802056503296\n",
            "Training Accuracy :0.11617999523878098\n",
            "Validation loss :2.295707989883423\n",
            "Validation Accuracy :0.17960000038146973\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.233768877105713\n",
            "Training Accuracy :0.2198599874973297\n",
            "Validation loss :2.191859195327759\n",
            "Validation Accuracy :0.3240000009536743\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.0329374114990233\n",
            "Training Accuracy :0.45257997512817383\n",
            "Validation loss :1.8881245927810668\n",
            "Validation Accuracy :0.5896999835968018\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.8307561221694946\n",
            "Training Accuracy :0.6481199860572815\n",
            "Validation loss :1.7938145761489868\n",
            "Validation Accuracy :0.6759999990463257\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.773698370361328\n",
            "Training Accuracy :0.6951199769973755\n",
            "Validation loss :1.7594048860549927\n",
            "Validation Accuracy :0.7069999575614929\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.7187300147247315\n",
            "Training Accuracy :0.7528199553489685\n",
            "Validation loss :1.691571815109253\n",
            "Validation Accuracy :0.7797999978065491\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6840352417373656\n",
            "Training Accuracy :0.7848199605941772\n",
            "Validation loss :1.679562728691101\n",
            "Validation Accuracy :0.786300003528595\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6759252349853515\n",
            "Training Accuracy :0.7906000018119812\n",
            "Validation loss :1.6737218475341797\n",
            "Validation Accuracy :0.7917999625205994\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6684692601776123\n",
            "Training Accuracy :0.7975800037384033\n",
            "Validation loss :1.6695599113464354\n",
            "Validation Accuracy :0.7953999638557434\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6636924154663086\n",
            "Training Accuracy :0.8016799688339233\n",
            "Validation loss :1.662908921432495\n",
            "Validation Accuracy :0.8030999898910522\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6591759677886964\n",
            "Training Accuracy :0.8065399527549744\n",
            "Validation loss :1.6601435998916625\n",
            "Validation Accuracy :0.8052999973297119\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.656034917907715\n",
            "Training Accuracy :0.8083800077438354\n",
            "Validation loss :1.6566977821350097\n",
            "Validation Accuracy :0.8072999715805054\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6530999969100952\n",
            "Training Accuracy :0.8113799691200256\n",
            "Validation loss :1.6540284515380859\n",
            "Validation Accuracy :0.8097999691963196\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6508364562225342\n",
            "Training Accuracy :0.8131799697875977\n",
            "Validation loss :1.6520511039733887\n",
            "Validation Accuracy :0.8122999668121338\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6492005450057983\n",
            "Training Accuracy :0.8146799802780151\n",
            "Validation loss :1.6491103174209594\n",
            "Validation Accuracy :0.8141999840736389\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6473084265518187\n",
            "Training Accuracy :0.8157999515533447\n",
            "Validation loss :1.6481288808822632\n",
            "Validation Accuracy :0.8167999982833862\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6453291223526\n",
            "Training Accuracy :0.8180399537086487\n",
            "Validation loss :1.6462525732040405\n",
            "Validation Accuracy :0.8169999718666077\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.643432254371643\n",
            "Training Accuracy :0.819920003414154\n",
            "Validation loss :1.6447944049835206\n",
            "Validation Accuracy :0.817799985408783\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.642981519241333\n",
            "Training Accuracy :0.8203399777412415\n",
            "Validation loss :1.6441035146713256\n",
            "Validation Accuracy :0.818399965763092\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.640877186050415\n",
            "Training Accuracy :0.8221799731254578\n",
            "Validation loss :1.6429633855819703\n",
            "Validation Accuracy :0.8188999891281128\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.638691056213379\n",
            "Training Accuracy :0.8245199918746948\n",
            "Validation loss :1.6405920433044434\n",
            "Validation Accuracy :0.8219999670982361\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6378959441757202\n",
            "Training Accuracy :0.8252599835395813\n",
            "Validation loss :1.6401244138717652\n",
            "Validation Accuracy :0.8222000002861023\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6366784912490844\n",
            "Training Accuracy :0.8262999653816223\n",
            "Validation loss :1.6386355327606201\n",
            "Validation Accuracy :0.8230999708175659\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6364231958770752\n",
            "Training Accuracy :0.826259970664978\n",
            "Validation loss :1.6422761985778809\n",
            "Validation Accuracy :0.8197999596595764\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6358514739227294\n",
            "Training Accuracy :0.8268599510192871\n",
            "Validation loss :1.6386740259170531\n",
            "Validation Accuracy :0.8237999677658081\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6341847690582276\n",
            "Training Accuracy :0.8287999629974365\n",
            "Validation loss :1.6389983396530152\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.633558643913269\n",
            "Training Accuracy :0.8286399841308594\n",
            "Validation loss :1.6371291276931763\n",
            "Validation Accuracy :0.824400007724762\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.632813457069397\n",
            "Training Accuracy :0.8299599885940552\n",
            "Validation loss :1.6367824462890626\n",
            "Validation Accuracy :0.8255999684333801\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6331899509048462\n",
            "Training Accuracy :0.8295599818229675\n",
            "Validation loss :1.6356791372299195\n",
            "Validation Accuracy :0.8258000016212463\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.631839754295349\n",
            "Training Accuracy :0.8314200043678284\n",
            "Validation loss :1.6351514862060548\n",
            "Validation Accuracy :0.827299952507019\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6314829174041747\n",
            "Training Accuracy :0.8315799832344055\n",
            "Validation loss :1.6355368453979493\n",
            "Validation Accuracy :0.824999988079071\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6316703942108155\n",
            "Training Accuracy :0.8307999968528748\n",
            "Validation loss :1.6340300743103027\n",
            "Validation Accuracy :0.8281999826431274\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6306010726547242\n",
            "Training Accuracy :0.8319799900054932\n",
            "Validation loss :1.6334030450820922\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6306269980621337\n",
            "Training Accuracy :0.8320399522781372\n",
            "Validation loss :1.636801933670044\n",
            "Validation Accuracy :0.8251000046730042\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6299323192977906\n",
            "Training Accuracy :0.8326599597930908\n",
            "Validation loss :1.6336957752227783\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6289559228515624\n",
            "Training Accuracy :0.8338199853897095\n",
            "Validation loss :1.6350243528366089\n",
            "Validation Accuracy :0.8253999948501587\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6290369818115233\n",
            "Training Accuracy :0.8335399627685547\n",
            "Validation loss :1.6338323671340942\n",
            "Validation Accuracy :0.8277999758720398\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6282583084487916\n",
            "Training Accuracy :0.8345999717712402\n",
            "Validation loss :1.6323770904541015\n",
            "Validation Accuracy :0.8287000060081482\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6287979022979737\n",
            "Training Accuracy :0.8338599801063538\n",
            "Validation loss :1.6332533756256105\n",
            "Validation Accuracy :0.8281999826431274\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6281857851791381\n",
            "Training Accuracy :0.8340399861335754\n",
            "Validation loss :1.6325814115524293\n",
            "Validation Accuracy :0.8285999894142151\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6276053359985352\n",
            "Training Accuracy :0.8345999717712402\n",
            "Validation loss :1.633533016204834\n",
            "Validation Accuracy :0.8280999660491943\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6275658507537842\n",
            "Training Accuracy :0.8347199559211731\n",
            "Validation loss :1.63283973903656\n",
            "Validation Accuracy :0.8287000060081482\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6263334795379638\n",
            "Training Accuracy :0.8362799882888794\n",
            "Validation loss :1.6322299432754517\n",
            "Validation Accuracy :0.8291999697685242\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6266794830703735\n",
            "Training Accuracy :0.8359400033950806\n",
            "Validation loss :1.6303741033554078\n",
            "Validation Accuracy :0.8308999538421631\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6262402068328858\n",
            "Training Accuracy :0.8357200026512146\n",
            "Validation loss :1.630120008468628\n",
            "Validation Accuracy :0.8317999839782715\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6253738375473021\n",
            "Training Accuracy :0.8368200063705444\n",
            "Validation loss :1.630550124359131\n",
            "Validation Accuracy :0.830299973487854\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6250322515106201\n",
            "Training Accuracy :0.8374199867248535\n",
            "Validation loss :1.6305510391235352\n",
            "Validation Accuracy :0.8296999931335449\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6241885845184325\n",
            "Training Accuracy :0.8387599587440491\n",
            "Validation loss :1.6298940137863158\n",
            "Validation Accuracy :0.8327999711036682\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6244640964126587\n",
            "Training Accuracy :0.8378799557685852\n",
            "Validation loss :1.6309012859344483\n",
            "Validation Accuracy :0.8313999772071838\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6258097234344482\n",
            "Training Accuracy :0.8363800048828125\n",
            "Validation loss :1.6309680952072143\n",
            "Validation Accuracy :0.8312999606132507\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6240945098114015\n",
            "Training Accuracy :0.838379979133606\n",
            "Validation loss :1.6318466423034668\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.624676812095642\n",
            "Training Accuracy :0.8378399610519409\n",
            "Validation loss :1.6300325199127197\n",
            "Validation Accuracy :0.8323999643325806\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6242530542755127\n",
            "Training Accuracy :0.8380399942398071\n",
            "Validation loss :1.6283366584777832\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.623302887878418\n",
            "Training Accuracy :0.8388599753379822\n",
            "Validation loss :1.6299555446624756\n",
            "Validation Accuracy :0.8313999772071838\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.623595485458374\n",
            "Training Accuracy :0.8385799527168274\n",
            "Validation loss :1.6280084693908692\n",
            "Validation Accuracy :0.8343999981880188\n",
            "Sparsity=0.022517998136852502\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3026174452209474\n",
            "Training Accuracy :0.09798000007867813\n",
            "Validation loss :2.3025838283538818\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3026019448852537\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.3026249969482424\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302582639541626\n",
            "Training Accuracy :0.10117999464273453\n",
            "Validation loss :2.3026539081573487\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025714849090577\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026834762573243\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025645555114744\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026967342376707\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025525233459474\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302682883453369\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.302533703765869\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026759201049805\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.3025140943908693\n",
            "Training Accuracy :0.10102000087499619\n",
            "Validation loss :2.3026551803588866\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.302471011505127\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302622186279297\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3023618156433105\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3024459995269777\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.3018079513549803\n",
            "Training Accuracy :0.10975999385118484\n",
            "Validation loss :2.3009161197662356\n",
            "Validation Accuracy :0.15240000188350677\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.265879384613037\n",
            "Training Accuracy :0.18783999979496002\n",
            "Validation loss :2.2165348731994627\n",
            "Validation Accuracy :0.2467999905347824\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.14490186088562\n",
            "Training Accuracy :0.34039998054504395\n",
            "Validation loss :2.0155170770645143\n",
            "Validation Accuracy :0.4664999842643738\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.8980246558380127\n",
            "Training Accuracy :0.5884400010108948\n",
            "Validation loss :1.8261798097610473\n",
            "Validation Accuracy :0.6467999815940857\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.8022316470718385\n",
            "Training Accuracy :0.6680200099945068\n",
            "Validation loss :1.7871480005264282\n",
            "Validation Accuracy :0.6801999807357788\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.7718558954238892\n",
            "Training Accuracy :0.693619966506958\n",
            "Validation loss :1.7639754371643066\n",
            "Validation Accuracy :0.7005000114440918\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.7507960186004639\n",
            "Training Accuracy :0.7131999731063843\n",
            "Validation loss :1.7099362117767334\n",
            "Validation Accuracy :0.7619999647140503\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6957955529403685\n",
            "Training Accuracy :0.7724799513816833\n",
            "Validation loss :1.6901914110183716\n",
            "Validation Accuracy :0.7763999700546265\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6857994617462158\n",
            "Training Accuracy :0.7801600098609924\n",
            "Validation loss :1.686270516395569\n",
            "Validation Accuracy :0.7795999646186829\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6806113547515869\n",
            "Training Accuracy :0.7839799523353577\n",
            "Validation loss :1.683260043334961\n",
            "Validation Accuracy :0.7807999849319458\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6770519690322876\n",
            "Training Accuracy :0.7874199748039246\n",
            "Validation loss :1.6806152685165405\n",
            "Validation Accuracy :0.7835999727249146\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6733554012298584\n",
            "Training Accuracy :0.7912600040435791\n",
            "Validation loss :1.6770740900039673\n",
            "Validation Accuracy :0.7849000096321106\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.671899221496582\n",
            "Training Accuracy :0.7920999526977539\n",
            "Validation loss :1.6747899995803832\n",
            "Validation Accuracy :0.7871999740600586\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6699420361709594\n",
            "Training Accuracy :0.7940599918365479\n",
            "Validation loss :1.6758730710983276\n",
            "Validation Accuracy :0.7865999937057495\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6688879796981813\n",
            "Training Accuracy :0.7941799759864807\n",
            "Validation loss :1.6731753162384033\n",
            "Validation Accuracy :0.7886999845504761\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6679175115585327\n",
            "Training Accuracy :0.7951200008392334\n",
            "Validation loss :1.6713303787231446\n",
            "Validation Accuracy :0.7900999784469604\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6662867646026611\n",
            "Training Accuracy :0.7968999743461609\n",
            "Validation loss :1.6678696018218995\n",
            "Validation Accuracy :0.7938999533653259\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6648380596542358\n",
            "Training Accuracy :0.7983799576759338\n",
            "Validation loss :1.6676244571685792\n",
            "Validation Accuracy :0.7949000000953674\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6641329455566407\n",
            "Training Accuracy :0.7987599968910217\n",
            "Validation loss :1.666685368156433\n",
            "Validation Accuracy :0.7947999835014343\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.66318755153656\n",
            "Training Accuracy :0.7995799779891968\n",
            "Validation loss :1.6675663103103637\n",
            "Validation Accuracy :0.7947999835014343\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6606240100479126\n",
            "Training Accuracy :0.8023599982261658\n",
            "Validation loss :1.666813988494873\n",
            "Validation Accuracy :0.7942000031471252\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6590771181488038\n",
            "Training Accuracy :0.803659975528717\n",
            "Validation loss :1.6648719583511353\n",
            "Validation Accuracy :0.7975999712944031\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6580594500732422\n",
            "Training Accuracy :0.8050199747085571\n",
            "Validation loss :1.6633541372299194\n",
            "Validation Accuracy :0.7986999750137329\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6581590688705445\n",
            "Training Accuracy :0.8049799799919128\n",
            "Validation loss :1.6616124565124513\n",
            "Validation Accuracy :0.8009999990463257\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6554770287704468\n",
            "Training Accuracy :0.8071399927139282\n",
            "Validation loss :1.6632100692749023\n",
            "Validation Accuracy :0.7982999682426453\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.655967151145935\n",
            "Training Accuracy :0.8067799806594849\n",
            "Validation loss :1.6598031089782714\n",
            "Validation Accuracy :0.8014999628067017\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6534857958221436\n",
            "Training Accuracy :0.8094399571418762\n",
            "Validation loss :1.6617221557617188\n",
            "Validation Accuracy :0.8018999695777893\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6517234308242799\n",
            "Training Accuracy :0.8111000061035156\n",
            "Validation loss :1.654740100479126\n",
            "Validation Accuracy :0.8078999519348145\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6506480270385742\n",
            "Training Accuracy :0.8122599720954895\n",
            "Validation loss :1.654359409713745\n",
            "Validation Accuracy :0.8082000017166138\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6500075384521484\n",
            "Training Accuracy :0.813319981098175\n",
            "Validation loss :1.6529593633651734\n",
            "Validation Accuracy :0.808899998664856\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6486218253326417\n",
            "Training Accuracy :0.8140999674797058\n",
            "Validation loss :1.6536145944595337\n",
            "Validation Accuracy :0.809499979019165\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.64812684299469\n",
            "Training Accuracy :0.814740002155304\n",
            "Validation loss :1.653646752166748\n",
            "Validation Accuracy :0.8083999752998352\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6465198656463622\n",
            "Training Accuracy :0.816540002822876\n",
            "Validation loss :1.6506092741012572\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.645015277633667\n",
            "Training Accuracy :0.8180800080299377\n",
            "Validation loss :1.6524465175628662\n",
            "Validation Accuracy :0.8091999888420105\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6445177004623412\n",
            "Training Accuracy :0.8180800080299377\n",
            "Validation loss :1.6489940120697022\n",
            "Validation Accuracy :0.8127999901771545\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6436544814300538\n",
            "Training Accuracy :0.8198599815368652\n",
            "Validation loss :1.6514973114013671\n",
            "Validation Accuracy :0.8101999759674072\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6433678759765624\n",
            "Training Accuracy :0.8198800086975098\n",
            "Validation loss :1.6493991367340088\n",
            "Validation Accuracy :0.8138999938964844\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6432233887481689\n",
            "Training Accuracy :0.8196600079536438\n",
            "Validation loss :1.6485310312271118\n",
            "Validation Accuracy :0.8136000037193298\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6420055899429322\n",
            "Training Accuracy :0.8213199973106384\n",
            "Validation loss :1.64938387966156\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6411630478668213\n",
            "Training Accuracy :0.8216399550437927\n",
            "Validation loss :1.646750429725647\n",
            "Validation Accuracy :0.8152999877929688\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.641328237991333\n",
            "Training Accuracy :0.8217799663543701\n",
            "Validation loss :1.6502285228729248\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6411429694366455\n",
            "Training Accuracy :0.8209399580955505\n",
            "Validation loss :1.6453085205078124\n",
            "Validation Accuracy :0.8167999982833862\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6398188732528687\n",
            "Training Accuracy :0.8228200078010559\n",
            "Validation loss :1.644810058784485\n",
            "Validation Accuracy :0.8173999786376953\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.639552766494751\n",
            "Training Accuracy :0.8230199813842773\n",
            "Validation loss :1.644545665550232\n",
            "Validation Accuracy :0.8166999816894531\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6399168173599243\n",
            "Training Accuracy :0.8226400017738342\n",
            "Validation loss :1.6459500194549561\n",
            "Validation Accuracy :0.8158999681472778\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6394583386993409\n",
            "Training Accuracy :0.8229599595069885\n",
            "Validation loss :1.6449032333374023\n",
            "Validation Accuracy :0.8176999688148499\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6387511185073853\n",
            "Training Accuracy :0.8238399624824524\n",
            "Validation loss :1.6417950332641602\n",
            "Validation Accuracy :0.8204999566078186\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.637745453567505\n",
            "Training Accuracy :0.8253999948501587\n",
            "Validation loss :1.6458074453353881\n",
            "Validation Accuracy :0.8169999718666077\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6378128122329711\n",
            "Training Accuracy :0.8243599534034729\n",
            "Validation loss :1.6437625402450562\n",
            "Validation Accuracy :0.8172000050544739\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.637437980041504\n",
            "Training Accuracy :0.825219988822937\n",
            "Validation loss :1.6431843814849854\n",
            "Validation Accuracy :0.8191999793052673\n",
            "Sparsity=0.018014398509482003\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3026175355529785\n",
            "Training Accuracy :0.09969999641180038\n",
            "Validation loss :2.3025823570251465\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302602190704346\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.3026269691467287\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3025924755096434\n",
            "Training Accuracy :0.10119999945163727\n",
            "Validation loss :2.30264515953064\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.302585284423828\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026675106048584\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.302575467376709\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026836673736573\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025663278198243\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027229000091554\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.302560664138794\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302728302383423\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.302549899978638\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027235553741456\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.3025417378234865\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027229778289793\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3025313649749757\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302714255905151\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.302506632156372\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026859363555907\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.302471222000122\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302649811553955\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.3023958851623534\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302539688873291\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.3021633235931396\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3020840187072755\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.2990749839782714\n",
            "Training Accuracy :0.1585799902677536\n",
            "Validation loss :2.2847804203033446\n",
            "Validation Accuracy :0.19290000200271606\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.200114801712036\n",
            "Training Accuracy :0.2613599896430969\n",
            "Validation loss :2.0611080772399903\n",
            "Validation Accuracy :0.41689997911453247\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.9531324633026124\n",
            "Training Accuracy :0.5219199657440186\n",
            "Validation loss :1.8565302684783935\n",
            "Validation Accuracy :0.6305999755859375\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.8140298595809936\n",
            "Training Accuracy :0.6613799929618835\n",
            "Validation loss :1.7828214057922362\n",
            "Validation Accuracy :0.6859999895095825\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.7650415949249267\n",
            "Training Accuracy :0.7035399675369263\n",
            "Validation loss :1.7185633600234986\n",
            "Validation Accuracy :0.7555999755859375\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.7065872766113281\n",
            "Training Accuracy :0.7638199925422668\n",
            "Validation loss :1.700187788772583\n",
            "Validation Accuracy :0.7662000060081482\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6917630014801026\n",
            "Training Accuracy :0.7753599882125854\n",
            "Validation loss :1.6926327936172485\n",
            "Validation Accuracy :0.7728999853134155\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6841194930267334\n",
            "Training Accuracy :0.7814199924468994\n",
            "Validation loss :1.6841732610702516\n",
            "Validation Accuracy :0.7798999547958374\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6798378986358642\n",
            "Training Accuracy :0.7855599522590637\n",
            "Validation loss :1.6811308069229125\n",
            "Validation Accuracy :0.7823999524116516\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6761701931762696\n",
            "Training Accuracy :0.7885800004005432\n",
            "Validation loss :1.6779187326431275\n",
            "Validation Accuracy :0.7871999740600586\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.674000097579956\n",
            "Training Accuracy :0.7896599769592285\n",
            "Validation loss :1.6742658155441283\n",
            "Validation Accuracy :0.7884999513626099\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6694112329483033\n",
            "Training Accuracy :0.7949199676513672\n",
            "Validation loss :1.6713043418884277\n",
            "Validation Accuracy :0.7915999889373779\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.666309723815918\n",
            "Training Accuracy :0.7980200052261353\n",
            "Validation loss :1.668811464881897\n",
            "Validation Accuracy :0.7943999767303467\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6636987575912476\n",
            "Training Accuracy :0.8006799817085266\n",
            "Validation loss :1.6665613702774047\n",
            "Validation Accuracy :0.79749995470047\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6606310879898072\n",
            "Training Accuracy :0.8039000034332275\n",
            "Validation loss :1.6624600799560547\n",
            "Validation Accuracy :0.8004999756813049\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6578202313232422\n",
            "Training Accuracy :0.8062799572944641\n",
            "Validation loss :1.658583673286438\n",
            "Validation Accuracy :0.8042999505996704\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6548585828399658\n",
            "Training Accuracy :0.8092799782752991\n",
            "Validation loss :1.6580840929031373\n",
            "Validation Accuracy :0.8039999604225159\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6531610298919677\n",
            "Training Accuracy :0.8109399676322937\n",
            "Validation loss :1.658560270881653\n",
            "Validation Accuracy :0.8032999634742737\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6519670429229736\n",
            "Training Accuracy :0.8121199607849121\n",
            "Validation loss :1.6568453493118287\n",
            "Validation Accuracy :0.8065999746322632\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6492629015731812\n",
            "Training Accuracy :0.8145599961280823\n",
            "Validation loss :1.6543635498046876\n",
            "Validation Accuracy :0.8077999949455261\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6477980422592162\n",
            "Training Accuracy :0.8159199953079224\n",
            "Validation loss :1.6510115591049195\n",
            "Validation Accuracy :0.8127999901771545\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6474714233398438\n",
            "Training Accuracy :0.8162399530410767\n",
            "Validation loss :1.6491416358947755\n",
            "Validation Accuracy :0.8138999938964844\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6458239220428468\n",
            "Training Accuracy :0.8177799582481384\n",
            "Validation loss :1.6509280838012694\n",
            "Validation Accuracy :0.8126999735832214\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.644473433265686\n",
            "Training Accuracy :0.8185199499130249\n",
            "Validation loss :1.6469651258468627\n",
            "Validation Accuracy :0.8157999515533447\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6433706985473633\n",
            "Training Accuracy :0.8199799656867981\n",
            "Validation loss :1.6456769702911378\n",
            "Validation Accuracy :0.8186999559402466\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6427132444000243\n",
            "Training Accuracy :0.821179986000061\n",
            "Validation loss :1.6459939069747924\n",
            "Validation Accuracy :0.8175999522209167\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.641468124923706\n",
            "Training Accuracy :0.8220599889755249\n",
            "Validation loss :1.6463820098876953\n",
            "Validation Accuracy :0.8167999982833862\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6403615558624267\n",
            "Training Accuracy :0.8225399851799011\n",
            "Validation loss :1.64450431804657\n",
            "Validation Accuracy :0.8192999958992004\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6403559408569337\n",
            "Training Accuracy :0.8224999904632568\n",
            "Validation loss :1.6433284086227418\n",
            "Validation Accuracy :0.819599986076355\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6396842752456664\n",
            "Training Accuracy :0.8229399919509888\n",
            "Validation loss :1.6437141450881958\n",
            "Validation Accuracy :0.8181999921798706\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6399192110443115\n",
            "Training Accuracy :0.8221799731254578\n",
            "Validation loss :1.6433218145370483\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6393155364990235\n",
            "Training Accuracy :0.82396000623703\n",
            "Validation loss :1.6444909826278686\n",
            "Validation Accuracy :0.8184999823570251\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.639175541419983\n",
            "Training Accuracy :0.8234999775886536\n",
            "Validation loss :1.6419281442642213\n",
            "Validation Accuracy :0.8204999566078186\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6377636180877686\n",
            "Training Accuracy :0.8248199820518494\n",
            "Validation loss :1.6423758949279785\n",
            "Validation Accuracy :0.8210999965667725\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6379769440078735\n",
            "Training Accuracy :0.8253600001335144\n",
            "Validation loss :1.645362810897827\n",
            "Validation Accuracy :0.8158999681472778\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6374409601593019\n",
            "Training Accuracy :0.8244199752807617\n",
            "Validation loss :1.6407535327911378\n",
            "Validation Accuracy :0.8212999701499939\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.636859227371216\n",
            "Training Accuracy :0.825760006904602\n",
            "Validation loss :1.6410202270507812\n",
            "Validation Accuracy :0.8205999732017517\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.637434806213379\n",
            "Training Accuracy :0.824999988079071\n",
            "Validation loss :1.6467060808181764\n",
            "Validation Accuracy :0.8144999742507935\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6366143359375\n",
            "Training Accuracy :0.8265599608421326\n",
            "Validation loss :1.6431341205596923\n",
            "Validation Accuracy :0.818399965763092\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6367148162460328\n",
            "Training Accuracy :0.8256399631500244\n",
            "Validation loss :1.6410639219284058\n",
            "Validation Accuracy :0.8208999633789062\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6348787633514403\n",
            "Training Accuracy :0.8279799818992615\n",
            "Validation loss :1.6400037546157837\n",
            "Validation Accuracy :0.8210999965667725\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6350173226547242\n",
            "Training Accuracy :0.8276399970054626\n",
            "Validation loss :1.6444198177337646\n",
            "Validation Accuracy :0.8173999786376953\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6347474756240845\n",
            "Training Accuracy :0.8275600075721741\n",
            "Validation loss :1.6388565826416015\n",
            "Validation Accuracy :0.8228999972343445\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6344349674224854\n",
            "Training Accuracy :0.8279599547386169\n",
            "Validation loss :1.6452264490127564\n",
            "Validation Accuracy :0.8161999583244324\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.634711226158142\n",
            "Training Accuracy :0.8274799585342407\n",
            "Validation loss :1.6377600828170777\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.633674867553711\n",
            "Training Accuracy :0.8289600014686584\n",
            "Validation loss :1.6407171964645386\n",
            "Validation Accuracy :0.821899950504303\n",
            "Sparsity=0.014411518807585602\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3026223815917968\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.302608177947998\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3026013284301756\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.3026314109802244\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3025921297454834\n",
            "Training Accuracy :0.1008399948477745\n",
            "Validation loss :2.3026678318023683\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025847175598146\n",
            "Training Accuracy :0.1005999967455864\n",
            "Validation loss :2.3026998817443847\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.302581919784546\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027204048156737\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025758456420897\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027337265014647\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.302574060897827\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027398399353025\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.3025720642089844\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027388317108155\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.3025661557006836\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027477756500243\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.302568608627319\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027534229278563\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.302562283935547\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027614776611327\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.3025560218048096\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302750363540649\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.302551202087402\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027442733764647\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.302542749557495\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302734581756592\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.3025354307556154\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027333911895753\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.302522625427246\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302730396270752\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.302501974182129\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302697365951538\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.302466759490967\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026441341400146\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.3024059815216065\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3025729278564455\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.3022823499298095\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3023862117767333\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :2.3019288374328615\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3017391937255858\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :2.299703401489258\n",
            "Training Accuracy :0.1539599895477295\n",
            "Validation loss :2.2943847106933593\n",
            "Validation Accuracy :0.2224999964237213\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :2.174460080795288\n",
            "Training Accuracy :0.36451998353004456\n",
            "Validation loss :1.973431686782837\n",
            "Validation Accuracy :0.5424999594688416\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.897589631690979\n",
            "Training Accuracy :0.5834400057792664\n",
            "Validation loss :1.8533915019989013\n",
            "Validation Accuracy :0.6132000088691711\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.8162752321624756\n",
            "Training Accuracy :0.6680600047111511\n",
            "Validation loss :1.7593126508712769\n",
            "Validation Accuracy :0.7261999845504761\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.7412049169540404\n",
            "Training Accuracy :0.7349799871444702\n",
            "Validation loss :1.7236241132736205\n",
            "Validation Accuracy :0.7476999759674072\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.715690400352478\n",
            "Training Accuracy :0.7540599703788757\n",
            "Validation loss :1.7053158153533936\n",
            "Validation Accuracy :0.7637999653816223\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.7012055270767212\n",
            "Training Accuracy :0.7656999826431274\n",
            "Validation loss :1.6977744785308837\n",
            "Validation Accuracy :0.7680000066757202\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.690800325317383\n",
            "Training Accuracy :0.7753799557685852\n",
            "Validation loss :1.6897022296905517\n",
            "Validation Accuracy :0.7760999798774719\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6844362634658814\n",
            "Training Accuracy :0.7818599939346313\n",
            "Validation loss :1.68336295337677\n",
            "Validation Accuracy :0.7811999917030334\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6798240670394897\n",
            "Training Accuracy :0.7854399681091309\n",
            "Validation loss :1.6782354732513427\n",
            "Validation Accuracy :0.7872999906539917\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6766493170928956\n",
            "Training Accuracy :0.7879999876022339\n",
            "Validation loss :1.678718609046936\n",
            "Validation Accuracy :0.7872999906539917\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6733807432556151\n",
            "Training Accuracy :0.7910199761390686\n",
            "Validation loss :1.6733737575531007\n",
            "Validation Accuracy :0.7913999557495117\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.670902501564026\n",
            "Training Accuracy :0.7935599684715271\n",
            "Validation loss :1.6740979705810546\n",
            "Validation Accuracy :0.7901999950408936\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6685270134735108\n",
            "Training Accuracy :0.7964800000190735\n",
            "Validation loss :1.6740227893829345\n",
            "Validation Accuracy :0.7892000079154968\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6671597116088868\n",
            "Training Accuracy :0.7966799736022949\n",
            "Validation loss :1.6666365701675414\n",
            "Validation Accuracy :0.7971999645233154\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6639883666229247\n",
            "Training Accuracy :0.8005799651145935\n",
            "Validation loss :1.6656372301101685\n",
            "Validation Accuracy :0.7958999872207642\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6625084352874755\n",
            "Training Accuracy :0.8013799786567688\n",
            "Validation loss :1.662925133895874\n",
            "Validation Accuracy :0.7994999885559082\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6612625603485107\n",
            "Training Accuracy :0.8021399974822998\n",
            "Validation loss :1.6622981548309326\n",
            "Validation Accuracy :0.7999999523162842\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6589994075775147\n",
            "Training Accuracy :0.8050400018692017\n",
            "Validation loss :1.6629458200454712\n",
            "Validation Accuracy :0.8007999658584595\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6580310809707641\n",
            "Training Accuracy :0.8052999973297119\n",
            "Validation loss :1.658788819694519\n",
            "Validation Accuracy :0.8042999505996704\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6567338360977173\n",
            "Training Accuracy :0.806939959526062\n",
            "Validation loss :1.6609072525024413\n",
            "Validation Accuracy :0.8021000027656555\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6551672052764892\n",
            "Training Accuracy :0.8082999587059021\n",
            "Validation loss :1.657449468421936\n",
            "Validation Accuracy :0.8064000010490417\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6536375713729858\n",
            "Training Accuracy :0.8101800084114075\n",
            "Validation loss :1.6546934947967529\n",
            "Validation Accuracy :0.8080999851226807\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6519765796661376\n",
            "Training Accuracy :0.8111799955368042\n",
            "Validation loss :1.6533508296966553\n",
            "Validation Accuracy :0.8100000023841858\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6498101555633544\n",
            "Training Accuracy :0.8137999773025513\n",
            "Validation loss :1.6528583570480346\n",
            "Validation Accuracy :0.8108999729156494\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6486040701293945\n",
            "Training Accuracy :0.8155999779701233\n",
            "Validation loss :1.6560200033187866\n",
            "Validation Accuracy :0.8070999979972839\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6469171313095092\n",
            "Training Accuracy :0.8168999552726746\n",
            "Validation loss :1.6499989135742188\n",
            "Validation Accuracy :0.8126999735832214\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.645578264389038\n",
            "Training Accuracy :0.8186599612236023\n",
            "Validation loss :1.6477175371170043\n",
            "Validation Accuracy :0.8149999976158142\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6443286309051515\n",
            "Training Accuracy :0.8192999958992004\n",
            "Validation loss :1.64699960231781\n",
            "Validation Accuracy :0.8159999847412109\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6430067184448243\n",
            "Training Accuracy :0.8206599950790405\n",
            "Validation loss :1.6453705549240112\n",
            "Validation Accuracy :0.8172999620437622\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.642701682357788\n",
            "Training Accuracy :0.8200599551200867\n",
            "Validation loss :1.6459885841369628\n",
            "Validation Accuracy :0.8172999620437622\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6415786125946046\n",
            "Training Accuracy :0.8221399784088135\n",
            "Validation loss :1.6448003938674927\n",
            "Validation Accuracy :0.8184999823570251\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6409139581298828\n",
            "Training Accuracy :0.8233399987220764\n",
            "Validation loss :1.6439962480545045\n",
            "Validation Accuracy :0.8197999596595764\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.640522764930725\n",
            "Training Accuracy :0.8228999972343445\n",
            "Validation loss :1.6441420539855958\n",
            "Validation Accuracy :0.8174999952316284\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.639163909225464\n",
            "Training Accuracy :0.823699951171875\n",
            "Validation loss :1.6460423164367677\n",
            "Validation Accuracy :0.8169999718666077\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6391697367095948\n",
            "Training Accuracy :0.823699951171875\n",
            "Validation loss :1.6439469261169433\n",
            "Validation Accuracy :0.8190999627113342\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6385042584228515\n",
            "Training Accuracy :0.8242999911308289\n",
            "Validation loss :1.642821004486084\n",
            "Validation Accuracy :0.8186999559402466\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6382301654815674\n",
            "Training Accuracy :0.8246399760246277\n",
            "Validation loss :1.6423348876953126\n",
            "Validation Accuracy :0.8198999762535095\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6374297054672242\n",
            "Training Accuracy :0.8253600001335144\n",
            "Validation loss :1.6418097854614258\n",
            "Validation Accuracy :0.8192999958992004\n",
            "Sparsity=0.011529215046068483\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302621397857666\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.30260725440979\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302606979522705\n",
            "Training Accuracy :0.09922000020742416\n",
            "Validation loss :2.3026322376251223\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3025968798065186\n",
            "Training Accuracy :0.09981999546289444\n",
            "Validation loss :2.3026681583404542\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025899291229246\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302700613021851\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025842002868653\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027179637908937\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025854307556153\n",
            "Training Accuracy :0.10053999722003937\n",
            "Validation loss :2.3027387733459475\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.3025817051696778\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30274528465271\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.302578060760498\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027590858459472\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.3025805899047853\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027483657836916\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3025756553649903\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30275011138916\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.3025738315582274\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302765587234497\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.3025739305114747\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027658348083495\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.3025726126861574\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027560771942137\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.3025722319030764\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027671176910403\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.302570923233032\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027633052825927\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.302568133010864\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027624095916748\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.302565839996338\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027733779907225\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.3025616996765135\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30276422996521\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.3025566960144044\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027612033843994\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.3025545860290526\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302754054641724\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :2.3025438133239744\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027385078430176\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :2.3025358984375\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302732345199585\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :2.3025243691253663\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027228912353515\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :2.302497932357788\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302690093612671\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :2.3024609428405762\n",
            "Training Accuracy :0.1005999967455864\n",
            "Validation loss :2.3026360736846923\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :2.3023837855529785\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3025312313079835\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :2.3021710570526124\n",
            "Training Accuracy :0.10573999583721161\n",
            "Validation loss :2.3021453647613526\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :2.3004834480285643\n",
            "Training Accuracy :0.18473999202251434\n",
            "Validation loss :2.2952418029785155\n",
            "Validation Accuracy :0.17960000038146973\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :2.23632352935791\n",
            "Training Accuracy :0.21375998854637146\n",
            "Validation loss :2.1640042652130127\n",
            "Validation Accuracy :0.313400000333786\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :2.0927594080352785\n",
            "Training Accuracy :0.36785998940467834\n",
            "Validation loss :2.0503335330963135\n",
            "Validation Accuracy :0.4315999746322632\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :2.0153450860595705\n",
            "Training Accuracy :0.4518199861049652\n",
            "Validation loss :1.951486650466919\n",
            "Validation Accuracy :0.5376999974250793\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.915779959793091\n",
            "Training Accuracy :0.5617799758911133\n",
            "Validation loss :1.892637165260315\n",
            "Validation Accuracy :0.5863999724388123\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.8855265628433227\n",
            "Training Accuracy :0.5854600071907043\n",
            "Validation loss :1.8724633123397827\n",
            "Validation Accuracy :0.5943999886512756\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.8721499541473388\n",
            "Training Accuracy :0.5952799916267395\n",
            "Validation loss :1.861661923599243\n",
            "Validation Accuracy :0.6040999889373779\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.8636061235809327\n",
            "Training Accuracy :0.601639986038208\n",
            "Validation loss :1.8573590984344484\n",
            "Validation Accuracy :0.6083999872207642\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.856449712562561\n",
            "Training Accuracy :0.6075599789619446\n",
            "Validation loss :1.8497634506225586\n",
            "Validation Accuracy :0.6140999794006348\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.849140131187439\n",
            "Training Accuracy :0.613379955291748\n",
            "Validation loss :1.8399750291824342\n",
            "Validation Accuracy :0.623699963092804\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.8432834142303467\n",
            "Training Accuracy :0.619439959526062\n",
            "Validation loss :1.8355910833358764\n",
            "Validation Accuracy :0.6279999613761902\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.8384421951675416\n",
            "Training Accuracy :0.6240599751472473\n",
            "Validation loss :1.8323493877410888\n",
            "Validation Accuracy :0.6298999786376953\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.8345621380996704\n",
            "Training Accuracy :0.6264199614524841\n",
            "Validation loss :1.8248143411636353\n",
            "Validation Accuracy :0.6344999670982361\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.8108332599639894\n",
            "Training Accuracy :0.6569799780845642\n",
            "Validation loss :1.7917074939727784\n",
            "Validation Accuracy :0.6784999966621399\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.790127446937561\n",
            "Training Accuracy :0.6764999628067017\n",
            "Validation loss :1.7827190139770508\n",
            "Validation Accuracy :0.682699978351593\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.781765803604126\n",
            "Training Accuracy :0.6838200092315674\n",
            "Validation loss :1.7727049360275269\n",
            "Validation Accuracy :0.6935999989509583\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.7712381851577759\n",
            "Training Accuracy :0.6938799619674683\n",
            "Validation loss :1.763551831626892\n",
            "Validation Accuracy :0.7021999955177307\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.764555531616211\n",
            "Training Accuracy :0.6990199685096741\n",
            "Validation loss :1.7590120920181274\n",
            "Validation Accuracy :0.7044000029563904\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.759201727333069\n",
            "Training Accuracy :0.7026799917221069\n",
            "Validation loss :1.7458389347076415\n",
            "Validation Accuracy :0.724399983882904\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.7164949608612061\n",
            "Training Accuracy :0.7577199935913086\n",
            "Validation loss :1.6999654800415038\n",
            "Validation Accuracy :0.7700999975204468\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6929011191558838\n",
            "Training Accuracy :0.7752400040626526\n",
            "Validation loss :1.6899971452713012\n",
            "Validation Accuracy :0.7777999639511108\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6826397247695923\n",
            "Training Accuracy :0.784779965877533\n",
            "Validation loss :1.6797491453170776\n",
            "Validation Accuracy :0.786899983882904\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6761778308486939\n",
            "Training Accuracy :0.7911199927330017\n",
            "Validation loss :1.6774082279205322\n",
            "Validation Accuracy :0.7890999913215637\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.672330047302246\n",
            "Training Accuracy :0.7943800091743469\n",
            "Validation loss :1.6748974014282227\n",
            "Validation Accuracy :0.7910000085830688\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6692200271224975\n",
            "Training Accuracy :0.7968599796295166\n",
            "Validation loss :1.6724655038833618\n",
            "Validation Accuracy :0.7944999933242798\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6673100176239013\n",
            "Training Accuracy :0.7981999516487122\n",
            "Validation loss :1.670364905166626\n",
            "Validation Accuracy :0.7947999835014343\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6651637055206299\n",
            "Training Accuracy :0.7998999953269958\n",
            "Validation loss :1.669755512237549\n",
            "Validation Accuracy :0.7930999994277954\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.662206892967224\n",
            "Training Accuracy :0.8033999800682068\n",
            "Validation loss :1.6637281448364258\n",
            "Validation Accuracy :0.8003999590873718\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6611515787124633\n",
            "Training Accuracy :0.8034799695014954\n",
            "Validation loss :1.6619424615859986\n",
            "Validation Accuracy :0.802899956703186\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6597769189453124\n",
            "Training Accuracy :0.8044599890708923\n",
            "Validation loss :1.6627388833999635\n",
            "Validation Accuracy :0.8004999756813049\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6577554138183594\n",
            "Training Accuracy :0.8066200017929077\n",
            "Validation loss :1.6656166580200196\n",
            "Validation Accuracy :0.7978000044822693\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6581988773345948\n",
            "Training Accuracy :0.8057599663734436\n",
            "Validation loss :1.660780968093872\n",
            "Validation Accuracy :0.8023999929428101\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6571592743682861\n",
            "Training Accuracy :0.8066799640655518\n",
            "Validation loss :1.6579551586151122\n",
            "Validation Accuracy :0.8057999610900879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3FP5xuFltDZ",
        "outputId": "5e501293-74c3-42e4-8352-f96b344736f8"
      },
      "source": [
        "sparsity,best_acc_list,early_stop_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.8,\n",
              "  0.6400000000000001,\n",
              "  0.5120000000000001,\n",
              "  0.4096000000000001,\n",
              "  0.3276800000000001,\n",
              "  0.2621440000000001,\n",
              "  0.20971520000000007,\n",
              "  0.1677721600000001,\n",
              "  0.13421772800000006,\n",
              "  0.10737418240000006,\n",
              "  0.08589934592000005,\n",
              "  0.06871947673600004,\n",
              "  0.054975581388800036,\n",
              "  0.043980465111040035,\n",
              "  0.03518437208883203,\n",
              "  0.028147497671065624,\n",
              "  0.022517998136852502,\n",
              "  0.018014398509482003,\n",
              "  0.014411518807585602,\n",
              "  0.011529215046068483],\n",
              " [0.8971,\n",
              "  tensor(0.8966, device='cuda:0'),\n",
              "  tensor(0.8966, device='cuda:0'),\n",
              "  tensor(0.8972, device='cuda:0'),\n",
              "  tensor(0.8982, device='cuda:0'),\n",
              "  tensor(0.8979, device='cuda:0'),\n",
              "  tensor(0.8993, device='cuda:0'),\n",
              "  tensor(0.9000, device='cuda:0'),\n",
              "  tensor(0.8989, device='cuda:0'),\n",
              "  tensor(0.8978, device='cuda:0'),\n",
              "  tensor(0.8984, device='cuda:0'),\n",
              "  tensor(0.8968, device='cuda:0'),\n",
              "  tensor(0.8846, device='cuda:0'),\n",
              "  tensor(0.8412, device='cuda:0'),\n",
              "  tensor(0.8383, device='cuda:0'),\n",
              "  tensor(0.8366, device='cuda:0'),\n",
              "  tensor(0.8344, device='cuda:0'),\n",
              "  tensor(0.8205, device='cuda:0'),\n",
              "  tensor(0.8235, device='cuda:0'),\n",
              "  tensor(0.8199, device='cuda:0'),\n",
              "  tensor(0.8058, device='cuda:0')],\n",
              " [52,\n",
              "  51,\n",
              "  58,\n",
              "  52,\n",
              "  37,\n",
              "  40,\n",
              "  48,\n",
              "  40,\n",
              "  50,\n",
              "  49,\n",
              "  55,\n",
              "  57,\n",
              "  58,\n",
              "  57,\n",
              "  54,\n",
              "  46,\n",
              "  59,\n",
              "  56,\n",
              "  58,\n",
              "  58,\n",
              "  59])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF4-0X2P4umO"
      },
      "source": [
        "#converting values to cpu for plotting\n",
        "best_acc_cpu=[0.8971]\n",
        "for i in range(1,len(best_acc_list)):\n",
        "  best_acc_cpu.append(best_acc_list[i].cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "FFZCqN_rmGs4",
        "outputId": "d205ae53-3c15-4e35-e952-61aeb1eb3e7c"
      },
      "source": [
        "#plotting sparsity vs accuracy\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(0.7,0.95)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"validation accuracy\")\n",
        "plt.scatter(sparsity,best_acc_cpu)\n",
        "plt.plot(sparsity,best_acc_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61f5adaa50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "3dXnvhaHmJSg",
        "outputId": "2b810b5e-b34e-44e7-cdf4-1bb43c4efaf1"
      },
      "source": [
        "#plotting early stopping \n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(20,60)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"early stopping iteration\")\n",
        "plt.scatter(sparsity,early_stop_list)\n",
        "plt.plot(sparsity,early_stop_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61f5a1edd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUkhK5cV5YsL"
      },
      "source": [
        "model=torch.load(\"/content/drive/MyDrive/ml project/fashion_lotterytrain\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiKfHAyL5loQ",
        "outputId": "c8ade200-e55c-4b80-fce3-709ce6a59be3"
      },
      "source": [
        "#applying magnitude based pruning with random re initialization using default initialization method of pytorch\n",
        "sparsity_wr=[1]\n",
        "best_acc_list_wr=[0.8971]\n",
        "early_stop_list_wr=[52]\n",
        "for i in range(20):\n",
        "  parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.conv3, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "  )\n",
        "\n",
        "  prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        "  )\n",
        "  #re initializing the weights using default method\n",
        "  model2=Network()\n",
        "  model2.to(device)\n",
        "  sd=model.conv1.state_dict()\n",
        "  sd[\"bias\"]=model2.conv1.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=model2.conv1.state_dict()['weight']\n",
        "  model.conv1.load_state_dict(sd)\n",
        "\n",
        "  sd=model.conv2.state_dict()\n",
        "  sd[\"bias\"]=model2.conv2.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=model2.conv2.state_dict()['weight']\n",
        "  model.conv2.load_state_dict(sd)\n",
        "\n",
        "  sd=model.conv3.state_dict()\n",
        "  sd[\"bias\"]=model2.conv3.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=model2.conv3.state_dict()['weight']\n",
        "  model.conv3.load_state_dict(sd)\n",
        "\n",
        "  sd=model.fc1.state_dict()\n",
        "  sd[\"bias\"]=model2.fc1.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=model2.fc1.state_dict()['weight']\n",
        "  model.fc1.load_state_dict(sd)\n",
        "\n",
        "  sd=model.fc2.state_dict()\n",
        "  sd[\"bias\"]=model2.fc2.state_dict()['bias']\n",
        "  sd[\"weight_orig\"]=model2.fc2.state_dict()['weight']\n",
        "  model.fc2.load_state_dict(sd)\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"Sparsity={(1-0.2)**(i+1)}\")\n",
        "  \n",
        "  learning_rate = 0.1\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
        "  crieteria=nn.CrossEntropyLoss()\n",
        "  best_acc=0\n",
        "  early_stop=0\n",
        "  n_epochs=60\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  train_accuracy=[]\n",
        "  val_accuracy=[]\n",
        "  model.train()\n",
        "  for epoch in range(n_epochs):\n",
        "    tr_loss=0\n",
        "    vl_loss=0\n",
        "    print(f\"-----------EPOCH {epoch} ------------------ \")\n",
        "    correct=0\n",
        "    for images, labels in train_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      train = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(train)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      tr_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    train_loss.append(tr_loss/len(train_dataset))\n",
        "    train_accuracy.append(correct/len(train_dataset))\n",
        "    print(f\"Training loss :{tr_loss/len(train_dataset)}\")\n",
        "    print(f\"Training Accuracy :{correct/len(train_dataset)}\")\n",
        "    correct=0\n",
        "    for images, labels in val_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      val = Variable(images.view(len(images), 1, 28, 28))\n",
        "      labels = Variable(labels)\n",
        "      outputs = model(val)\n",
        "      loss = crieteria(outputs, labels)\n",
        "      vl_loss+=loss.item()*len(images)\n",
        "      predictions = torch.max(outputs, 1)[1].to(device)\n",
        "      correct += (predictions == labels).sum()\n",
        "    val_loss.append(vl_loss/len(val_dataset))\n",
        "    val_accuracy.append(correct/len(val_dataset))\n",
        "    print(f\"Validation loss :{vl_loss/len(val_dataset)}\")\n",
        "    print(f\"Validation Accuracy :{correct/len(val_dataset)}\")\n",
        "    if correct/len(val_dataset) > best_acc:\n",
        "      best_acc=correct/len(val_dataset)\n",
        "      early_stop=epoch\n",
        "  best_acc_list_wr.append(best_acc)\n",
        "  early_stop_list_wr.append(early_stop)\n",
        "  sparsity_wr.append((1-0.2)**(i+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training loss :1.622207121810913\n",
            "Training Accuracy :0.8398799896240234\n",
            "Validation loss :1.629018766593933\n",
            "Validation Accuracy :0.8319999575614929\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6219733954620361\n",
            "Training Accuracy :0.8400200009346008\n",
            "Validation loss :1.6267791704177856\n",
            "Validation Accuracy :0.8353999853134155\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6207300435638428\n",
            "Training Accuracy :0.8410599827766418\n",
            "Validation loss :1.6258488073349\n",
            "Validation Accuracy :0.8357999920845032\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6199716426849364\n",
            "Training Accuracy :0.8418599963188171\n",
            "Validation loss :1.6290147094726561\n",
            "Validation Accuracy :0.8325999975204468\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6203708512115478\n",
            "Training Accuracy :0.8416199684143066\n",
            "Validation loss :1.6294322231292724\n",
            "Validation Accuracy :0.8317999839782715\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6191084325408935\n",
            "Training Accuracy :0.8426399827003479\n",
            "Validation loss :1.6311350643157958\n",
            "Validation Accuracy :0.8297999501228333\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6181219219589233\n",
            "Training Accuracy :0.8436200022697449\n",
            "Validation loss :1.627674242401123\n",
            "Validation Accuracy :0.8326999545097351\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.617951615562439\n",
            "Training Accuracy :0.843779981136322\n",
            "Validation loss :1.6251830514907837\n",
            "Validation Accuracy :0.8356999754905701\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6160760598754882\n",
            "Training Accuracy :0.8455999493598938\n",
            "Validation loss :1.6240668226242065\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6168137453460694\n",
            "Training Accuracy :0.8449400067329407\n",
            "Validation loss :1.6269371587753296\n",
            "Validation Accuracy :0.8345999717712402\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6161970441055298\n",
            "Training Accuracy :0.8458399772644043\n",
            "Validation loss :1.625167645072937\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6151002753448487\n",
            "Training Accuracy :0.8466599583625793\n",
            "Validation loss :1.623957929611206\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6154730046463013\n",
            "Training Accuracy :0.8461599946022034\n",
            "Validation loss :1.622697522163391\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6146638802337647\n",
            "Training Accuracy :0.8472599983215332\n",
            "Validation loss :1.6283438608169556\n",
            "Validation Accuracy :0.8328999876976013\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6136393493652343\n",
            "Training Accuracy :0.8477999567985535\n",
            "Validation loss :1.6255320997238158\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.612343399810791\n",
            "Training Accuracy :0.8494199514389038\n",
            "Validation loss :1.6264537870407105\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6120786991119385\n",
            "Training Accuracy :0.8496800065040588\n",
            "Validation loss :1.625802529335022\n",
            "Validation Accuracy :0.8349999785423279\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6112660668945313\n",
            "Training Accuracy :0.8506799936294556\n",
            "Validation loss :1.625281568145752\n",
            "Validation Accuracy :0.8361999988555908\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6110610816955566\n",
            "Training Accuracy :0.8510800004005432\n",
            "Validation loss :1.6223003940582275\n",
            "Validation Accuracy :0.8389999866485596\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6095790683746338\n",
            "Training Accuracy :0.8518399596214294\n",
            "Validation loss :1.622524233818054\n",
            "Validation Accuracy :0.8378999829292297\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6103000570297241\n",
            "Training Accuracy :0.8518399596214294\n",
            "Validation loss :1.6269127168655395\n",
            "Validation Accuracy :0.8341999650001526\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6100859103012084\n",
            "Training Accuracy :0.8519399762153625\n",
            "Validation loss :1.6241426195144653\n",
            "Validation Accuracy :0.8369999527931213\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6101708028030395\n",
            "Training Accuracy :0.851639986038208\n",
            "Validation loss :1.6203596321105957\n",
            "Validation Accuracy :0.8416999578475952\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6093182944488524\n",
            "Training Accuracy :0.8527199625968933\n",
            "Validation loss :1.622120238494873\n",
            "Validation Accuracy :0.8376999497413635\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6086088537597656\n",
            "Training Accuracy :0.8536199927330017\n",
            "Validation loss :1.6227724411010742\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6092481112670898\n",
            "Training Accuracy :0.8525199890136719\n",
            "Validation loss :1.6202051118850709\n",
            "Validation Accuracy :0.8405999541282654\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.607351603012085\n",
            "Training Accuracy :0.8544999957084656\n",
            "Validation loss :1.6256575799942017\n",
            "Validation Accuracy :0.8348000049591064\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6073178453826904\n",
            "Training Accuracy :0.854640007019043\n",
            "Validation loss :1.6204473358154297\n",
            "Validation Accuracy :0.8413999676704407\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.608529430923462\n",
            "Training Accuracy :0.853119969367981\n",
            "Validation loss :1.62482656955719\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6069321814346313\n",
            "Training Accuracy :0.8550399541854858\n",
            "Validation loss :1.622339128112793\n",
            "Validation Accuracy :0.8381999731063843\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6059793756866456\n",
            "Training Accuracy :0.8559799790382385\n",
            "Validation loss :1.6210707094192505\n",
            "Validation Accuracy :0.8400999903678894\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6060271760177611\n",
            "Training Accuracy :0.855739951133728\n",
            "Validation loss :1.6221062980651855\n",
            "Validation Accuracy :0.8388999700546265\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6056518115234375\n",
            "Training Accuracy :0.8558200001716614\n",
            "Validation loss :1.6226724243164063\n",
            "Validation Accuracy :0.8377999663352966\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6044912670135498\n",
            "Training Accuracy :0.8569599986076355\n",
            "Validation loss :1.623371907234192\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6046484580993652\n",
            "Training Accuracy :0.8574599623680115\n",
            "Validation loss :1.6230665472030639\n",
            "Validation Accuracy :0.8377999663352966\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6048857167816162\n",
            "Training Accuracy :0.8568599820137024\n",
            "Validation loss :1.6218134620666504\n",
            "Validation Accuracy :0.839199960231781\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.60404888381958\n",
            "Training Accuracy :0.8579999804496765\n",
            "Validation loss :1.6259871566772461\n",
            "Validation Accuracy :0.835599958896637\n",
            "Sparsity=0.3276800000000001\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3010924894714355\n",
            "Training Accuracy :0.12223999947309494\n",
            "Validation loss :2.29415546836853\n",
            "Validation Accuracy :0.25110000371932983\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.0210226160430906\n",
            "Training Accuracy :0.5033000111579895\n",
            "Validation loss :1.8048898571014405\n",
            "Validation Accuracy :0.6825999617576599\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.741984213294983\n",
            "Training Accuracy :0.733959972858429\n",
            "Validation loss :1.7070064723968505\n",
            "Validation Accuracy :0.7626000046730042\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.6867656365585326\n",
            "Training Accuracy :0.781499981880188\n",
            "Validation loss :1.674910837173462\n",
            "Validation Accuracy :0.789900004863739\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.667743335647583\n",
            "Training Accuracy :0.7980999946594238\n",
            "Validation loss :1.6648335603713988\n",
            "Validation Accuracy :0.7996000051498413\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6586459456634521\n",
            "Training Accuracy :0.8060399889945984\n",
            "Validation loss :1.6614400068283082\n",
            "Validation Accuracy :0.8029999732971191\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6524527297973632\n",
            "Training Accuracy :0.8112999796867371\n",
            "Validation loss :1.6524584245681764\n",
            "Validation Accuracy :0.8102999925613403\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6480223584747316\n",
            "Training Accuracy :0.8157999515533447\n",
            "Validation loss :1.6497770263671876\n",
            "Validation Accuracy :0.8120999932289124\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6445486712265014\n",
            "Training Accuracy :0.818340003490448\n",
            "Validation loss :1.6464411401748658\n",
            "Validation Accuracy :0.8152999877929688\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.640733924179077\n",
            "Training Accuracy :0.8219599723815918\n",
            "Validation loss :1.6399221828460693\n",
            "Validation Accuracy :0.8229999542236328\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.638723804397583\n",
            "Training Accuracy :0.8238399624824524\n",
            "Validation loss :1.6406989665985108\n",
            "Validation Accuracy :0.8204999566078186\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6364150783538818\n",
            "Training Accuracy :0.8267399668693542\n",
            "Validation loss :1.6388200653076173\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.634767699584961\n",
            "Training Accuracy :0.8276000022888184\n",
            "Validation loss :1.6400661540985106\n",
            "Validation Accuracy :0.8222000002861023\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6330483584213258\n",
            "Training Accuracy :0.8297399878501892\n",
            "Validation loss :1.63786691532135\n",
            "Validation Accuracy :0.8235999941825867\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6315473995971679\n",
            "Training Accuracy :0.8309800028800964\n",
            "Validation loss :1.634266010093689\n",
            "Validation Accuracy :0.8277999758720398\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6290775817489624\n",
            "Training Accuracy :0.8332200050354004\n",
            "Validation loss :1.6356324949264527\n",
            "Validation Accuracy :0.8260999917984009\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6283607495117187\n",
            "Training Accuracy :0.8342799544334412\n",
            "Validation loss :1.6355618297576904\n",
            "Validation Accuracy :0.8251000046730042\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.627278450279236\n",
            "Training Accuracy :0.8350600004196167\n",
            "Validation loss :1.6325252933502197\n",
            "Validation Accuracy :0.828499972820282\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6263649731445313\n",
            "Training Accuracy :0.8351199626922607\n",
            "Validation loss :1.6320698406219483\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6252239386367797\n",
            "Training Accuracy :0.8369399905204773\n",
            "Validation loss :1.6305035041809082\n",
            "Validation Accuracy :0.8307999968528748\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6234677535629272\n",
            "Training Accuracy :0.8388400077819824\n",
            "Validation loss :1.633410252571106\n",
            "Validation Accuracy :0.8280999660491943\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6226417621994018\n",
            "Training Accuracy :0.8393999934196472\n",
            "Validation loss :1.6293663896560668\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6221900968170166\n",
            "Training Accuracy :0.8400799632072449\n",
            "Validation loss :1.6273507942199708\n",
            "Validation Accuracy :0.8342999815940857\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.620549532699585\n",
            "Training Accuracy :0.8419399857521057\n",
            "Validation loss :1.630468327331543\n",
            "Validation Accuracy :0.8306999802589417\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.620294101524353\n",
            "Training Accuracy :0.8418999910354614\n",
            "Validation loss :1.6270761032104493\n",
            "Validation Accuracy :0.8346999883651733\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.619310472946167\n",
            "Training Accuracy :0.8425799608230591\n",
            "Validation loss :1.6263052993774414\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.617413119430542\n",
            "Training Accuracy :0.844980001449585\n",
            "Validation loss :1.6255602552413941\n",
            "Validation Accuracy :0.8362999558448792\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.617499807357788\n",
            "Training Accuracy :0.8446999788284302\n",
            "Validation loss :1.6272734455108642\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.616415521965027\n",
            "Training Accuracy :0.846019983291626\n",
            "Validation loss :1.6274720819473267\n",
            "Validation Accuracy :0.8330000042915344\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6170778713989258\n",
            "Training Accuracy :0.8452999591827393\n",
            "Validation loss :1.6248095504760742\n",
            "Validation Accuracy :0.8362999558448792\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6159601830673218\n",
            "Training Accuracy :0.8462399840354919\n",
            "Validation loss :1.6239193912506102\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6154049728775024\n",
            "Training Accuracy :0.8465799689292908\n",
            "Validation loss :1.626473627090454\n",
            "Validation Accuracy :0.8341999650001526\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.614352494392395\n",
            "Training Accuracy :0.8479200005531311\n",
            "Validation loss :1.6250891807556151\n",
            "Validation Accuracy :0.8363999724388123\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.613403070602417\n",
            "Training Accuracy :0.8489799499511719\n",
            "Validation loss :1.6245481872558594\n",
            "Validation Accuracy :0.836899995803833\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6133725490951538\n",
            "Training Accuracy :0.8486799597740173\n",
            "Validation loss :1.626374517440796\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6127137283706665\n",
            "Training Accuracy :0.8496599793434143\n",
            "Validation loss :1.6251651523590087\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6121809048080444\n",
            "Training Accuracy :0.8504199981689453\n",
            "Validation loss :1.6240756797790528\n",
            "Validation Accuracy :0.836899995803833\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6132130756378174\n",
            "Training Accuracy :0.8490399718284607\n",
            "Validation loss :1.6294254135131836\n",
            "Validation Accuracy :0.8316999673843384\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6113479934692383\n",
            "Training Accuracy :0.8508599996566772\n",
            "Validation loss :1.6235162036895752\n",
            "Validation Accuracy :0.8377999663352966\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6112324097061157\n",
            "Training Accuracy :0.8513199687004089\n",
            "Validation loss :1.6245087398529052\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6098593210983276\n",
            "Training Accuracy :0.8523399829864502\n",
            "Validation loss :1.622648949432373\n",
            "Validation Accuracy :0.8389999866485596\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6095578338623047\n",
            "Training Accuracy :0.8529799580574036\n",
            "Validation loss :1.6224433616638183\n",
            "Validation Accuracy :0.8389999866485596\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6093995807647705\n",
            "Training Accuracy :0.8527399897575378\n",
            "Validation loss :1.6218169651031493\n",
            "Validation Accuracy :0.8398000001907349\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6091240313720703\n",
            "Training Accuracy :0.8531799912452698\n",
            "Validation loss :1.6233483528137207\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6083952685165406\n",
            "Training Accuracy :0.8537600040435791\n",
            "Validation loss :1.622685214996338\n",
            "Validation Accuracy :0.8394999504089355\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6072589652252198\n",
            "Training Accuracy :0.8549999594688416\n",
            "Validation loss :1.6219021202087403\n",
            "Validation Accuracy :0.839199960231781\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6073969735336304\n",
            "Training Accuracy :0.8548399806022644\n",
            "Validation loss :1.6209612003326417\n",
            "Validation Accuracy :0.8410999774932861\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.608409462776184\n",
            "Training Accuracy :0.8539800047874451\n",
            "Validation loss :1.6215950157165526\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6070541440582276\n",
            "Training Accuracy :0.8549999594688416\n",
            "Validation loss :1.6195349910736083\n",
            "Validation Accuracy :0.8410999774932861\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.606164021911621\n",
            "Training Accuracy :0.8562799692153931\n",
            "Validation loss :1.6217819183349609\n",
            "Validation Accuracy :0.8394999504089355\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.606042417488098\n",
            "Training Accuracy :0.8557999730110168\n",
            "Validation loss :1.6207732757568358\n",
            "Validation Accuracy :0.8410999774932861\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6064568774032593\n",
            "Training Accuracy :0.8555399775505066\n",
            "Validation loss :1.6232619052886963\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6060253720092774\n",
            "Training Accuracy :0.8561599850654602\n",
            "Validation loss :1.6208635135650635\n",
            "Validation Accuracy :0.8402000069618225\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6045332614898682\n",
            "Training Accuracy :0.8572999835014343\n",
            "Validation loss :1.6214088874816894\n",
            "Validation Accuracy :0.8384000062942505\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6042732369232178\n",
            "Training Accuracy :0.8579399585723877\n",
            "Validation loss :1.6209221820831299\n",
            "Validation Accuracy :0.8402999639511108\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6044886716079712\n",
            "Training Accuracy :0.8578599691390991\n",
            "Validation loss :1.6220657009124755\n",
            "Validation Accuracy :0.8380999565124512\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6042645230865478\n",
            "Training Accuracy :0.8579399585723877\n",
            "Validation loss :1.6205371940612794\n",
            "Validation Accuracy :0.8399999737739563\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6032068957901\n",
            "Training Accuracy :0.8589199781417847\n",
            "Validation loss :1.6205604183197022\n",
            "Validation Accuracy :0.8411999940872192\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6035907907485962\n",
            "Training Accuracy :0.8585799932479858\n",
            "Validation loss :1.620180546951294\n",
            "Validation Accuracy :0.8406999707221985\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.603000641708374\n",
            "Training Accuracy :0.8593999743461609\n",
            "Validation loss :1.619247709274292\n",
            "Validation Accuracy :0.8432999849319458\n",
            "Sparsity=0.2621440000000001\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3022309535980225\n",
            "Training Accuracy :0.1383799910545349\n",
            "Validation loss :2.3011579608917234\n",
            "Validation Accuracy :0.14229999482631683\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.207658021697998\n",
            "Training Accuracy :0.30115997791290283\n",
            "Validation loss :1.9814131132125854\n",
            "Validation Accuracy :0.5166000127792358\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.8561755759429932\n",
            "Training Accuracy :0.6271600127220154\n",
            "Validation loss :1.7583828548431397\n",
            "Validation Accuracy :0.7179999947547913\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.7157260359954833\n",
            "Training Accuracy :0.7559799551963806\n",
            "Validation loss :1.688633975982666\n",
            "Validation Accuracy :0.7803999781608582\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6820685610198975\n",
            "Training Accuracy :0.7842199802398682\n",
            "Validation loss :1.6756566638946533\n",
            "Validation Accuracy :0.7890999913215637\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.668935835647583\n",
            "Training Accuracy :0.7961399555206299\n",
            "Validation loss :1.6652991800308228\n",
            "Validation Accuracy :0.8000999689102173\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6621948616790772\n",
            "Training Accuracy :0.8011800050735474\n",
            "Validation loss :1.6622436157226563\n",
            "Validation Accuracy :0.8014999628067017\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6557152731323241\n",
            "Training Accuracy :0.8076799511909485\n",
            "Validation loss :1.6544221359252929\n",
            "Validation Accuracy :0.8091999888420105\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6504507576751708\n",
            "Training Accuracy :0.813539981842041\n",
            "Validation loss :1.6539731981277466\n",
            "Validation Accuracy :0.8086000084877014\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6482328057098388\n",
            "Training Accuracy :0.8143999576568604\n",
            "Validation loss :1.6459607839584351\n",
            "Validation Accuracy :0.8156999945640564\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6440982111358642\n",
            "Training Accuracy :0.8187199831008911\n",
            "Validation loss :1.6450987451553345\n",
            "Validation Accuracy :0.8170999884605408\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6396441051101684\n",
            "Training Accuracy :0.8230400085449219\n",
            "Validation loss :1.6416337730407715\n",
            "Validation Accuracy :0.8222000002861023\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6365850311660766\n",
            "Training Accuracy :0.8259199857711792\n",
            "Validation loss :1.6394175964355469\n",
            "Validation Accuracy :0.8215999603271484\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.634490414352417\n",
            "Training Accuracy :0.828719973564148\n",
            "Validation loss :1.6384860569000244\n",
            "Validation Accuracy :0.8224999904632568\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.633465015258789\n",
            "Training Accuracy :0.8296399712562561\n",
            "Validation loss :1.634438536453247\n",
            "Validation Accuracy :0.8271999955177307\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.631479249572754\n",
            "Training Accuracy :0.8314399719238281\n",
            "Validation loss :1.6350738986968993\n",
            "Validation Accuracy :0.8270999789237976\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.629107004776001\n",
            "Training Accuracy :0.8332799673080444\n",
            "Validation loss :1.635728314781189\n",
            "Validation Accuracy :0.8258999586105347\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6292972817230225\n",
            "Training Accuracy :0.8332599997520447\n",
            "Validation loss :1.6349886623382568\n",
            "Validation Accuracy :0.8263999819755554\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6268551880264281\n",
            "Training Accuracy :0.8354600071907043\n",
            "Validation loss :1.6341011196136475\n",
            "Validation Accuracy :0.8276999592781067\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6267443667221069\n",
            "Training Accuracy :0.835599958896637\n",
            "Validation loss :1.6292678602218629\n",
            "Validation Accuracy :0.8330999612808228\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.625284409866333\n",
            "Training Accuracy :0.8367399573326111\n",
            "Validation loss :1.6318186765670777\n",
            "Validation Accuracy :0.8295999765396118\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6251236379241942\n",
            "Training Accuracy :0.8372199535369873\n",
            "Validation loss :1.6293180536270142\n",
            "Validation Accuracy :0.8331999778747559\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6238701907348634\n",
            "Training Accuracy :0.8379999995231628\n",
            "Validation loss :1.628787001991272\n",
            "Validation Accuracy :0.8328999876976013\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.623212587928772\n",
            "Training Accuracy :0.8386600017547607\n",
            "Validation loss :1.6285042232513427\n",
            "Validation Accuracy :0.8331999778747559\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6234972127532958\n",
            "Training Accuracy :0.8381800055503845\n",
            "Validation loss :1.6359875942230224\n",
            "Validation Accuracy :0.825499951839447\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6208906177520752\n",
            "Training Accuracy :0.840999960899353\n",
            "Validation loss :1.6264844821929931\n",
            "Validation Accuracy :0.8349999785423279\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6199554135513305\n",
            "Training Accuracy :0.8426599502563477\n",
            "Validation loss :1.62579296875\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6195977193450928\n",
            "Training Accuracy :0.8425399661064148\n",
            "Validation loss :1.6282141094207763\n",
            "Validation Accuracy :0.8323999643325806\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6198199408721923\n",
            "Training Accuracy :0.8422999978065491\n",
            "Validation loss :1.6280825033187867\n",
            "Validation Accuracy :0.8326999545097351\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6194457922363281\n",
            "Training Accuracy :0.8424399495124817\n",
            "Validation loss :1.6275633312225342\n",
            "Validation Accuracy :0.8325999975204468\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6188016997909547\n",
            "Training Accuracy :0.8433799743652344\n",
            "Validation loss :1.626061304473877\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6174718957519532\n",
            "Training Accuracy :0.8442399501800537\n",
            "Validation loss :1.6260493488311767\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6182117956924438\n",
            "Training Accuracy :0.8434799909591675\n",
            "Validation loss :1.6235562252044677\n",
            "Validation Accuracy :0.8380999565124512\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6164065807724\n",
            "Training Accuracy :0.8452799916267395\n",
            "Validation loss :1.6226973402023315\n",
            "Validation Accuracy :0.8394999504089355\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.617533486289978\n",
            "Training Accuracy :0.8442399501800537\n",
            "Validation loss :1.6279636407852174\n",
            "Validation Accuracy :0.8337999582290649\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6148427017211915\n",
            "Training Accuracy :0.8465999960899353\n",
            "Validation loss :1.6293596797943115\n",
            "Validation Accuracy :0.8313999772071838\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6153995083999633\n",
            "Training Accuracy :0.8462599515914917\n",
            "Validation loss :1.623254413986206\n",
            "Validation Accuracy :0.8380999565124512\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.616195924911499\n",
            "Training Accuracy :0.84579998254776\n",
            "Validation loss :1.623949240875244\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6139780902862548\n",
            "Training Accuracy :0.8478800058364868\n",
            "Validation loss :1.6225039674758912\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6132251309204102\n",
            "Training Accuracy :0.8487199544906616\n",
            "Validation loss :1.6251626720428467\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6123612392425537\n",
            "Training Accuracy :0.849299967288971\n",
            "Validation loss :1.6228774362564087\n",
            "Validation Accuracy :0.8385999798774719\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6134363103485108\n",
            "Training Accuracy :0.8481599688529968\n",
            "Validation loss :1.6221475734710693\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6131926850128173\n",
            "Training Accuracy :0.8481799960136414\n",
            "Validation loss :1.6233557594299317\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6111548931884765\n",
            "Training Accuracy :0.8503599762916565\n",
            "Validation loss :1.6246280723571778\n",
            "Validation Accuracy :0.836899995803833\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6124629931640626\n",
            "Training Accuracy :0.8495000004768372\n",
            "Validation loss :1.62428939743042\n",
            "Validation Accuracy :0.8366999626159668\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6122650177383422\n",
            "Training Accuracy :0.8497399687767029\n",
            "Validation loss :1.623012208366394\n",
            "Validation Accuracy :0.8377999663352966\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6111557764434814\n",
            "Training Accuracy :0.8504999876022339\n",
            "Validation loss :1.6210647954940796\n",
            "Validation Accuracy :0.840399980545044\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6097058776855468\n",
            "Training Accuracy :0.8523399829864502\n",
            "Validation loss :1.6231589292526245\n",
            "Validation Accuracy :0.8376999497413635\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6098594744110108\n",
            "Training Accuracy :0.8520999550819397\n",
            "Validation loss :1.6229739686965943\n",
            "Validation Accuracy :0.837399959564209\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6097592895507813\n",
            "Training Accuracy :0.851919949054718\n",
            "Validation loss :1.6194504179000855\n",
            "Validation Accuracy :0.8420999646186829\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6096076480865478\n",
            "Training Accuracy :0.8521599769592285\n",
            "Validation loss :1.624695972251892\n",
            "Validation Accuracy :0.8363999724388123\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.610363564224243\n",
            "Training Accuracy :0.851419985294342\n",
            "Validation loss :1.6217256462097167\n",
            "Validation Accuracy :0.839199960231781\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6092623934555055\n",
            "Training Accuracy :0.8524599671363831\n",
            "Validation loss :1.6201040285110473\n",
            "Validation Accuracy :0.8411999940872192\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6082162694168092\n",
            "Training Accuracy :0.8534599542617798\n",
            "Validation loss :1.6192715118408203\n",
            "Validation Accuracy :0.8416000008583069\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6083854454803468\n",
            "Training Accuracy :0.8533799648284912\n",
            "Validation loss :1.6206200511932374\n",
            "Validation Accuracy :0.8402999639511108\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6088859482192994\n",
            "Training Accuracy :0.8528800010681152\n",
            "Validation loss :1.6213533479690552\n",
            "Validation Accuracy :0.8396999835968018\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6083270672607421\n",
            "Training Accuracy :0.85343998670578\n",
            "Validation loss :1.619674584388733\n",
            "Validation Accuracy :0.8417999744415283\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6073275730133056\n",
            "Training Accuracy :0.8542400002479553\n",
            "Validation loss :1.6187281311035155\n",
            "Validation Accuracy :0.8425999879837036\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6083975284576415\n",
            "Training Accuracy :0.8535999655723572\n",
            "Validation loss :1.6221005338668824\n",
            "Validation Accuracy :0.8384999632835388\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6068913373565674\n",
            "Training Accuracy :0.8548399806022644\n",
            "Validation loss :1.6209513832092286\n",
            "Validation Accuracy :0.8391000032424927\n",
            "Sparsity=0.20971520000000007\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3018899922943117\n",
            "Training Accuracy :0.1000399962067604\n",
            "Validation loss :2.2993612106323242\n",
            "Validation Accuracy :0.09759999811649323\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.180241771392822\n",
            "Training Accuracy :0.27254000306129456\n",
            "Validation loss :1.9720480739593507\n",
            "Validation Accuracy :0.5192999839782715\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :1.8358493472290038\n",
            "Training Accuracy :0.6516199707984924\n",
            "Validation loss :1.7434405689239503\n",
            "Validation Accuracy :0.7303999662399292\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.7233473092269898\n",
            "Training Accuracy :0.7470799684524536\n",
            "Validation loss :1.703572360229492\n",
            "Validation Accuracy :0.7640999555587769\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.6939667496490478\n",
            "Training Accuracy :0.7731399536132812\n",
            "Validation loss :1.6859917127609252\n",
            "Validation Accuracy :0.7828999757766724\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.6762662992095947\n",
            "Training Accuracy :0.7893799543380737\n",
            "Validation loss :1.6721775732040405\n",
            "Validation Accuracy :0.792199969291687\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6668123977279663\n",
            "Training Accuracy :0.7973799705505371\n",
            "Validation loss :1.6627306715011596\n",
            "Validation Accuracy :0.8008999824523926\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6586181842041015\n",
            "Training Accuracy :0.8058799505233765\n",
            "Validation loss :1.6546589056015015\n",
            "Validation Accuracy :0.8101999759674072\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.652509128189087\n",
            "Training Accuracy :0.8118399977684021\n",
            "Validation loss :1.6511783344268798\n",
            "Validation Accuracy :0.8127999901771545\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6496424868011474\n",
            "Training Accuracy :0.8138399720191956\n",
            "Validation loss :1.6480211261749267\n",
            "Validation Accuracy :0.8150999546051025\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6443953350448608\n",
            "Training Accuracy :0.8183199763298035\n",
            "Validation loss :1.6433551160812379\n",
            "Validation Accuracy :0.8198999762535095\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6421662694549561\n",
            "Training Accuracy :0.8207799792289734\n",
            "Validation loss :1.6429389041900635\n",
            "Validation Accuracy :0.8198999762535095\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.638276185951233\n",
            "Training Accuracy :0.8243799805641174\n",
            "Validation loss :1.6381901706695556\n",
            "Validation Accuracy :0.8251000046730042\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.636620036239624\n",
            "Training Accuracy :0.8269599676132202\n",
            "Validation loss :1.638538303375244\n",
            "Validation Accuracy :0.8234999775886536\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.635161995162964\n",
            "Training Accuracy :0.8273400068283081\n",
            "Validation loss :1.6401928686141969\n",
            "Validation Accuracy :0.8216999769210815\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.634352301712036\n",
            "Training Accuracy :0.8284599781036377\n",
            "Validation loss :1.6352640127182008\n",
            "Validation Accuracy :0.8270999789237976\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6329017651748656\n",
            "Training Accuracy :0.8301399946212769\n",
            "Validation loss :1.637990029335022\n",
            "Validation Accuracy :0.8230999708175659\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.632282933883667\n",
            "Training Accuracy :0.8301799893379211\n",
            "Validation loss :1.638363759803772\n",
            "Validation Accuracy :0.8233999609947205\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6300672274780272\n",
            "Training Accuracy :0.8322199583053589\n",
            "Validation loss :1.6342591220855713\n",
            "Validation Accuracy :0.8276999592781067\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6283554654693604\n",
            "Training Accuracy :0.8341400027275085\n",
            "Validation loss :1.6372065153121949\n",
            "Validation Accuracy :0.8244999647140503\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6287595779418946\n",
            "Training Accuracy :0.8337399959564209\n",
            "Validation loss :1.6327412576675415\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6270070970916748\n",
            "Training Accuracy :0.8352599740028381\n",
            "Validation loss :1.6318115219116212\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6262276210784912\n",
            "Training Accuracy :0.8360399603843689\n",
            "Validation loss :1.6317288063049316\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6251009105300904\n",
            "Training Accuracy :0.8367999792098999\n",
            "Validation loss :1.6315845958709716\n",
            "Validation Accuracy :0.8303999900817871\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6253783752059936\n",
            "Training Accuracy :0.8366000056266785\n",
            "Validation loss :1.632129047203064\n",
            "Validation Accuracy :0.8280999660491943\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6237406870269775\n",
            "Training Accuracy :0.8385799527168274\n",
            "Validation loss :1.6315866060256958\n",
            "Validation Accuracy :0.8297999501228333\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6236429651260376\n",
            "Training Accuracy :0.8387399911880493\n",
            "Validation loss :1.6315240356445313\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6219165348434448\n",
            "Training Accuracy :0.8402400016784668\n",
            "Validation loss :1.6289434997558594\n",
            "Validation Accuracy :0.832099974155426\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.621700118560791\n",
            "Training Accuracy :0.8404600024223328\n",
            "Validation loss :1.6291341697692872\n",
            "Validation Accuracy :0.8323999643325806\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6216495489501954\n",
            "Training Accuracy :0.8407799601554871\n",
            "Validation loss :1.6291062784194947\n",
            "Validation Accuracy :0.8323000073432922\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6210297193145753\n",
            "Training Accuracy :0.8409000039100647\n",
            "Validation loss :1.6309448083877562\n",
            "Validation Accuracy :0.8300999999046326\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6202992304229735\n",
            "Training Accuracy :0.8418599963188171\n",
            "Validation loss :1.6256333568572998\n",
            "Validation Accuracy :0.8363999724388123\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6194836707305909\n",
            "Training Accuracy :0.8424199819564819\n",
            "Validation loss :1.6284158975601197\n",
            "Validation Accuracy :0.8312999606132507\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6187051874160767\n",
            "Training Accuracy :0.8435399532318115\n",
            "Validation loss :1.6284331434249877\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.619486941833496\n",
            "Training Accuracy :0.842739999294281\n",
            "Validation loss :1.6283242288589477\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.618227875061035\n",
            "Training Accuracy :0.8434799909591675\n",
            "Validation loss :1.6283336429595947\n",
            "Validation Accuracy :0.8325999975204468\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6183705896759033\n",
            "Training Accuracy :0.8434399962425232\n",
            "Validation loss :1.6264110137939454\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6170933118438722\n",
            "Training Accuracy :0.8449199795722961\n",
            "Validation loss :1.626766132736206\n",
            "Validation Accuracy :0.8341000080108643\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.617325016708374\n",
            "Training Accuracy :0.8448399901390076\n",
            "Validation loss :1.6268801559448243\n",
            "Validation Accuracy :0.8339999914169312\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6169392389297486\n",
            "Training Accuracy :0.8452999591827393\n",
            "Validation loss :1.6249731338500977\n",
            "Validation Accuracy :0.8361999988555908\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6157601081085204\n",
            "Training Accuracy :0.8458999991416931\n",
            "Validation loss :1.6255500427246095\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6156866040420532\n",
            "Training Accuracy :0.8464999794960022\n",
            "Validation loss :1.6251852741241455\n",
            "Validation Accuracy :0.8356999754905701\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.615089780960083\n",
            "Training Accuracy :0.8471599817276001\n",
            "Validation loss :1.6261340648651124\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6148173611068726\n",
            "Training Accuracy :0.8472200036048889\n",
            "Validation loss :1.6239697322845459\n",
            "Validation Accuracy :0.8376999497413635\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6139242987060547\n",
            "Training Accuracy :0.8484199643135071\n",
            "Validation loss :1.625983884048462\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.614195230407715\n",
            "Training Accuracy :0.8476999998092651\n",
            "Validation loss :1.6258925603866576\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6132370580673219\n",
            "Training Accuracy :0.8485599756240845\n",
            "Validation loss :1.6233300266265869\n",
            "Validation Accuracy :0.8370999693870544\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6130469298553467\n",
            "Training Accuracy :0.8488799929618835\n",
            "Validation loss :1.6239124315261841\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.613260057067871\n",
            "Training Accuracy :0.8486999869346619\n",
            "Validation loss :1.62439133644104\n",
            "Validation Accuracy :0.8362999558448792\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.612388493270874\n",
            "Training Accuracy :0.8495799899101257\n",
            "Validation loss :1.624062995147705\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6115292315673828\n",
            "Training Accuracy :0.8503999710083008\n",
            "Validation loss :1.6230221248626708\n",
            "Validation Accuracy :0.8379999995231628\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.612277541885376\n",
            "Training Accuracy :0.8497200012207031\n",
            "Validation loss :1.6237192888259888\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6118244107437134\n",
            "Training Accuracy :0.850600004196167\n",
            "Validation loss :1.6239968370437623\n",
            "Validation Accuracy :0.8367999792098999\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.610710883102417\n",
            "Training Accuracy :0.8515599966049194\n",
            "Validation loss :1.6236080896377563\n",
            "Validation Accuracy :0.8380999565124512\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6106372199249268\n",
            "Training Accuracy :0.8516599535942078\n",
            "Validation loss :1.62314831199646\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.610397677001953\n",
            "Training Accuracy :0.8511599898338318\n",
            "Validation loss :1.6214204193115234\n",
            "Validation Accuracy :0.840499997138977\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.609785104751587\n",
            "Training Accuracy :0.8524399995803833\n",
            "Validation loss :1.6221349723815919\n",
            "Validation Accuracy :0.8398000001907349\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6091193899536134\n",
            "Training Accuracy :0.8528599739074707\n",
            "Validation loss :1.6261473115921021\n",
            "Validation Accuracy :0.8346999883651733\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6091891119766235\n",
            "Training Accuracy :0.8529399633407593\n",
            "Validation loss :1.6233727624893188\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6090964407730102\n",
            "Training Accuracy :0.8531599640846252\n",
            "Validation loss :1.6225717027664184\n",
            "Validation Accuracy :0.8382999897003174\n",
            "Sparsity=0.1677721600000001\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3024875620269776\n",
            "Training Accuracy :0.10645999759435654\n",
            "Validation loss :2.302364778518677\n",
            "Validation Accuracy :0.09759999811649323\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3003764741516113\n",
            "Training Accuracy :0.14451999962329865\n",
            "Validation loss :2.2928250644683836\n",
            "Validation Accuracy :0.21719999611377716\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.1120850342559816\n",
            "Training Accuracy :0.3687399923801422\n",
            "Validation loss :1.9326732316970825\n",
            "Validation Accuracy :0.5449999570846558\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.8507521921157837\n",
            "Training Accuracy :0.6292399764060974\n",
            "Validation loss :1.757193966293335\n",
            "Validation Accuracy :0.7233999967575073\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.7269518307495118\n",
            "Training Accuracy :0.7454400062561035\n",
            "Validation loss :1.7016417844772338\n",
            "Validation Accuracy :0.7675999999046326\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.690414140357971\n",
            "Training Accuracy :0.7784199714660645\n",
            "Validation loss :1.6786501514434815\n",
            "Validation Accuracy :0.7881999611854553\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6722004830551147\n",
            "Training Accuracy :0.7944599986076355\n",
            "Validation loss :1.6674477241516112\n",
            "Validation Accuracy :0.7983999848365784\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6614762187957763\n",
            "Training Accuracy :0.8043799996376038\n",
            "Validation loss :1.6574628425598144\n",
            "Validation Accuracy :0.8052999973297119\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6552327209091187\n",
            "Training Accuracy :0.8094199895858765\n",
            "Validation loss :1.6565524671554566\n",
            "Validation Accuracy :0.8070999979972839\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6495593405532838\n",
            "Training Accuracy :0.8154000043869019\n",
            "Validation loss :1.6522509580612184\n",
            "Validation Accuracy :0.8130999803543091\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6448601880645752\n",
            "Training Accuracy :0.8187999725341797\n",
            "Validation loss :1.6498669633865357\n",
            "Validation Accuracy :0.8132999539375305\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6415926812362671\n",
            "Training Accuracy :0.8221799731254578\n",
            "Validation loss :1.6484222005844116\n",
            "Validation Accuracy :0.8149999976158142\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6390976074600219\n",
            "Training Accuracy :0.8247199654579163\n",
            "Validation loss :1.6431171787261962\n",
            "Validation Accuracy :0.8193999528884888\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6357017317581177\n",
            "Training Accuracy :0.8278999924659729\n",
            "Validation loss :1.636065898513794\n",
            "Validation Accuracy :0.8278999924659729\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6346696423721314\n",
            "Training Accuracy :0.8282999992370605\n",
            "Validation loss :1.6373738368988038\n",
            "Validation Accuracy :0.8247999548912048\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6327202033996582\n",
            "Training Accuracy :0.8304199576377869\n",
            "Validation loss :1.6372601490020753\n",
            "Validation Accuracy :0.8246999979019165\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.631844268722534\n",
            "Training Accuracy :0.8311599493026733\n",
            "Validation loss :1.6366429651260377\n",
            "Validation Accuracy :0.8252999782562256\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6303707567596435\n",
            "Training Accuracy :0.8327199816703796\n",
            "Validation loss :1.632005978012085\n",
            "Validation Accuracy :0.8301999568939209\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6279497635269164\n",
            "Training Accuracy :0.8348399996757507\n",
            "Validation loss :1.6343805423736573\n",
            "Validation Accuracy :0.8285999894142151\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.626840524291992\n",
            "Training Accuracy :0.8362399935722351\n",
            "Validation loss :1.6326981552124022\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6257902514648437\n",
            "Training Accuracy :0.8369799852371216\n",
            "Validation loss :1.6304155954360962\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.624910775718689\n",
            "Training Accuracy :0.8377999663352966\n",
            "Validation loss :1.633615570640564\n",
            "Validation Accuracy :0.8279999494552612\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6240507958984376\n",
            "Training Accuracy :0.838699996471405\n",
            "Validation loss :1.6309973188400269\n",
            "Validation Accuracy :0.8310999870300293\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6230961174011231\n",
            "Training Accuracy :0.8396399617195129\n",
            "Validation loss :1.6315836029052735\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6226028211212158\n",
            "Training Accuracy :0.8402799963951111\n",
            "Validation loss :1.6297057041168213\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6208950204086303\n",
            "Training Accuracy :0.8414799571037292\n",
            "Validation loss :1.6264244115829467\n",
            "Validation Accuracy :0.8359000086784363\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6206991979217529\n",
            "Training Accuracy :0.8416799902915955\n",
            "Validation loss :1.6268459211349486\n",
            "Validation Accuracy :0.8345999717712402\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6206625900650025\n",
            "Training Accuracy :0.8415199518203735\n",
            "Validation loss :1.6291399505615234\n",
            "Validation Accuracy :0.832099974155426\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6193978707504273\n",
            "Training Accuracy :0.8429399728775024\n",
            "Validation loss :1.6286695741653443\n",
            "Validation Accuracy :0.8328999876976013\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6189147037506104\n",
            "Training Accuracy :0.8436799645423889\n",
            "Validation loss :1.627688186454773\n",
            "Validation Accuracy :0.8333999514579773\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6180547008895874\n",
            "Training Accuracy :0.8444799780845642\n",
            "Validation loss :1.6262352878570556\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6180641213226319\n",
            "Training Accuracy :0.844219982624054\n",
            "Validation loss :1.625180887413025\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6171459741592407\n",
            "Training Accuracy :0.8450799584388733\n",
            "Validation loss :1.6237602773666382\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6162388788604736\n",
            "Training Accuracy :0.8462599515914917\n",
            "Validation loss :1.6255226684570312\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6162913763427735\n",
            "Training Accuracy :0.8460999727249146\n",
            "Validation loss :1.6261952291488648\n",
            "Validation Accuracy :0.8349999785423279\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6160706427383422\n",
            "Training Accuracy :0.8462799787521362\n",
            "Validation loss :1.6266796543121338\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6156232162857056\n",
            "Training Accuracy :0.8468599915504456\n",
            "Validation loss :1.6244720127105712\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6146833587265015\n",
            "Training Accuracy :0.8475199937820435\n",
            "Validation loss :1.6240441770553589\n",
            "Validation Accuracy :0.8369999527931213\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.61446285987854\n",
            "Training Accuracy :0.8473999500274658\n",
            "Validation loss :1.623383260345459\n",
            "Validation Accuracy :0.8381999731063843\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6136552239227295\n",
            "Training Accuracy :0.848800003528595\n",
            "Validation loss :1.6266991743087769\n",
            "Validation Accuracy :0.8343999981880188\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6127301257324218\n",
            "Training Accuracy :0.8497999906539917\n",
            "Validation loss :1.6229208883285522\n",
            "Validation Accuracy :0.838699996471405\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6124053848266602\n",
            "Training Accuracy :0.8497799634933472\n",
            "Validation loss :1.6230107065200805\n",
            "Validation Accuracy :0.8371999859809875\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6117791720962524\n",
            "Training Accuracy :0.850339949131012\n",
            "Validation loss :1.6252549243927001\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6123405026626587\n",
            "Training Accuracy :0.8505799770355225\n",
            "Validation loss :1.6234870056152344\n",
            "Validation Accuracy :0.8371999859809875\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.611412537574768\n",
            "Training Accuracy :0.850659966468811\n",
            "Validation loss :1.6246871063232422\n",
            "Validation Accuracy :0.8369999527931213\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6116588927841187\n",
            "Training Accuracy :0.8511799573898315\n",
            "Validation loss :1.6260576473236084\n",
            "Validation Accuracy :0.8348000049591064\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6117673272705078\n",
            "Training Accuracy :0.8501200079917908\n",
            "Validation loss :1.622334411048889\n",
            "Validation Accuracy :0.8392999768257141\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6103782374191284\n",
            "Training Accuracy :0.8519600033760071\n",
            "Validation loss :1.6229604934692383\n",
            "Validation Accuracy :0.8382999897003174\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6114429401779176\n",
            "Training Accuracy :0.8508399724960327\n",
            "Validation loss :1.6246091457366942\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6106149459457397\n",
            "Training Accuracy :0.8514999747276306\n",
            "Validation loss :1.6225303535461426\n",
            "Validation Accuracy :0.8392999768257141\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6095040869522095\n",
            "Training Accuracy :0.8528599739074707\n",
            "Validation loss :1.6226983907699586\n",
            "Validation Accuracy :0.8379999995231628\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6095264269256593\n",
            "Training Accuracy :0.8524999618530273\n",
            "Validation loss :1.6228361484527587\n",
            "Validation Accuracy :0.8393999934196472\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6086338229751587\n",
            "Training Accuracy :0.8540599942207336\n",
            "Validation loss :1.6224734712600708\n",
            "Validation Accuracy :0.8384000062942505\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6098859595870971\n",
            "Training Accuracy :0.8518399596214294\n",
            "Validation loss :1.6242564792633056\n",
            "Validation Accuracy :0.8360999822616577\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6079353646469117\n",
            "Training Accuracy :0.8541199564933777\n",
            "Validation loss :1.6236789054870606\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6086539502334594\n",
            "Training Accuracy :0.8538399934768677\n",
            "Validation loss :1.6229179765701294\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6072814267349242\n",
            "Training Accuracy :0.8551799654960632\n",
            "Validation loss :1.6227286167144774\n",
            "Validation Accuracy :0.8387999534606934\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6076223754882812\n",
            "Training Accuracy :0.8549599647521973\n",
            "Validation loss :1.6230274564743041\n",
            "Validation Accuracy :0.836899995803833\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6077864155960082\n",
            "Training Accuracy :0.8542799949645996\n",
            "Validation loss :1.6224110130310059\n",
            "Validation Accuracy :0.8385999798774719\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6074998896408081\n",
            "Training Accuracy :0.8549000024795532\n",
            "Validation loss :1.6259882928848266\n",
            "Validation Accuracy :0.8344999551773071\n",
            "Sparsity=0.13421772800000006\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302477741012573\n",
            "Training Accuracy :0.10049999505281448\n",
            "Validation loss :2.3023153251647948\n",
            "Validation Accuracy :0.09759999811649323\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3014828163909913\n",
            "Training Accuracy :0.10049999505281448\n",
            "Validation loss :2.2992569770812987\n",
            "Validation Accuracy :0.10009999573230743\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.1854056146240235\n",
            "Training Accuracy :0.2935999929904938\n",
            "Validation loss :1.9652779859542846\n",
            "Validation Accuracy :0.5062999725341797\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :1.8745355926513672\n",
            "Training Accuracy :0.6035000085830688\n",
            "Validation loss :1.815681576538086\n",
            "Validation Accuracy :0.6596999764442444\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.7528291198730468\n",
            "Training Accuracy :0.7245399951934814\n",
            "Validation loss :1.716093360519409\n",
            "Validation Accuracy :0.7558000087738037\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.697658832168579\n",
            "Training Accuracy :0.7709199786186218\n",
            "Validation loss :1.6861364786148072\n",
            "Validation Accuracy :0.7823999524116516\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6802827920150756\n",
            "Training Accuracy :0.7860199809074402\n",
            "Validation loss :1.672334171104431\n",
            "Validation Accuracy :0.7953000068664551\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.6687701689910888\n",
            "Training Accuracy :0.7973799705505371\n",
            "Validation loss :1.6659968004226684\n",
            "Validation Accuracy :0.7976999878883362\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.661553075942993\n",
            "Training Accuracy :0.8026599884033203\n",
            "Validation loss :1.6609328231811524\n",
            "Validation Accuracy :0.8037999868392944\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.65577075340271\n",
            "Training Accuracy :0.8087199926376343\n",
            "Validation loss :1.6551482595443725\n",
            "Validation Accuracy :0.8084999918937683\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6520862659454345\n",
            "Training Accuracy :0.8124799728393555\n",
            "Validation loss :1.6525647296905517\n",
            "Validation Accuracy :0.8108999729156494\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6488448334503174\n",
            "Training Accuracy :0.8143999576568604\n",
            "Validation loss :1.6484059608459474\n",
            "Validation Accuracy :0.8143999576568604\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.644228223953247\n",
            "Training Accuracy :0.8189199566841125\n",
            "Validation loss :1.6461015007019042\n",
            "Validation Accuracy :0.8158999681472778\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6419671017456055\n",
            "Training Accuracy :0.820859968662262\n",
            "Validation loss :1.642421329689026\n",
            "Validation Accuracy :0.8215000033378601\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6397987801742553\n",
            "Training Accuracy :0.8232599496841431\n",
            "Validation loss :1.6462752349853516\n",
            "Validation Accuracy :0.8162999749183655\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6379873553466797\n",
            "Training Accuracy :0.824679970741272\n",
            "Validation loss :1.6465659189224242\n",
            "Validation Accuracy :0.8157999515533447\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.637220966835022\n",
            "Training Accuracy :0.8253799676895142\n",
            "Validation loss :1.6443357740402222\n",
            "Validation Accuracy :0.8180999755859375\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6360872018432617\n",
            "Training Accuracy :0.8267399668693542\n",
            "Validation loss :1.6373992736816407\n",
            "Validation Accuracy :0.8252999782562256\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6332141872406005\n",
            "Training Accuracy :0.8294599652290344\n",
            "Validation loss :1.6431351892471313\n",
            "Validation Accuracy :0.8169999718666077\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6316298589324951\n",
            "Training Accuracy :0.8305400013923645\n",
            "Validation loss :1.642297709274292\n",
            "Validation Accuracy :0.8191999793052673\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6307062316894532\n",
            "Training Accuracy :0.8318600058555603\n",
            "Validation loss :1.6360693899154664\n",
            "Validation Accuracy :0.8260999917984009\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6310482718658448\n",
            "Training Accuracy :0.8309800028800964\n",
            "Validation loss :1.634039115715027\n",
            "Validation Accuracy :0.8280999660491943\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6284326314926147\n",
            "Training Accuracy :0.8345399498939514\n",
            "Validation loss :1.6402019145965576\n",
            "Validation Accuracy :0.8212999701499939\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6293009672546386\n",
            "Training Accuracy :0.832859992980957\n",
            "Validation loss :1.6339605812072755\n",
            "Validation Accuracy :0.827299952507019\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6272333980941773\n",
            "Training Accuracy :0.8349999785423279\n",
            "Validation loss :1.6312391315460204\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6268098529434205\n",
            "Training Accuracy :0.8352800011634827\n",
            "Validation loss :1.6324268175125123\n",
            "Validation Accuracy :0.8295999765396118\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6252813607788086\n",
            "Training Accuracy :0.8371999859809875\n",
            "Validation loss :1.632378977584839\n",
            "Validation Accuracy :0.8288999795913696\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6259192776107787\n",
            "Training Accuracy :0.8364199995994568\n",
            "Validation loss :1.6294390195846558\n",
            "Validation Accuracy :0.8310999870300293\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6233136535263062\n",
            "Training Accuracy :0.8388599753379822\n",
            "Validation loss :1.6300465200424195\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6233440340805054\n",
            "Training Accuracy :0.8390199542045593\n",
            "Validation loss :1.6300990674972535\n",
            "Validation Accuracy :0.8305999636650085\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6236819265747071\n",
            "Training Accuracy :0.8382399678230286\n",
            "Validation loss :1.6313654079437256\n",
            "Validation Accuracy :0.8306999802589417\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6221060388946533\n",
            "Training Accuracy :0.8400399684906006\n",
            "Validation loss :1.6297089910507203\n",
            "Validation Accuracy :0.8310999870300293\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6218490832519532\n",
            "Training Accuracy :0.840179979801178\n",
            "Validation loss :1.6302784116744995\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6210219814682008\n",
            "Training Accuracy :0.8416799902915955\n",
            "Validation loss :1.628460298538208\n",
            "Validation Accuracy :0.833299994468689\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6202390560913087\n",
            "Training Accuracy :0.8419199585914612\n",
            "Validation loss :1.6290482391357421\n",
            "Validation Accuracy :0.8319999575614929\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6199356168365477\n",
            "Training Accuracy :0.8420400023460388\n",
            "Validation loss :1.6279821159362793\n",
            "Validation Accuracy :0.8324999809265137\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.619039116897583\n",
            "Training Accuracy :0.8433600068092346\n",
            "Validation loss :1.625192186355591\n",
            "Validation Accuracy :0.8352999687194824\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.61949402469635\n",
            "Training Accuracy :0.842519998550415\n",
            "Validation loss :1.6253129915237428\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6188329048156738\n",
            "Training Accuracy :0.8432999849319458\n",
            "Validation loss :1.6255381469726562\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6173822295761109\n",
            "Training Accuracy :0.8445999622344971\n",
            "Validation loss :1.6257885749816894\n",
            "Validation Accuracy :0.8362999558448792\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6168206205749511\n",
            "Training Accuracy :0.8454799652099609\n",
            "Validation loss :1.6257638641357421\n",
            "Validation Accuracy :0.8352999687194824\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.617282400817871\n",
            "Training Accuracy :0.8450599908828735\n",
            "Validation loss :1.6255852186203004\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6170460790252685\n",
            "Training Accuracy :0.8449199795722961\n",
            "Validation loss :1.62671774559021\n",
            "Validation Accuracy :0.8344999551773071\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6166712768936158\n",
            "Training Accuracy :0.8453999757766724\n",
            "Validation loss :1.6266463537216187\n",
            "Validation Accuracy :0.8346999883651733\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6163367971038818\n",
            "Training Accuracy :0.8458399772644043\n",
            "Validation loss :1.6254270053863524\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6152609815216064\n",
            "Training Accuracy :0.8475399613380432\n",
            "Validation loss :1.6294748182296752\n",
            "Validation Accuracy :0.8315999507904053\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.615401774673462\n",
            "Training Accuracy :0.8467999696731567\n",
            "Validation loss :1.6243866184234619\n",
            "Validation Accuracy :0.8378999829292297\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6144198696899414\n",
            "Training Accuracy :0.8476999998092651\n",
            "Validation loss :1.6238389387130738\n",
            "Validation Accuracy :0.8378999829292297\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6143283404541016\n",
            "Training Accuracy :0.8477199673652649\n",
            "Validation loss :1.6245219108581543\n",
            "Validation Accuracy :0.8366999626159668\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6145703567886354\n",
            "Training Accuracy :0.8475599884986877\n",
            "Validation loss :1.628522289276123\n",
            "Validation Accuracy :0.8330000042915344\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.61391592376709\n",
            "Training Accuracy :0.8479399681091309\n",
            "Validation loss :1.6265697156906127\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6130339630126953\n",
            "Training Accuracy :0.8492599725723267\n",
            "Validation loss :1.6232778228759766\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6127931939315796\n",
            "Training Accuracy :0.8493199944496155\n",
            "Validation loss :1.6246524909973143\n",
            "Validation Accuracy :0.8371999859809875\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6124080166625976\n",
            "Training Accuracy :0.8497799634933472\n",
            "Validation loss :1.6239528076171874\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6126115531158447\n",
            "Training Accuracy :0.8496999740600586\n",
            "Validation loss :1.6241341400146485\n",
            "Validation Accuracy :0.8380999565124512\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6130486285400392\n",
            "Training Accuracy :0.8491799831390381\n",
            "Validation loss :1.6233120275497437\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6111367958450318\n",
            "Training Accuracy :0.8512799739837646\n",
            "Validation loss :1.6215278232574464\n",
            "Validation Accuracy :0.8396999835968018\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6117390203475952\n",
            "Training Accuracy :0.8502199649810791\n",
            "Validation loss :1.6231151626586915\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6113083139801025\n",
            "Training Accuracy :0.8507799506187439\n",
            "Validation loss :1.6224889526367188\n",
            "Validation Accuracy :0.8388999700546265\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6111056104278565\n",
            "Training Accuracy :0.850879967212677\n",
            "Validation loss :1.6223057949066162\n",
            "Validation Accuracy :0.8402000069618225\n",
            "Sparsity=0.10737418240000006\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302594220123291\n",
            "Training Accuracy :0.09705999493598938\n",
            "Validation loss :2.302455255126953\n",
            "Validation Accuracy :0.11639999598264694\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302428438568115\n",
            "Training Accuracy :0.10649999976158142\n",
            "Validation loss :2.3022386920928954\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3014585735321047\n",
            "Training Accuracy :0.148499995470047\n",
            "Validation loss :2.299053470611572\n",
            "Validation Accuracy :0.202799990773201\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.191295000457764\n",
            "Training Accuracy :0.31046000123023987\n",
            "Validation loss :2.033861332511902\n",
            "Validation Accuracy :0.4197999835014343\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :1.9006750754165649\n",
            "Training Accuracy :0.5843999981880188\n",
            "Validation loss :1.7816273843765258\n",
            "Validation Accuracy :0.7059999704360962\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :1.733119631614685\n",
            "Training Accuracy :0.7462999820709229\n",
            "Validation loss :1.704988509941101\n",
            "Validation Accuracy :0.7662000060081482\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.6915839041137695\n",
            "Training Accuracy :0.7775999903678894\n",
            "Validation loss :1.6848981309890747\n",
            "Validation Accuracy :0.7821999788284302\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.672734750404358\n",
            "Training Accuracy :0.7944799661636353\n",
            "Validation loss :1.671016859436035\n",
            "Validation Accuracy :0.7944999933242798\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6635259652328491\n",
            "Training Accuracy :0.8016999959945679\n",
            "Validation loss :1.662252579689026\n",
            "Validation Accuracy :0.8014999628067017\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6577039813232421\n",
            "Training Accuracy :0.8063399791717529\n",
            "Validation loss :1.6541758354187013\n",
            "Validation Accuracy :0.8109999895095825\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6535968620681762\n",
            "Training Accuracy :0.8103199601173401\n",
            "Validation loss :1.65369361038208\n",
            "Validation Accuracy :0.8084999918937683\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6486458614349366\n",
            "Training Accuracy :0.8149999976158142\n",
            "Validation loss :1.6499667793273927\n",
            "Validation Accuracy :0.8132999539375305\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6459440650177002\n",
            "Training Accuracy :0.8171599507331848\n",
            "Validation loss :1.649286604499817\n",
            "Validation Accuracy :0.8132999539375305\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6437317813110353\n",
            "Training Accuracy :0.8195399641990662\n",
            "Validation loss :1.642240077972412\n",
            "Validation Accuracy :0.8198999762535095\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6436468553924561\n",
            "Training Accuracy :0.8194599747657776\n",
            "Validation loss :1.6414885496139526\n",
            "Validation Accuracy :0.8209999799728394\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6390917374420166\n",
            "Training Accuracy :0.8241199851036072\n",
            "Validation loss :1.6427287563323976\n",
            "Validation Accuracy :0.8194999694824219\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6372355810928345\n",
            "Training Accuracy :0.8256799578666687\n",
            "Validation loss :1.6424101352691651\n",
            "Validation Accuracy :0.8193999528884888\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.63605317237854\n",
            "Training Accuracy :0.827239990234375\n",
            "Validation loss :1.636738303565979\n",
            "Validation Accuracy :0.8245999813079834\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.634653031387329\n",
            "Training Accuracy :0.8282600045204163\n",
            "Validation loss :1.6374696298599243\n",
            "Validation Accuracy :0.8235999941825867\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6330476483917236\n",
            "Training Accuracy :0.8294000029563904\n",
            "Validation loss :1.634940322494507\n",
            "Validation Accuracy :0.8262999653816223\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.633348969192505\n",
            "Training Accuracy :0.829319953918457\n",
            "Validation loss :1.6359364387512207\n",
            "Validation Accuracy :0.8247999548912048\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6311907916259765\n",
            "Training Accuracy :0.8317999839782715\n",
            "Validation loss :1.6369497514724731\n",
            "Validation Accuracy :0.8245999813079834\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6322470123672486\n",
            "Training Accuracy :0.8305000066757202\n",
            "Validation loss :1.6341383771896363\n",
            "Validation Accuracy :0.8278999924659729\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.631044541244507\n",
            "Training Accuracy :0.8314599990844727\n",
            "Validation loss :1.6353469291687013\n",
            "Validation Accuracy :0.824999988079071\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.62922233253479\n",
            "Training Accuracy :0.8332599997520447\n",
            "Validation loss :1.635053072166443\n",
            "Validation Accuracy :0.8265999555587769\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6284461642074586\n",
            "Training Accuracy :0.8336199522018433\n",
            "Validation loss :1.6328599523544312\n",
            "Validation Accuracy :0.8289999961853027\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6275097453689575\n",
            "Training Accuracy :0.8349999785423279\n",
            "Validation loss :1.6332010009765625\n",
            "Validation Accuracy :0.8288999795913696\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6265166916656495\n",
            "Training Accuracy :0.8357799649238586\n",
            "Validation loss :1.6292430145263672\n",
            "Validation Accuracy :0.8328999876976013\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.625907046546936\n",
            "Training Accuracy :0.8363800048828125\n",
            "Validation loss :1.6310573081970214\n",
            "Validation Accuracy :0.830299973487854\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6250946047592163\n",
            "Training Accuracy :0.8374199867248535\n",
            "Validation loss :1.6302748714447022\n",
            "Validation Accuracy :0.8319000005722046\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6247836365127564\n",
            "Training Accuracy :0.8376999497413635\n",
            "Validation loss :1.6352566204071044\n",
            "Validation Accuracy :0.8278999924659729\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6233660962295533\n",
            "Training Accuracy :0.8388199806213379\n",
            "Validation loss :1.628789121246338\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.623562352218628\n",
            "Training Accuracy :0.8387399911880493\n",
            "Validation loss :1.6316044666290284\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.623790097808838\n",
            "Training Accuracy :0.8380999565124512\n",
            "Validation loss :1.62892553024292\n",
            "Validation Accuracy :0.833299994468689\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.622879048500061\n",
            "Training Accuracy :0.8393399715423584\n",
            "Validation loss :1.6286097038269043\n",
            "Validation Accuracy :0.8344999551773071\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6214323024749755\n",
            "Training Accuracy :0.841219961643219\n",
            "Validation loss :1.6296398191452026\n",
            "Validation Accuracy :0.8314999938011169\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6206269760894776\n",
            "Training Accuracy :0.8420999646186829\n",
            "Validation loss :1.6286886688232423\n",
            "Validation Accuracy :0.8330999612808228\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6205070415878295\n",
            "Training Accuracy :0.8415199518203735\n",
            "Validation loss :1.6274600772857666\n",
            "Validation Accuracy :0.8345999717712402\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6194368683624267\n",
            "Training Accuracy :0.8428399562835693\n",
            "Validation loss :1.6286897464752197\n",
            "Validation Accuracy :0.8331999778747559\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.619605948791504\n",
            "Training Accuracy :0.8424999713897705\n",
            "Validation loss :1.6268929656982423\n",
            "Validation Accuracy :0.8337000012397766\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.619961870765686\n",
            "Training Accuracy :0.8422399759292603\n",
            "Validation loss :1.6283536365509033\n",
            "Validation Accuracy :0.8330999612808228\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6191415367889403\n",
            "Training Accuracy :0.8428399562835693\n",
            "Validation loss :1.6276453605651855\n",
            "Validation Accuracy :0.8337999582290649\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6187754926300049\n",
            "Training Accuracy :0.8432199954986572\n",
            "Validation loss :1.626432900238037\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6181359787750245\n",
            "Training Accuracy :0.8438799977302551\n",
            "Validation loss :1.6254842517852783\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6175609106445312\n",
            "Training Accuracy :0.8445199728012085\n",
            "Validation loss :1.6257220464706421\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6165453298568726\n",
            "Training Accuracy :0.8456799983978271\n",
            "Validation loss :1.6261179113388062\n",
            "Validation Accuracy :0.8349999785423279\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.617690112991333\n",
            "Training Accuracy :0.8446399569511414\n",
            "Validation loss :1.6245003273010254\n",
            "Validation Accuracy :0.8374999761581421\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6161575313568115\n",
            "Training Accuracy :0.8457599878311157\n",
            "Validation loss :1.6238839130401612\n",
            "Validation Accuracy :0.8375999927520752\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6156337902832032\n",
            "Training Accuracy :0.8467599749565125\n",
            "Validation loss :1.6253194732666016\n",
            "Validation Accuracy :0.8359000086784363\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6153011696624755\n",
            "Training Accuracy :0.8471599817276001\n",
            "Validation loss :1.6247033723831177\n",
            "Validation Accuracy :0.8366999626159668\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6150554660797118\n",
            "Training Accuracy :0.8473399877548218\n",
            "Validation loss :1.6247156440734862\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.615582875099182\n",
            "Training Accuracy :0.8464799523353577\n",
            "Validation loss :1.626193532180786\n",
            "Validation Accuracy :0.8348999619483948\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6145896488189697\n",
            "Training Accuracy :0.8475399613380432\n",
            "Validation loss :1.6235411678314209\n",
            "Validation Accuracy :0.8381999731063843\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6135296305084228\n",
            "Training Accuracy :0.8486199975013733\n",
            "Validation loss :1.6263161695480346\n",
            "Validation Accuracy :0.8355000019073486\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6138801392364501\n",
            "Training Accuracy :0.8480599522590637\n",
            "Validation loss :1.6241971103668214\n",
            "Validation Accuracy :0.8371999859809875\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6134609896850587\n",
            "Training Accuracy :0.8485599756240845\n",
            "Validation loss :1.6256502183914185\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6139181769561768\n",
            "Training Accuracy :0.8482199907302856\n",
            "Validation loss :1.625028637123108\n",
            "Validation Accuracy :0.8359999656677246\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6129083435440064\n",
            "Training Accuracy :0.8496599793434143\n",
            "Validation loss :1.6247447193145752\n",
            "Validation Accuracy :0.8366000056266785\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6127613137435912\n",
            "Training Accuracy :0.8492599725723267\n",
            "Validation loss :1.6234294008255006\n",
            "Validation Accuracy :0.837399959564209\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6128444204330443\n",
            "Training Accuracy :0.8494199514389038\n",
            "Validation loss :1.6250638349533082\n",
            "Validation Accuracy :0.8360999822616577\n",
            "Sparsity=0.08589934592000005\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3025947494506838\n",
            "Training Accuracy :0.09713999927043915\n",
            "Validation loss :2.3026344718933105\n",
            "Validation Accuracy :0.09759999811649323\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302543867111206\n",
            "Training Accuracy :0.09823999553918839\n",
            "Validation loss :2.302609014892578\n",
            "Validation Accuracy :0.10649999976158142\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302455040512085\n",
            "Training Accuracy :0.11925999820232391\n",
            "Validation loss :2.3024908752441404\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.30212072555542\n",
            "Training Accuracy :0.11595999449491501\n",
            "Validation loss :2.301739044189453\n",
            "Validation Accuracy :0.13830000162124634\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.2858517594909666\n",
            "Training Accuracy :0.20117999613285065\n",
            "Validation loss :2.2156503955841065\n",
            "Validation Accuracy :0.2003999948501587\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.0442111993408205\n",
            "Training Accuracy :0.42851999402046204\n",
            "Validation loss :1.9220025396347047\n",
            "Validation Accuracy :0.5620999932289124\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :1.8264658138656615\n",
            "Training Accuracy :0.6603400111198425\n",
            "Validation loss :1.7535654558181764\n",
            "Validation Accuracy :0.7235999703407288\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.7227279806518554\n",
            "Training Accuracy :0.7515400052070618\n",
            "Validation loss :1.7011853635787964\n",
            "Validation Accuracy :0.7699999809265137\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.6911231030654907\n",
            "Training Accuracy :0.7779799699783325\n",
            "Validation loss :1.6817947734832763\n",
            "Validation Accuracy :0.7866999506950378\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6775561953735352\n",
            "Training Accuracy :0.7889599800109863\n",
            "Validation loss :1.6719814121246337\n",
            "Validation Accuracy :0.7930999994277954\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6683719003677369\n",
            "Training Accuracy :0.7969399690628052\n",
            "Validation loss :1.6655399868011476\n",
            "Validation Accuracy :0.7991999983787537\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6605152011871338\n",
            "Training Accuracy :0.8043799996376038\n",
            "Validation loss :1.664004905128479\n",
            "Validation Accuracy :0.7989999651908875\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6560903841400147\n",
            "Training Accuracy :0.8082799911499023\n",
            "Validation loss :1.6584003011703492\n",
            "Validation Accuracy :0.8039999604225159\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6505167580413818\n",
            "Training Accuracy :0.8131200075149536\n",
            "Validation loss :1.6549585218429566\n",
            "Validation Accuracy :0.8078999519348145\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6476319995117188\n",
            "Training Accuracy :0.816100001335144\n",
            "Validation loss :1.6490877618789672\n",
            "Validation Accuracy :0.8139999508857727\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6435775561523438\n",
            "Training Accuracy :0.8197999596595764\n",
            "Validation loss :1.6450518089294432\n",
            "Validation Accuracy :0.8170999884605408\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.641437681274414\n",
            "Training Accuracy :0.8215199708938599\n",
            "Validation loss :1.647437347984314\n",
            "Validation Accuracy :0.8133999705314636\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6389409519195557\n",
            "Training Accuracy :0.8236599564552307\n",
            "Validation loss :1.6440310388565063\n",
            "Validation Accuracy :0.8162999749183655\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6385659062957765\n",
            "Training Accuracy :0.824180006980896\n",
            "Validation loss :1.644114616394043\n",
            "Validation Accuracy :0.8179999589920044\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6376662005615235\n",
            "Training Accuracy :0.8246999979019165\n",
            "Validation loss :1.6434641838073731\n",
            "Validation Accuracy :0.8174999952316284\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6343323203277589\n",
            "Training Accuracy :0.8285999894142151\n",
            "Validation loss :1.6411358015060424\n",
            "Validation Accuracy :0.8197000026702881\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6338396215057374\n",
            "Training Accuracy :0.8289200067520142\n",
            "Validation loss :1.6395903135299683\n",
            "Validation Accuracy :0.8219999670982361\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6314664075469971\n",
            "Training Accuracy :0.8311799764633179\n",
            "Validation loss :1.6400328870773315\n",
            "Validation Accuracy :0.8210999965667725\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6311682132720948\n",
            "Training Accuracy :0.831119954586029\n",
            "Validation loss :1.6367618549346923\n",
            "Validation Accuracy :0.8262999653816223\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6310776615142821\n",
            "Training Accuracy :0.8319999575614929\n",
            "Validation loss :1.6362375274658203\n",
            "Validation Accuracy :0.8264999985694885\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6299104023742677\n",
            "Training Accuracy :0.8321999907493591\n",
            "Validation loss :1.6334625915527343\n",
            "Validation Accuracy :0.8276999592781067\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6277682697296143\n",
            "Training Accuracy :0.8339599967002869\n",
            "Validation loss :1.6336432786941528\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6275829232788086\n",
            "Training Accuracy :0.8358599543571472\n",
            "Validation loss :1.6348770503997803\n",
            "Validation Accuracy :0.8264999985694885\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6266945267486572\n",
            "Training Accuracy :0.8358599543571472\n",
            "Validation loss :1.6312156566619873\n",
            "Validation Accuracy :0.8312999606132507\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6262932878875733\n",
            "Training Accuracy :0.8359599709510803\n",
            "Validation loss :1.6319090744018554\n",
            "Validation Accuracy :0.8294000029563904\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6267406296157836\n",
            "Training Accuracy :0.8350799679756165\n",
            "Validation loss :1.6319789054870606\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6243578810882568\n",
            "Training Accuracy :0.8379999995231628\n",
            "Validation loss :1.6323360048294067\n",
            "Validation Accuracy :0.8291999697685242\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6257305575561523\n",
            "Training Accuracy :0.8361799716949463\n",
            "Validation loss :1.6284383668899536\n",
            "Validation Accuracy :0.8327999711036682\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.623005299911499\n",
            "Training Accuracy :0.8395199775695801\n",
            "Validation loss :1.6290288600921632\n",
            "Validation Accuracy :0.8333999514579773\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6230436748886108\n",
            "Training Accuracy :0.8389999866485596\n",
            "Validation loss :1.632593999481201\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.622218031616211\n",
            "Training Accuracy :0.8400399684906006\n",
            "Validation loss :1.6321980834960939\n",
            "Validation Accuracy :0.8299999833106995\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6212707614898683\n",
            "Training Accuracy :0.8410799503326416\n",
            "Validation loss :1.628016104888916\n",
            "Validation Accuracy :0.8345999717712402\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6206762372207641\n",
            "Training Accuracy :0.841219961643219\n",
            "Validation loss :1.6276464218139648\n",
            "Validation Accuracy :0.8344999551773071\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.621539723777771\n",
            "Training Accuracy :0.840499997138977\n",
            "Validation loss :1.6297498062133788\n",
            "Validation Accuracy :0.8314999938011169\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6203716684341432\n",
            "Training Accuracy :0.8420599699020386\n",
            "Validation loss :1.6299270448684693\n",
            "Validation Accuracy :0.8317999839782715\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6198909477996826\n",
            "Training Accuracy :0.8423999547958374\n",
            "Validation loss :1.6314157426834106\n",
            "Validation Accuracy :0.830299973487854\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6203193362808228\n",
            "Training Accuracy :0.8420199751853943\n",
            "Validation loss :1.6272968732833861\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6194564276123047\n",
            "Training Accuracy :0.8429200053215027\n",
            "Validation loss :1.626861373901367\n",
            "Validation Accuracy :0.8345999717712402\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6182682593536377\n",
            "Training Accuracy :0.8439399600028992\n",
            "Validation loss :1.625525997543335\n",
            "Validation Accuracy :0.835599958896637\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6181134210968018\n",
            "Training Accuracy :0.8440399765968323\n",
            "Validation loss :1.6246937095642089\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6178851538467407\n",
            "Training Accuracy :0.8440999984741211\n",
            "Validation loss :1.6268303411483764\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6179779861068726\n",
            "Training Accuracy :0.8439599871635437\n",
            "Validation loss :1.6256067869186401\n",
            "Validation Accuracy :0.835099995136261\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6170298261260987\n",
            "Training Accuracy :0.8452199697494507\n",
            "Validation loss :1.6285393548965454\n",
            "Validation Accuracy :0.8334999680519104\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6166012270355226\n",
            "Training Accuracy :0.8455999493598938\n",
            "Validation loss :1.6254881950378417\n",
            "Validation Accuracy :0.8359000086784363\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6168255626678467\n",
            "Training Accuracy :0.8453599810600281\n",
            "Validation loss :1.6245876655578613\n",
            "Validation Accuracy :0.8373000025749207\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6170058769989013\n",
            "Training Accuracy :0.8451799750328064\n",
            "Validation loss :1.6256074796676636\n",
            "Validation Accuracy :0.8356999754905701\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6163389910125732\n",
            "Training Accuracy :0.8455999493598938\n",
            "Validation loss :1.6284542474746704\n",
            "Validation Accuracy :0.8335999846458435\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6160371926498414\n",
            "Training Accuracy :0.8457199931144714\n",
            "Validation loss :1.6299650226593017\n",
            "Validation Accuracy :0.8309999704360962\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6152558382415771\n",
            "Training Accuracy :0.8472399711608887\n",
            "Validation loss :1.6244354417800904\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.614921353225708\n",
            "Training Accuracy :0.8470799922943115\n",
            "Validation loss :1.6280830863952638\n",
            "Validation Accuracy :0.8333999514579773\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6146584644317628\n",
            "Training Accuracy :0.8476799726486206\n",
            "Validation loss :1.6266874746322633\n",
            "Validation Accuracy :0.8339999914169312\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6146377365112305\n",
            "Training Accuracy :0.8474400043487549\n",
            "Validation loss :1.6245440301895142\n",
            "Validation Accuracy :0.8364999890327454\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.614111385498047\n",
            "Training Accuracy :0.8482799530029297\n",
            "Validation loss :1.6259429592132568\n",
            "Validation Accuracy :0.8351999521255493\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6146009744644165\n",
            "Training Accuracy :0.8471999764442444\n",
            "Validation loss :1.627330839920044\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6136566598510742\n",
            "Training Accuracy :0.8490399718284607\n",
            "Validation loss :1.6225225145339965\n",
            "Validation Accuracy :0.8396999835968018\n",
            "Sparsity=0.06871947673600004\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302595057296753\n",
            "Training Accuracy :0.09963999688625336\n",
            "Validation loss :2.3026481746673584\n",
            "Validation Accuracy :0.10179999470710754\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3025626834106445\n",
            "Training Accuracy :0.10041999816894531\n",
            "Validation loss :2.3026563232421875\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3025245874786378\n",
            "Training Accuracy :0.10319999605417252\n",
            "Validation loss :2.3026202785491945\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3024152482604983\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3024541004180907\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3019138201141356\n",
            "Training Accuracy :0.11367999762296677\n",
            "Validation loss :2.3011578510284423\n",
            "Validation Accuracy :0.16279999911785126\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.2715616417694093\n",
            "Training Accuracy :0.20867998898029327\n",
            "Validation loss :2.214199299621582\n",
            "Validation Accuracy :0.19990000128746033\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.0699930123901367\n",
            "Training Accuracy :0.40233999490737915\n",
            "Validation loss :1.9430285026550294\n",
            "Validation Accuracy :0.5331999659538269\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :1.8490622423934937\n",
            "Training Accuracy :0.6375600099563599\n",
            "Validation loss :1.7502336429595948\n",
            "Validation Accuracy :0.733199954032898\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.720604599609375\n",
            "Training Accuracy :0.7518999576568604\n",
            "Validation loss :1.7009550245285034\n",
            "Validation Accuracy :0.7690999507904053\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.6944015740966798\n",
            "Training Accuracy :0.7731199860572815\n",
            "Validation loss :1.6864163776397705\n",
            "Validation Accuracy :0.7792999744415283\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.6821157830810547\n",
            "Training Accuracy :0.7839999794960022\n",
            "Validation loss :1.6789807683944702\n",
            "Validation Accuracy :0.7863999605178833\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.673683380470276\n",
            "Training Accuracy :0.7908999919891357\n",
            "Validation loss :1.674224144935608\n",
            "Validation Accuracy :0.7908999919891357\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6680427661514283\n",
            "Training Accuracy :0.7968199849128723\n",
            "Validation loss :1.6756828826904298\n",
            "Validation Accuracy :0.7870000004768372\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6632017824935914\n",
            "Training Accuracy :0.8008999824523926\n",
            "Validation loss :1.6651988864898681\n",
            "Validation Accuracy :0.7978000044822693\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6586109307861328\n",
            "Training Accuracy :0.8051999807357788\n",
            "Validation loss :1.6610546089172362\n",
            "Validation Accuracy :0.8026999831199646\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6570761449432374\n",
            "Training Accuracy :0.8075000047683716\n",
            "Validation loss :1.6571809225082397\n",
            "Validation Accuracy :0.8065999746322632\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.6522475275421142\n",
            "Training Accuracy :0.8107999563217163\n",
            "Validation loss :1.6535964054107666\n",
            "Validation Accuracy :0.808899998664856\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6485419214248658\n",
            "Training Accuracy :0.8148199915885925\n",
            "Validation loss :1.6574467071533203\n",
            "Validation Accuracy :0.8060999512672424\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6464772552108764\n",
            "Training Accuracy :0.8174999952316284\n",
            "Validation loss :1.6509304969787597\n",
            "Validation Accuracy :0.8111000061035156\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6448936396026612\n",
            "Training Accuracy :0.8184599876403809\n",
            "Validation loss :1.647389449119568\n",
            "Validation Accuracy :0.8151999711990356\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.644402326889038\n",
            "Training Accuracy :0.8190199732780457\n",
            "Validation loss :1.65130193901062\n",
            "Validation Accuracy :0.8115999698638916\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6418589623260498\n",
            "Training Accuracy :0.8213799595832825\n",
            "Validation loss :1.6449913381576537\n",
            "Validation Accuracy :0.8173999786376953\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6410711333847046\n",
            "Training Accuracy :0.8222799897193909\n",
            "Validation loss :1.6457238903045655\n",
            "Validation Accuracy :0.8155999779701233\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6387655639266967\n",
            "Training Accuracy :0.8238199949264526\n",
            "Validation loss :1.6444422220230102\n",
            "Validation Accuracy :0.8174999952316284\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6378091405868531\n",
            "Training Accuracy :0.8247799873352051\n",
            "Validation loss :1.644482704925537\n",
            "Validation Accuracy :0.8179000020027161\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6362230581665038\n",
            "Training Accuracy :0.8268199563026428\n",
            "Validation loss :1.6412842224121094\n",
            "Validation Accuracy :0.8209999799728394\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6348418257904054\n",
            "Training Accuracy :0.8283799886703491\n",
            "Validation loss :1.6387336248397828\n",
            "Validation Accuracy :0.8237999677658081\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.634934361152649\n",
            "Training Accuracy :0.8277199864387512\n",
            "Validation loss :1.6413980491638183\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6342402976226806\n",
            "Training Accuracy :0.8282999992370605\n",
            "Validation loss :1.6378608982086182\n",
            "Validation Accuracy :0.8238999843597412\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.632279232711792\n",
            "Training Accuracy :0.8299799561500549\n",
            "Validation loss :1.6378305810928344\n",
            "Validation Accuracy :0.8253999948501587\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6331501459503175\n",
            "Training Accuracy :0.829319953918457\n",
            "Validation loss :1.6369090757369995\n",
            "Validation Accuracy :0.824400007724762\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6318724552154542\n",
            "Training Accuracy :0.8306399583816528\n",
            "Validation loss :1.640139917564392\n",
            "Validation Accuracy :0.8211999535560608\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6313955123519897\n",
            "Training Accuracy :0.8311399817466736\n",
            "Validation loss :1.6355798166275024\n",
            "Validation Accuracy :0.8267999887466431\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6292276781845092\n",
            "Training Accuracy :0.832859992980957\n",
            "Validation loss :1.6361950017929077\n",
            "Validation Accuracy :0.8263999819755554\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6290431603622437\n",
            "Training Accuracy :0.8331799507141113\n",
            "Validation loss :1.6375463787078857\n",
            "Validation Accuracy :0.8229999542236328\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6290344695663452\n",
            "Training Accuracy :0.8339999914169312\n",
            "Validation loss :1.635098847770691\n",
            "Validation Accuracy :0.827299952507019\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6278771579742433\n",
            "Training Accuracy :0.834879994392395\n",
            "Validation loss :1.6317873956680298\n",
            "Validation Accuracy :0.8310999870300293\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6274607346343994\n",
            "Training Accuracy :0.835599958896637\n",
            "Validation loss :1.6355240949630738\n",
            "Validation Accuracy :0.8269999623298645\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.626980891342163\n",
            "Training Accuracy :0.835099995136261\n",
            "Validation loss :1.6343537214279176\n",
            "Validation Accuracy :0.8270999789237976\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6268500994873047\n",
            "Training Accuracy :0.8356199860572815\n",
            "Validation loss :1.6339194032669067\n",
            "Validation Accuracy :0.8276999592781067\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6254981925201415\n",
            "Training Accuracy :0.8364799618721008\n",
            "Validation loss :1.6371169710159301\n",
            "Validation Accuracy :0.8248999714851379\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.625356255531311\n",
            "Training Accuracy :0.8371399641036987\n",
            "Validation loss :1.6318796297073364\n",
            "Validation Accuracy :0.8305999636650085\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6254467429351807\n",
            "Training Accuracy :0.8369799852371216\n",
            "Validation loss :1.6339310632705688\n",
            "Validation Accuracy :0.8279999494552612\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6243063653564453\n",
            "Training Accuracy :0.838379979133606\n",
            "Validation loss :1.6406515481948853\n",
            "Validation Accuracy :0.8199999928474426\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6239369304656983\n",
            "Training Accuracy :0.838379979133606\n",
            "Validation loss :1.6325090560913087\n",
            "Validation Accuracy :0.8296999931335449\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6241778400421143\n",
            "Training Accuracy :0.8378999829292297\n",
            "Validation loss :1.6339321332931518\n",
            "Validation Accuracy :0.8259999752044678\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6246393587493897\n",
            "Training Accuracy :0.8375399708747864\n",
            "Validation loss :1.6367555372238158\n",
            "Validation Accuracy :0.8237999677658081\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6226259548568727\n",
            "Training Accuracy :0.8402799963951111\n",
            "Validation loss :1.6352190114974976\n",
            "Validation Accuracy :0.8251999616622925\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6231473555755616\n",
            "Training Accuracy :0.8389599919319153\n",
            "Validation loss :1.6305066843032836\n",
            "Validation Accuracy :0.8305999636650085\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.622436353187561\n",
            "Training Accuracy :0.8398199677467346\n",
            "Validation loss :1.6369425605773926\n",
            "Validation Accuracy :0.8246999979019165\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6223844373321534\n",
            "Training Accuracy :0.8399999737739563\n",
            "Validation loss :1.6306139976501466\n",
            "Validation Accuracy :0.8312000036239624\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.621296759109497\n",
            "Training Accuracy :0.8414599895477295\n",
            "Validation loss :1.6297617263793944\n",
            "Validation Accuracy :0.8319999575614929\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.62189062210083\n",
            "Training Accuracy :0.8405799865722656\n",
            "Validation loss :1.6301388010025024\n",
            "Validation Accuracy :0.8319999575614929\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.622207610244751\n",
            "Training Accuracy :0.8397600054740906\n",
            "Validation loss :1.6311223852157593\n",
            "Validation Accuracy :0.830299973487854\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6203557916641236\n",
            "Training Accuracy :0.8420400023460388\n",
            "Validation loss :1.6285989551544189\n",
            "Validation Accuracy :0.833299994468689\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6211326522827147\n",
            "Training Accuracy :0.8413999676704407\n",
            "Validation loss :1.629052787590027\n",
            "Validation Accuracy :0.8326999545097351\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6198981697845458\n",
            "Training Accuracy :0.8427000045776367\n",
            "Validation loss :1.627811417388916\n",
            "Validation Accuracy :0.833899974822998\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6194380200195313\n",
            "Training Accuracy :0.8428399562835693\n",
            "Validation loss :1.6290677387237549\n",
            "Validation Accuracy :0.833299994468689\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6202066228103638\n",
            "Training Accuracy :0.8423999547958374\n",
            "Validation loss :1.6288537828445435\n",
            "Validation Accuracy :0.8327999711036682\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.619209582862854\n",
            "Training Accuracy :0.8431199789047241\n",
            "Validation loss :1.629017112159729\n",
            "Validation Accuracy :0.8321999907493591\n",
            "Sparsity=0.054975581388800036\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3026390269470216\n",
            "Training Accuracy :0.10012000054121017\n",
            "Validation loss :2.302607006072998\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302604963760376\n",
            "Training Accuracy :0.10103999823331833\n",
            "Validation loss :2.3026110481262205\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3025764910125734\n",
            "Training Accuracy :0.10473999381065369\n",
            "Validation loss :2.3026242111206057\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025339597320555\n",
            "Training Accuracy :0.10291999578475952\n",
            "Validation loss :2.3026095989227295\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.302460718231201\n",
            "Training Accuracy :0.1008399948477745\n",
            "Validation loss :2.302503572845459\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3021406340026855\n",
            "Training Accuracy :0.10731999576091766\n",
            "Validation loss :2.3017628269195556\n",
            "Validation Accuracy :0.13580000400543213\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.285395546417236\n",
            "Training Accuracy :0.20126000046730042\n",
            "Validation loss :2.2245711177825926\n",
            "Validation Accuracy :0.22439999878406525\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.1392373487854\n",
            "Training Accuracy :0.3297799825668335\n",
            "Validation loss :2.016367192649841\n",
            "Validation Accuracy :0.4324999749660492\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :1.9000822870635987\n",
            "Training Accuracy :0.5880999565124512\n",
            "Validation loss :1.7919016275405883\n",
            "Validation Accuracy :0.6869999766349792\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.7516918036651612\n",
            "Training Accuracy :0.7261799573898315\n",
            "Validation loss :1.7192635105133056\n",
            "Validation Accuracy :0.7532999515533447\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.7087578548431397\n",
            "Training Accuracy :0.7608399987220764\n",
            "Validation loss :1.6973630088806153\n",
            "Validation Accuracy :0.7694000005722046\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.6898077874374389\n",
            "Training Accuracy :0.7770799994468689\n",
            "Validation loss :1.6858631870269776\n",
            "Validation Accuracy :0.7825999855995178\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6760185287857057\n",
            "Training Accuracy :0.7908799648284912\n",
            "Validation loss :1.673424543571472\n",
            "Validation Accuracy :0.793999969959259\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6693988381195068\n",
            "Training Accuracy :0.796239972114563\n",
            "Validation loss :1.6669517297744751\n",
            "Validation Accuracy :0.7991999983787537\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.6633013958740235\n",
            "Training Accuracy :0.8021799921989441\n",
            "Validation loss :1.6635071910858155\n",
            "Validation Accuracy :0.8014000058174133\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6600688805770873\n",
            "Training Accuracy :0.8041999936103821\n",
            "Validation loss :1.660096311378479\n",
            "Validation Accuracy :0.8024999499320984\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.656435341720581\n",
            "Training Accuracy :0.8075799942016602\n",
            "Validation loss :1.6594507223129273\n",
            "Validation Accuracy :0.8027999997138977\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.65491231716156\n",
            "Training Accuracy :0.8085599541664124\n",
            "Validation loss :1.6554337411880493\n",
            "Validation Accuracy :0.8057999610900879\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6520794593048096\n",
            "Training Accuracy :0.8121399879455566\n",
            "Validation loss :1.653122207260132\n",
            "Validation Accuracy :0.8078999519348145\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6498585412979125\n",
            "Training Accuracy :0.8130799531936646\n",
            "Validation loss :1.6516729625701905\n",
            "Validation Accuracy :0.8101999759674072\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6497173036956787\n",
            "Training Accuracy :0.8136199712753296\n",
            "Validation loss :1.6525508880615234\n",
            "Validation Accuracy :0.8095999956130981\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6474451499176026\n",
            "Training Accuracy :0.814740002155304\n",
            "Validation loss :1.6479563121795655\n",
            "Validation Accuracy :0.8140999674797058\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6457987106704712\n",
            "Training Accuracy :0.8176199793815613\n",
            "Validation loss :1.6471244567871093\n",
            "Validation Accuracy :0.8150999546051025\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6429935928726196\n",
            "Training Accuracy :0.8201999664306641\n",
            "Validation loss :1.6482149427413941\n",
            "Validation Accuracy :0.814300000667572\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.642567558631897\n",
            "Training Accuracy :0.8205399513244629\n",
            "Validation loss :1.648392215156555\n",
            "Validation Accuracy :0.8136000037193298\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.641346987876892\n",
            "Training Accuracy :0.8218799829483032\n",
            "Validation loss :1.6446442615509034\n",
            "Validation Accuracy :0.8176999688148499\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6390056970977782\n",
            "Training Accuracy :0.8240999579429626\n",
            "Validation loss :1.6443623205184936\n",
            "Validation Accuracy :0.8181999921798706\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6381330295181273\n",
            "Training Accuracy :0.8250399827957153\n",
            "Validation loss :1.6399908432006836\n",
            "Validation Accuracy :0.8223999738693237\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.638368236694336\n",
            "Training Accuracy :0.8242599964141846\n",
            "Validation loss :1.6423586477279664\n",
            "Validation Accuracy :0.8199999928474426\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6375604723358155\n",
            "Training Accuracy :0.8254599571228027\n",
            "Validation loss :1.640499131011963\n",
            "Validation Accuracy :0.8215000033378601\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6372193773651122\n",
            "Training Accuracy :0.8247999548912048\n",
            "Validation loss :1.6414080629348755\n",
            "Validation Accuracy :0.8203999996185303\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6352379504776\n",
            "Training Accuracy :0.8269999623298645\n",
            "Validation loss :1.6403866973876953\n",
            "Validation Accuracy :0.8216999769210815\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.634887388267517\n",
            "Training Accuracy :0.8274199962615967\n",
            "Validation loss :1.6398474437713624\n",
            "Validation Accuracy :0.8224999904632568\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6347118863677979\n",
            "Training Accuracy :0.8275399804115295\n",
            "Validation loss :1.6402670595169067\n",
            "Validation Accuracy :0.8210999965667725\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6335772344207764\n",
            "Training Accuracy :0.8291199803352356\n",
            "Validation loss :1.6397007452011108\n",
            "Validation Accuracy :0.8228999972343445\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.63298541015625\n",
            "Training Accuracy :0.8296399712562561\n",
            "Validation loss :1.6476547624588012\n",
            "Validation Accuracy :0.8136000037193298\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.633709351348877\n",
            "Training Accuracy :0.828279972076416\n",
            "Validation loss :1.6394837779998779\n",
            "Validation Accuracy :0.8226999640464783\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6316274188232422\n",
            "Training Accuracy :0.8305599689483643\n",
            "Validation loss :1.6399568712234498\n",
            "Validation Accuracy :0.8230999708175659\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6325190504455567\n",
            "Training Accuracy :0.8298799991607666\n",
            "Validation loss :1.635921847343445\n",
            "Validation Accuracy :0.8251999616622925\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6306342346191407\n",
            "Training Accuracy :0.831339955329895\n",
            "Validation loss :1.6358152778625488\n",
            "Validation Accuracy :0.8253999948501587\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6305871449279785\n",
            "Training Accuracy :0.8315399885177612\n",
            "Validation loss :1.6365848279953004\n",
            "Validation Accuracy :0.8251999616622925\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6295590020751953\n",
            "Training Accuracy :0.832859992980957\n",
            "Validation loss :1.6356950109481811\n",
            "Validation Accuracy :0.8256999850273132\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6292105948257447\n",
            "Training Accuracy :0.8328999876976013\n",
            "Validation loss :1.636583388710022\n",
            "Validation Accuracy :0.8240000009536743\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6300445873260498\n",
            "Training Accuracy :0.8325200080871582\n",
            "Validation loss :1.6362429498672486\n",
            "Validation Accuracy :0.824999988079071\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6292816427993775\n",
            "Training Accuracy :0.8328999876976013\n",
            "Validation loss :1.6354749732971192\n",
            "Validation Accuracy :0.8258000016212463\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6290537720108031\n",
            "Training Accuracy :0.8332200050354004\n",
            "Validation loss :1.6329959720611573\n",
            "Validation Accuracy :0.8285999894142151\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6280448108673096\n",
            "Training Accuracy :0.8342199921607971\n",
            "Validation loss :1.6390084054946898\n",
            "Validation Accuracy :0.8227999806404114\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.628101552734375\n",
            "Training Accuracy :0.8337799906730652\n",
            "Validation loss :1.6357606992721558\n",
            "Validation Accuracy :0.8258999586105347\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6273700323104858\n",
            "Training Accuracy :0.8345800042152405\n",
            "Validation loss :1.6339330127716065\n",
            "Validation Accuracy :0.8271999955177307\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6270243552398682\n",
            "Training Accuracy :0.835099995136261\n",
            "Validation loss :1.636060549736023\n",
            "Validation Accuracy :0.8245999813079834\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.626697499923706\n",
            "Training Accuracy :0.8358199596405029\n",
            "Validation loss :1.633848289680481\n",
            "Validation Accuracy :0.827299952507019\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6267644794845582\n",
            "Training Accuracy :0.8358599543571472\n",
            "Validation loss :1.634989280128479\n",
            "Validation Accuracy :0.8274999856948853\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6271343492889405\n",
            "Training Accuracy :0.8350600004196167\n",
            "Validation loss :1.634139256286621\n",
            "Validation Accuracy :0.8279999494552612\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.626733539085388\n",
            "Training Accuracy :0.835379958152771\n",
            "Validation loss :1.6350035438537598\n",
            "Validation Accuracy :0.8267999887466431\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6260599796295165\n",
            "Training Accuracy :0.8359400033950806\n",
            "Validation loss :1.6343635856628418\n",
            "Validation Accuracy :0.8276000022888184\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6251928232574462\n",
            "Training Accuracy :0.8373399972915649\n",
            "Validation loss :1.6320580797195434\n",
            "Validation Accuracy :0.8292999863624573\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6243298822021484\n",
            "Training Accuracy :0.8382799625396729\n",
            "Validation loss :1.6323732524871826\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6238501797485352\n",
            "Training Accuracy :0.8383199572563171\n",
            "Validation loss :1.632834476852417\n",
            "Validation Accuracy :0.8292999863624573\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6246056328582763\n",
            "Training Accuracy :0.8369999527931213\n",
            "Validation loss :1.6319753150939942\n",
            "Validation Accuracy :0.8283999562263489\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6239623931503295\n",
            "Training Accuracy :0.838379979133606\n",
            "Validation loss :1.6329283243179322\n",
            "Validation Accuracy :0.8282999992370605\n",
            "Sparsity=0.043980465111040035\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3025980851745604\n",
            "Training Accuracy :0.09861999750137329\n",
            "Validation loss :2.302704964828491\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302585542297363\n",
            "Training Accuracy :0.09985999763011932\n",
            "Validation loss :2.302705809020996\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302561851272583\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30269690284729\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025325248718262\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026786655426026\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.302474652175903\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302590072631836\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3022129023742677\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3020239479064943\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.2926446926879884\n",
            "Training Accuracy :0.17175999283790588\n",
            "Validation loss :2.246358798980713\n",
            "Validation Accuracy :0.18809999525547028\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.198440531692505\n",
            "Training Accuracy :0.23683999478816986\n",
            "Validation loss :2.1232319416046144\n",
            "Validation Accuracy :0.3294000029563904\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.046619819068909\n",
            "Training Accuracy :0.40469998121261597\n",
            "Validation loss :1.9888120986938476\n",
            "Validation Accuracy :0.4575999975204468\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :1.870879213180542\n",
            "Training Accuracy :0.6132799983024597\n",
            "Validation loss :1.767253863143921\n",
            "Validation Accuracy :0.7333999872207642\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :1.7312086267089843\n",
            "Training Accuracy :0.7483800053596497\n",
            "Validation loss :1.7119872364044189\n",
            "Validation Accuracy :0.7616999745368958\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :1.701044415359497\n",
            "Training Accuracy :0.7682600021362305\n",
            "Validation loss :1.6948865598678589\n",
            "Validation Accuracy :0.771399974822998\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.6888574261093139\n",
            "Training Accuracy :0.7774800062179565\n",
            "Validation loss :1.6845731830596924\n",
            "Validation Accuracy :0.7807999849319458\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.6793296060943603\n",
            "Training Accuracy :0.786579966545105\n",
            "Validation loss :1.679818816947937\n",
            "Validation Accuracy :0.7856000065803528\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.672919096031189\n",
            "Training Accuracy :0.7925999760627747\n",
            "Validation loss :1.6673972995758057\n",
            "Validation Accuracy :0.7979999780654907\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6665343358612061\n",
            "Training Accuracy :0.7980200052261353\n",
            "Validation loss :1.6664761856079102\n",
            "Validation Accuracy :0.7963999509811401\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.662424164123535\n",
            "Training Accuracy :0.801539957523346\n",
            "Validation loss :1.6607351802825927\n",
            "Validation Accuracy :0.8023999929428101\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6589038246917724\n",
            "Training Accuracy :0.8042999505996704\n",
            "Validation loss :1.6559149625778198\n",
            "Validation Accuracy :0.8071999549865723\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6550022116851806\n",
            "Training Accuracy :0.8086999654769897\n",
            "Validation loss :1.6552212228775025\n",
            "Validation Accuracy :0.8077999949455261\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6526168923568725\n",
            "Training Accuracy :0.8114199638366699\n",
            "Validation loss :1.652576743888855\n",
            "Validation Accuracy :0.8098999857902527\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.649603921852112\n",
            "Training Accuracy :0.8130999803543091\n",
            "Validation loss :1.6592840579986572\n",
            "Validation Accuracy :0.8041999936103821\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.6476572088241577\n",
            "Training Accuracy :0.8156599998474121\n",
            "Validation loss :1.6506520685195922\n",
            "Validation Accuracy :0.8115999698638916\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6462109029388428\n",
            "Training Accuracy :0.8166599869728088\n",
            "Validation loss :1.6464622764587402\n",
            "Validation Accuracy :0.8154000043869019\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6446156924438478\n",
            "Training Accuracy :0.818340003490448\n",
            "Validation loss :1.6540411949157714\n",
            "Validation Accuracy :0.8087999820709229\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6438216782379151\n",
            "Training Accuracy :0.8187800049781799\n",
            "Validation loss :1.6476994533538818\n",
            "Validation Accuracy :0.8138999938964844\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6429988915634155\n",
            "Training Accuracy :0.82014000415802\n",
            "Validation loss :1.6410422199249268\n",
            "Validation Accuracy :0.8220999836921692\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.643427862854004\n",
            "Training Accuracy :0.8190000057220459\n",
            "Validation loss :1.644489136314392\n",
            "Validation Accuracy :0.81659996509552\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6404119830322266\n",
            "Training Accuracy :0.8215199708938599\n",
            "Validation loss :1.6447318914413451\n",
            "Validation Accuracy :0.8169999718666077\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.640135859413147\n",
            "Training Accuracy :0.8216399550437927\n",
            "Validation loss :1.649295006942749\n",
            "Validation Accuracy :0.8137999773025513\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6397853204345703\n",
            "Training Accuracy :0.822160005569458\n",
            "Validation loss :1.6387476667404175\n",
            "Validation Accuracy :0.8229999542236328\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6384572580718995\n",
            "Training Accuracy :0.8237999677658081\n",
            "Validation loss :1.6383412923812866\n",
            "Validation Accuracy :0.824400007724762\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6373332067871094\n",
            "Training Accuracy :0.8250799775123596\n",
            "Validation loss :1.6515562831878663\n",
            "Validation Accuracy :0.8107999563217163\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6373436058807374\n",
            "Training Accuracy :0.8248800039291382\n",
            "Validation loss :1.6437429487228394\n",
            "Validation Accuracy :0.8175999522209167\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6379812766265869\n",
            "Training Accuracy :0.8243199586868286\n",
            "Validation loss :1.6439528923034668\n",
            "Validation Accuracy :0.8170999884605408\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6353814128875732\n",
            "Training Accuracy :0.8266199827194214\n",
            "Validation loss :1.6378240297317506\n",
            "Validation Accuracy :0.8240000009536743\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6357830605697632\n",
            "Training Accuracy :0.8259999752044678\n",
            "Validation loss :1.6398856355667115\n",
            "Validation Accuracy :0.8216999769210815\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6353138680267334\n",
            "Training Accuracy :0.8269400000572205\n",
            "Validation loss :1.6359355354309082\n",
            "Validation Accuracy :0.8264999985694885\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6334958418655396\n",
            "Training Accuracy :0.8287000060081482\n",
            "Validation loss :1.6346099674224854\n",
            "Validation Accuracy :0.8273999691009521\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6328084232330322\n",
            "Training Accuracy :0.829259991645813\n",
            "Validation loss :1.6344117403030396\n",
            "Validation Accuracy :0.8270999789237976\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6313867992401123\n",
            "Training Accuracy :0.8312599658966064\n",
            "Validation loss :1.6413805353164672\n",
            "Validation Accuracy :0.8210999965667725\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.632046173171997\n",
            "Training Accuracy :0.8299399614334106\n",
            "Validation loss :1.6358477350234986\n",
            "Validation Accuracy :0.8251000046730042\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6304370550918579\n",
            "Training Accuracy :0.8319999575614929\n",
            "Validation loss :1.6373827489852906\n",
            "Validation Accuracy :0.8226999640464783\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6300679669952391\n",
            "Training Accuracy :0.8319999575614929\n",
            "Validation loss :1.6430188497543334\n",
            "Validation Accuracy :0.817799985408783\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6307123365020753\n",
            "Training Accuracy :0.8314200043678284\n",
            "Validation loss :1.6358178091049194\n",
            "Validation Accuracy :0.8247999548912048\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6296412133789062\n",
            "Training Accuracy :0.8319799900054932\n",
            "Validation loss :1.639008823776245\n",
            "Validation Accuracy :0.8224999904632568\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6296336055755616\n",
            "Training Accuracy :0.8320399522781372\n",
            "Validation loss :1.633333653831482\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.630191667137146\n",
            "Training Accuracy :0.8315799832344055\n",
            "Validation loss :1.6336871894836427\n",
            "Validation Accuracy :0.8280999660491943\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6284229206085206\n",
            "Training Accuracy :0.8336399793624878\n",
            "Validation loss :1.6343342903137208\n",
            "Validation Accuracy :0.8270999789237976\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.628019263381958\n",
            "Training Accuracy :0.8342999815940857\n",
            "Validation loss :1.6356227165222168\n",
            "Validation Accuracy :0.8251000046730042\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6275131523895263\n",
            "Training Accuracy :0.8344999551773071\n",
            "Validation loss :1.6354209072113037\n",
            "Validation Accuracy :0.8264999985694885\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6276185793304443\n",
            "Training Accuracy :0.8343600034713745\n",
            "Validation loss :1.638140651702881\n",
            "Validation Accuracy :0.8244999647140503\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6279511931610107\n",
            "Training Accuracy :0.8339399695396423\n",
            "Validation loss :1.6327506698608398\n",
            "Validation Accuracy :0.8291999697685242\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6270668272399902\n",
            "Training Accuracy :0.8347799777984619\n",
            "Validation loss :1.632917741394043\n",
            "Validation Accuracy :0.8287999629974365\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6264550945663452\n",
            "Training Accuracy :0.8354199528694153\n",
            "Validation loss :1.630192360687256\n",
            "Validation Accuracy :0.8305000066757202\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6269184692764282\n",
            "Training Accuracy :0.8345199823379517\n",
            "Validation loss :1.6322593559265137\n",
            "Validation Accuracy :0.8298999667167664\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6266296878814697\n",
            "Training Accuracy :0.8350399732589722\n",
            "Validation loss :1.6323630716323851\n",
            "Validation Accuracy :0.8290999531745911\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.62609436668396\n",
            "Training Accuracy :0.8352199792861938\n",
            "Validation loss :1.6292201150894166\n",
            "Validation Accuracy :0.8319000005722046\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6257387917327881\n",
            "Training Accuracy :0.8365199565887451\n",
            "Validation loss :1.6334796007156371\n",
            "Validation Accuracy :0.8276000022888184\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6261031860733033\n",
            "Training Accuracy :0.8354600071907043\n",
            "Validation loss :1.6328687995910645\n",
            "Validation Accuracy :0.8277999758720398\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6256208737945557\n",
            "Training Accuracy :0.8362999558448792\n",
            "Validation loss :1.6310054807662964\n",
            "Validation Accuracy :0.8303999900817871\n",
            "Sparsity=0.03518437208883203\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302623720474243\n",
            "Training Accuracy :0.09715999662876129\n",
            "Validation loss :2.3026009685516358\n",
            "Validation Accuracy :0.07599999755620956\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302603599395752\n",
            "Training Accuracy :0.09975999593734741\n",
            "Validation loss :2.302634089279175\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302586828689575\n",
            "Training Accuracy :0.10009999573230743\n",
            "Validation loss :2.3026595336914064\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025718856048583\n",
            "Training Accuracy :0.09931999444961548\n",
            "Validation loss :2.3026670810699463\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.302562173461914\n",
            "Training Accuracy :0.10025999695062637\n",
            "Validation loss :2.302680238342285\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025387882995605\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302668578338623\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.302495852737427\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30262419090271\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.302384464416504\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3024461280822752\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.301785731277466\n",
            "Training Accuracy :0.1361600011587143\n",
            "Validation loss :2.300927522659302\n",
            "Validation Accuracy :0.1777999997138977\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.2693821495056152\n",
            "Training Accuracy :0.18437999486923218\n",
            "Validation loss :2.2296917945861816\n",
            "Validation Accuracy :0.18279999494552612\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.175838998413086\n",
            "Training Accuracy :0.2644200026988983\n",
            "Validation loss :2.1115424339294435\n",
            "Validation Accuracy :0.36879998445510864\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.0508361694335937\n",
            "Training Accuracy :0.41211998462677\n",
            "Validation loss :1.9567406490325927\n",
            "Validation Accuracy :0.5364999771118164\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :1.8572707874298096\n",
            "Training Accuracy :0.6346200108528137\n",
            "Validation loss :1.7553216707229615\n",
            "Validation Accuracy :0.7347999811172485\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :1.73047281791687\n",
            "Training Accuracy :0.7467199563980103\n",
            "Validation loss :1.7118657424926758\n",
            "Validation Accuracy :0.7598999738693237\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :1.703846642074585\n",
            "Training Accuracy :0.7658399939537048\n",
            "Validation loss :1.7014753631591797\n",
            "Validation Accuracy :0.7662000060081482\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :1.6899655530166626\n",
            "Training Accuracy :0.7768399715423584\n",
            "Validation loss :1.6845613382339477\n",
            "Validation Accuracy :0.7824999690055847\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :1.681082123451233\n",
            "Training Accuracy :0.784060001373291\n",
            "Validation loss :1.681265665626526\n",
            "Validation Accuracy :0.7838000059127808\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :1.6735397286605835\n",
            "Training Accuracy :0.7909799814224243\n",
            "Validation loss :1.6714596899032592\n",
            "Validation Accuracy :0.7926999926567078\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :1.6674168824005127\n",
            "Training Accuracy :0.7973799705505371\n",
            "Validation loss :1.6652694566726685\n",
            "Validation Accuracy :0.7985999584197998\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :1.6634808587646484\n",
            "Training Accuracy :0.8011399507522583\n",
            "Validation loss :1.66702863407135\n",
            "Validation Accuracy :0.7960999608039856\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.6593223154449463\n",
            "Training Accuracy :0.8045600056648254\n",
            "Validation loss :1.6590389844894409\n",
            "Validation Accuracy :0.8039999604225159\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.655971318283081\n",
            "Training Accuracy :0.8073999881744385\n",
            "Validation loss :1.6631276554107666\n",
            "Validation Accuracy :0.8009999990463257\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.6558075072479248\n",
            "Training Accuracy :0.8070999979972839\n",
            "Validation loss :1.6542929412841796\n",
            "Validation Accuracy :0.8075999617576599\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.6538018557739258\n",
            "Training Accuracy :0.8087999820709229\n",
            "Validation loss :1.656564977645874\n",
            "Validation Accuracy :0.8066999912261963\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6511648294830323\n",
            "Training Accuracy :0.811519980430603\n",
            "Validation loss :1.6508289953231812\n",
            "Validation Accuracy :0.8118999600410461\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6500420659637451\n",
            "Training Accuracy :0.8128799796104431\n",
            "Validation loss :1.6528094663619994\n",
            "Validation Accuracy :0.8098999857902527\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6489806427383422\n",
            "Training Accuracy :0.8139399886131287\n",
            "Validation loss :1.652331050491333\n",
            "Validation Accuracy :0.8093999624252319\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6474686458969117\n",
            "Training Accuracy :0.8151400089263916\n",
            "Validation loss :1.6516491540908813\n",
            "Validation Accuracy :0.8104999661445618\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6460407207870484\n",
            "Training Accuracy :0.8166399598121643\n",
            "Validation loss :1.6449424751281738\n",
            "Validation Accuracy :0.8166999816894531\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6445739023590087\n",
            "Training Accuracy :0.8180599808692932\n",
            "Validation loss :1.645397357559204\n",
            "Validation Accuracy :0.8169999718666077\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6444794446182252\n",
            "Training Accuracy :0.8178199529647827\n",
            "Validation loss :1.6465457452774048\n",
            "Validation Accuracy :0.8141999840736389\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6433279043960571\n",
            "Training Accuracy :0.8190999627113342\n",
            "Validation loss :1.6477695404052735\n",
            "Validation Accuracy :0.8158999681472778\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.642767324256897\n",
            "Training Accuracy :0.8195799589157104\n",
            "Validation loss :1.647150147819519\n",
            "Validation Accuracy :0.8143999576568604\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6422655219268798\n",
            "Training Accuracy :0.8202799558639526\n",
            "Validation loss :1.6462164707183837\n",
            "Validation Accuracy :0.8157999515533447\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.640975594406128\n",
            "Training Accuracy :0.8219799995422363\n",
            "Validation loss :1.6519974187850952\n",
            "Validation Accuracy :0.8089999556541443\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6412060729598998\n",
            "Training Accuracy :0.820580005645752\n",
            "Validation loss :1.648187068939209\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6391222788238526\n",
            "Training Accuracy :0.8227999806404114\n",
            "Validation loss :1.6431263347625733\n",
            "Validation Accuracy :0.8197000026702881\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.638097529525757\n",
            "Training Accuracy :0.82396000623703\n",
            "Validation loss :1.6442798845291138\n",
            "Validation Accuracy :0.8174999952316284\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6389100905990601\n",
            "Training Accuracy :0.8230400085449219\n",
            "Validation loss :1.6462366584777832\n",
            "Validation Accuracy :0.8152999877929688\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.638810119972229\n",
            "Training Accuracy :0.823419988155365\n",
            "Validation loss :1.6426019693374634\n",
            "Validation Accuracy :0.8184999823570251\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.637345784225464\n",
            "Training Accuracy :0.8247799873352051\n",
            "Validation loss :1.643438745880127\n",
            "Validation Accuracy :0.8179999589920044\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6377785374450684\n",
            "Training Accuracy :0.8241199851036072\n",
            "Validation loss :1.6411195932388305\n",
            "Validation Accuracy :0.8199999928474426\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6368784656906128\n",
            "Training Accuracy :0.8246399760246277\n",
            "Validation loss :1.643098804283142\n",
            "Validation Accuracy :0.8192999958992004\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6357558791351319\n",
            "Training Accuracy :0.8261199593544006\n",
            "Validation loss :1.6406051216125488\n",
            "Validation Accuracy :0.8215000033378601\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6363157623291016\n",
            "Training Accuracy :0.8256199955940247\n",
            "Validation loss :1.6447326330184937\n",
            "Validation Accuracy :0.8163999915122986\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6355360187911987\n",
            "Training Accuracy :0.826200008392334\n",
            "Validation loss :1.6396308019638062\n",
            "Validation Accuracy :0.8212999701499939\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6351175214767455\n",
            "Training Accuracy :0.8267599940299988\n",
            "Validation loss :1.6406859142303467\n",
            "Validation Accuracy :0.8197000026702881\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6346033629989625\n",
            "Training Accuracy :0.8277599811553955\n",
            "Validation loss :1.6421894901275635\n",
            "Validation Accuracy :0.8198999762535095\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6353467206192016\n",
            "Training Accuracy :0.8263599872589111\n",
            "Validation loss :1.6416183748245239\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.633643737487793\n",
            "Training Accuracy :0.8286199569702148\n",
            "Validation loss :1.641576874923706\n",
            "Validation Accuracy :0.8203999996185303\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6341873321533202\n",
            "Training Accuracy :0.82778000831604\n",
            "Validation loss :1.6413542337417601\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6341843834686278\n",
            "Training Accuracy :0.8276799917221069\n",
            "Validation loss :1.63993470993042\n",
            "Validation Accuracy :0.8219999670982361\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6333155868530274\n",
            "Training Accuracy :0.8287599682807922\n",
            "Validation loss :1.641230955696106\n",
            "Validation Accuracy :0.8203999996185303\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.632667935409546\n",
            "Training Accuracy :0.829319953918457\n",
            "Validation loss :1.6397591260910034\n",
            "Validation Accuracy :0.8202999830245972\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6329174300384521\n",
            "Training Accuracy :0.8293600082397461\n",
            "Validation loss :1.643219571685791\n",
            "Validation Accuracy :0.8184999823570251\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6315025254058837\n",
            "Training Accuracy :0.8303799629211426\n",
            "Validation loss :1.639736778640747\n",
            "Validation Accuracy :0.821399986743927\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6325498181533813\n",
            "Training Accuracy :0.8295599818229675\n",
            "Validation loss :1.6406496534347534\n",
            "Validation Accuracy :0.8211999535560608\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6324548773956298\n",
            "Training Accuracy :0.8294999599456787\n",
            "Validation loss :1.6409789297103883\n",
            "Validation Accuracy :0.8203999996185303\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6315672249603272\n",
            "Training Accuracy :0.8300399780273438\n",
            "Validation loss :1.6409600109100342\n",
            "Validation Accuracy :0.8190999627113342\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.631011492843628\n",
            "Training Accuracy :0.8310999870300293\n",
            "Validation loss :1.6391125343322754\n",
            "Validation Accuracy :0.8224999904632568\n",
            "Sparsity=0.028147497671065624\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.30262760597229\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.302665255737305\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302610325088501\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.3026842460632326\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302603565673828\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.302697229385376\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.302592486038208\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.302711711883545\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025875765991213\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.3027394733428954\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.302588591995239\n",
            "Training Accuracy :0.09854000061750412\n",
            "Validation loss :2.3027390144348145\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.30258378326416\n",
            "Training Accuracy :0.10047999769449234\n",
            "Validation loss :2.3027579387664794\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.3025783192443847\n",
            "Training Accuracy :0.0999399945139885\n",
            "Validation loss :2.3027563083648683\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.302578325958252\n",
            "Training Accuracy :0.09971999377012253\n",
            "Validation loss :2.3027553047180174\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3025782063293456\n",
            "Training Accuracy :0.10007999837398529\n",
            "Validation loss :2.302770514678955\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.3025768799591066\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302759720611572\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.3025736920928956\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027661193847657\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.3025693544006347\n",
            "Training Accuracy :0.10117999464273453\n",
            "Validation loss :2.3027585594177244\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.302566138305664\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027683944702146\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.3025569886779786\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302763195037842\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.302547780761719\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027475959777832\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.302534340133667\n",
            "Training Accuracy :0.10047999769449234\n",
            "Validation loss :2.3027343502044677\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.3024955320739746\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302699164199829\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.302404403839111\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3025336196899415\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.301962998275757\n",
            "Training Accuracy :0.10183999687433243\n",
            "Validation loss :2.3013365768432616\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :2.272567024307251\n",
            "Training Accuracy :0.18184000253677368\n",
            "Validation loss :2.2052738677978514\n",
            "Validation Accuracy :0.2093999981880188\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :2.113957297668457\n",
            "Training Accuracy :0.361299991607666\n",
            "Validation loss :2.036093246078491\n",
            "Validation Accuracy :0.4690999984741211\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.9673650753021241\n",
            "Training Accuracy :0.526639997959137\n",
            "Validation loss :1.914650729751587\n",
            "Validation Accuracy :0.5509999990463257\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.8810098693466186\n",
            "Training Accuracy :0.5999799966812134\n",
            "Validation loss :1.798547723197937\n",
            "Validation Accuracy :0.7103999853134155\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.750194192199707\n",
            "Training Accuracy :0.7367799878120422\n",
            "Validation loss :1.7232248554229737\n",
            "Validation Accuracy :0.7559999823570251\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.7111756639862061\n",
            "Training Accuracy :0.7621399760246277\n",
            "Validation loss :1.7024799030303954\n",
            "Validation Accuracy :0.7676999568939209\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6925452545547486\n",
            "Training Accuracy :0.7760799527168274\n",
            "Validation loss :1.690896482849121\n",
            "Validation Accuracy :0.7777999639511108\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6807924085235595\n",
            "Training Accuracy :0.7864399552345276\n",
            "Validation loss :1.6794404209136964\n",
            "Validation Accuracy :0.7876999974250793\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6726990628814697\n",
            "Training Accuracy :0.7936199903488159\n",
            "Validation loss :1.672727645301819\n",
            "Validation Accuracy :0.7924999594688416\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6686826706314086\n",
            "Training Accuracy :0.7968599796295166\n",
            "Validation loss :1.671896858215332\n",
            "Validation Accuracy :0.793999969959259\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.664168328819275\n",
            "Training Accuracy :0.8002600073814392\n",
            "Validation loss :1.6656465225219728\n",
            "Validation Accuracy :0.7979999780654907\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6581851305389403\n",
            "Training Accuracy :0.8065599799156189\n",
            "Validation loss :1.6612269969940185\n",
            "Validation Accuracy :0.8021999597549438\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.6575420487213135\n",
            "Training Accuracy :0.8060199618339539\n",
            "Validation loss :1.6550229095458984\n",
            "Validation Accuracy :0.8084999918937683\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6542806786346436\n",
            "Training Accuracy :0.8087999820709229\n",
            "Validation loss :1.6556661418914795\n",
            "Validation Accuracy :0.8069999814033508\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6518710276412965\n",
            "Training Accuracy :0.8111199736595154\n",
            "Validation loss :1.6524275436401368\n",
            "Validation Accuracy :0.8100999593734741\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6486321558380126\n",
            "Training Accuracy :0.8142199516296387\n",
            "Validation loss :1.650920611190796\n",
            "Validation Accuracy :0.8118000030517578\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6473493465423583\n",
            "Training Accuracy :0.8157199621200562\n",
            "Validation loss :1.6497614017486573\n",
            "Validation Accuracy :0.8125\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6458224135589599\n",
            "Training Accuracy :0.8169599771499634\n",
            "Validation loss :1.64865656414032\n",
            "Validation Accuracy :0.8141999840736389\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6441780059051514\n",
            "Training Accuracy :0.8183199763298035\n",
            "Validation loss :1.6567339521408082\n",
            "Validation Accuracy :0.8064000010490417\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6434266761016845\n",
            "Training Accuracy :0.8188599944114685\n",
            "Validation loss :1.6474890266418456\n",
            "Validation Accuracy :0.8144999742507935\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6422523226928711\n",
            "Training Accuracy :0.8204399943351746\n",
            "Validation loss :1.6480058361053467\n",
            "Validation Accuracy :0.8138999938964844\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6403783492279054\n",
            "Training Accuracy :0.8221799731254578\n",
            "Validation loss :1.6464405038833618\n",
            "Validation Accuracy :0.8143999576568604\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6401363705825807\n",
            "Training Accuracy :0.8224599957466125\n",
            "Validation loss :1.6499177198410033\n",
            "Validation Accuracy :0.8118999600410461\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6402076842498778\n",
            "Training Accuracy :0.8219999670982361\n",
            "Validation loss :1.6428825965881348\n",
            "Validation Accuracy :0.8190000057220459\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6394781339263915\n",
            "Training Accuracy :0.822659969329834\n",
            "Validation loss :1.6437067546844482\n",
            "Validation Accuracy :0.8179999589920044\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6388083801651\n",
            "Training Accuracy :0.8234599828720093\n",
            "Validation loss :1.642980355834961\n",
            "Validation Accuracy :0.8184999823570251\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6374770708847046\n",
            "Training Accuracy :0.8246200084686279\n",
            "Validation loss :1.6413537994384766\n",
            "Validation Accuracy :0.819599986076355\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6358364417266846\n",
            "Training Accuracy :0.8262199759483337\n",
            "Validation loss :1.6408836301803589\n",
            "Validation Accuracy :0.8212999701499939\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6360938757705688\n",
            "Training Accuracy :0.8261799812316895\n",
            "Validation loss :1.6451323499679567\n",
            "Validation Accuracy :0.81659996509552\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6366263653945923\n",
            "Training Accuracy :0.825439989566803\n",
            "Validation loss :1.6423282064437865\n",
            "Validation Accuracy :0.8194999694824219\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6358327068710328\n",
            "Training Accuracy :0.8266399502754211\n",
            "Validation loss :1.6393742279052734\n",
            "Validation Accuracy :0.8222999572753906\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.635914469642639\n",
            "Training Accuracy :0.8263399600982666\n",
            "Validation loss :1.6421312381744384\n",
            "Validation Accuracy :0.8197000026702881\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.6352202127838136\n",
            "Training Accuracy :0.8268599510192871\n",
            "Validation loss :1.63962017288208\n",
            "Validation Accuracy :0.8216999769210815\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6337139368057252\n",
            "Training Accuracy :0.8285599946975708\n",
            "Validation loss :1.643817658805847\n",
            "Validation Accuracy :0.8180999755859375\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6345814471817017\n",
            "Training Accuracy :0.8270799517631531\n",
            "Validation loss :1.63945559425354\n",
            "Validation Accuracy :0.8215000033378601\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6335482931518555\n",
            "Training Accuracy :0.8281599879264832\n",
            "Validation loss :1.63973503780365\n",
            "Validation Accuracy :0.8205999732017517\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6321342084503174\n",
            "Training Accuracy :0.8301599621772766\n",
            "Validation loss :1.6369897369384765\n",
            "Validation Accuracy :0.8237999677658081\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6324832809066772\n",
            "Training Accuracy :0.829319953918457\n",
            "Validation loss :1.6402224519729613\n",
            "Validation Accuracy :0.8215000033378601\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.631832831993103\n",
            "Training Accuracy :0.8303599953651428\n",
            "Validation loss :1.6377581756591797\n",
            "Validation Accuracy :0.823199987411499\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6319039545440674\n",
            "Training Accuracy :0.8297199606895447\n",
            "Validation loss :1.6425057424545288\n",
            "Validation Accuracy :0.8190999627113342\n",
            "Sparsity=0.022517998136852502\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3026201577758787\n",
            "Training Accuracy :0.09919999539852142\n",
            "Validation loss :2.302648707962036\n",
            "Validation Accuracy :0.10249999910593033\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302604423675537\n",
            "Training Accuracy :0.09991999715566635\n",
            "Validation loss :2.3026843257904055\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3025952291107177\n",
            "Training Accuracy :0.09922000020742416\n",
            "Validation loss :2.302688917541504\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025881785583495\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302709749984741\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025824254608156\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027333198547364\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025807894897463\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302735111236572\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.302579358291626\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027450881958007\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.3025762763214113\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30275396232605\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.302573963470459\n",
            "Training Accuracy :0.09995999932289124\n",
            "Validation loss :2.302754891204834\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3025739535522463\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027573207855223\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.302568636016846\n",
            "Training Accuracy :0.10055999457836151\n",
            "Validation loss :2.302752974700928\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.302558174362183\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027507621765135\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.3025505563354494\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302750368118286\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.30253702003479\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027297897338865\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.302504600982666\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302684148788452\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.3023981650543215\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3024882625579832\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.3013883831787108\n",
            "Training Accuracy :0.11803999543190002\n",
            "Validation loss :2.298551459503174\n",
            "Validation Accuracy :0.16049998998641968\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.25078020904541\n",
            "Training Accuracy :0.1921200007200241\n",
            "Validation loss :2.22022317237854\n",
            "Validation Accuracy :0.19769999384880066\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.2070843043518065\n",
            "Training Accuracy :0.2246599942445755\n",
            "Validation loss :2.1881293952941894\n",
            "Validation Accuracy :0.2732999920845032\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.1233158325195314\n",
            "Training Accuracy :0.33969998359680176\n",
            "Validation loss :2.0225663982391358\n",
            "Validation Accuracy :0.43309998512268066\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :1.8911371432495117\n",
            "Training Accuracy :0.6246799826622009\n",
            "Validation loss :1.7766277309417724\n",
            "Validation Accuracy :0.722000002861023\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :1.7452013348007203\n",
            "Training Accuracy :0.7376599907875061\n",
            "Validation loss :1.7267246633529663\n",
            "Validation Accuracy :0.7482999563217163\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :1.7208444959259033\n",
            "Training Accuracy :0.7492199540138245\n",
            "Validation loss :1.7106118370056151\n",
            "Validation Accuracy :0.7583999633789062\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :1.703082980003357\n",
            "Training Accuracy :0.7657999992370605\n",
            "Validation loss :1.6937776912689209\n",
            "Validation Accuracy :0.772599995136261\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :1.6908248516845703\n",
            "Training Accuracy :0.7765399813652039\n",
            "Validation loss :1.6842463569641113\n",
            "Validation Accuracy :0.7828999757766724\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.6811056903457642\n",
            "Training Accuracy :0.7860599756240845\n",
            "Validation loss :1.6769443874359131\n",
            "Validation Accuracy :0.7914999723434448\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.6766300131607055\n",
            "Training Accuracy :0.7897399663925171\n",
            "Validation loss :1.6803800306320191\n",
            "Validation Accuracy :0.7859999537467957\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.6702107579803467\n",
            "Training Accuracy :0.7954599857330322\n",
            "Validation loss :1.6735808309555054\n",
            "Validation Accuracy :0.7904999852180481\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.6672983944320678\n",
            "Training Accuracy :0.7975800037384033\n",
            "Validation loss :1.6684465824127197\n",
            "Validation Accuracy :0.795199990272522\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.6641491537475586\n",
            "Training Accuracy :0.8006599545478821\n",
            "Validation loss :1.6616332889556884\n",
            "Validation Accuracy :0.8026999831199646\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.6618516175079345\n",
            "Training Accuracy :0.8020199537277222\n",
            "Validation loss :1.6656497037887574\n",
            "Validation Accuracy :0.7972999811172485\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.6591758444595337\n",
            "Training Accuracy :0.8049799799919128\n",
            "Validation loss :1.6608493144989014\n",
            "Validation Accuracy :0.8039999604225159\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.656841340713501\n",
            "Training Accuracy :0.8066799640655518\n",
            "Validation loss :1.6589026588439941\n",
            "Validation Accuracy :0.8050000071525574\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6566038677215575\n",
            "Training Accuracy :0.8072599768638611\n",
            "Validation loss :1.6574431079864502\n",
            "Validation Accuracy :0.8059999942779541\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6564630331420898\n",
            "Training Accuracy :0.8070600032806396\n",
            "Validation loss :1.6634061555862427\n",
            "Validation Accuracy :0.8008999824523926\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.654149200744629\n",
            "Training Accuracy :0.8084999918937683\n",
            "Validation loss :1.6549688549041748\n",
            "Validation Accuracy :0.8075999617576599\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6524546615600586\n",
            "Training Accuracy :0.8108199834823608\n",
            "Validation loss :1.6529041284561157\n",
            "Validation Accuracy :0.809499979019165\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6506162395858766\n",
            "Training Accuracy :0.8130199909210205\n",
            "Validation loss :1.6531269666671753\n",
            "Validation Accuracy :0.8090999722480774\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.6508677404022216\n",
            "Training Accuracy :0.8123799562454224\n",
            "Validation loss :1.651378210067749\n",
            "Validation Accuracy :0.8122999668121338\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6494584156036376\n",
            "Training Accuracy :0.8132199645042419\n",
            "Validation loss :1.650775615119934\n",
            "Validation Accuracy :0.8126999735832214\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6484960901260377\n",
            "Training Accuracy :0.8145399689674377\n",
            "Validation loss :1.6506054605484008\n",
            "Validation Accuracy :0.8122999668121338\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6466659136962891\n",
            "Training Accuracy :0.815779983997345\n",
            "Validation loss :1.6467316720962524\n",
            "Validation Accuracy :0.816100001335144\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6463712283706664\n",
            "Training Accuracy :0.8163599967956543\n",
            "Validation loss :1.6466348106384276\n",
            "Validation Accuracy :0.8170999884605408\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6454805666732788\n",
            "Training Accuracy :0.8175199627876282\n",
            "Validation loss :1.6607925443649292\n",
            "Validation Accuracy :0.8021000027656555\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6450984231567383\n",
            "Training Accuracy :0.8181999921798706\n",
            "Validation loss :1.6475037992477417\n",
            "Validation Accuracy :0.8136999607086182\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6442767902374267\n",
            "Training Accuracy :0.8184199929237366\n",
            "Validation loss :1.646126506614685\n",
            "Validation Accuracy :0.8166999816894531\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.642240239944458\n",
            "Training Accuracy :0.8212800025939941\n",
            "Validation loss :1.6445184087753295\n",
            "Validation Accuracy :0.8175999522209167\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6416964932250977\n",
            "Training Accuracy :0.8214399814605713\n",
            "Validation loss :1.64813053855896\n",
            "Validation Accuracy :0.8131999969482422\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.641981957397461\n",
            "Training Accuracy :0.820859968662262\n",
            "Validation loss :1.6441233949661256\n",
            "Validation Accuracy :0.8190000057220459\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.640823066444397\n",
            "Training Accuracy :0.8225799798965454\n",
            "Validation loss :1.6451794195175171\n",
            "Validation Accuracy :0.8175999522209167\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.6399959466552734\n",
            "Training Accuracy :0.8224799633026123\n",
            "Validation loss :1.6500154195785524\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.640170295944214\n",
            "Training Accuracy :0.8225599527359009\n",
            "Validation loss :1.6491206310272217\n",
            "Validation Accuracy :0.8123999834060669\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.639200839805603\n",
            "Training Accuracy :0.8236599564552307\n",
            "Validation loss :1.6456577312469483\n",
            "Validation Accuracy :0.8167999982833862\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6384176493072509\n",
            "Training Accuracy :0.8237599730491638\n",
            "Validation loss :1.6471665075302124\n",
            "Validation Accuracy :0.8147000074386597\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6382909336090088\n",
            "Training Accuracy :0.8248399496078491\n",
            "Validation loss :1.6447827995300293\n",
            "Validation Accuracy :0.8172000050544739\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.638405881576538\n",
            "Training Accuracy :0.824679970741272\n",
            "Validation loss :1.6429413360595704\n",
            "Validation Accuracy :0.820099949836731\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6375802768707275\n",
            "Training Accuracy :0.8260399699211121\n",
            "Validation loss :1.6415302770614624\n",
            "Validation Accuracy :0.8203999996185303\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6371117776489257\n",
            "Training Accuracy :0.8251799941062927\n",
            "Validation loss :1.6507669576644897\n",
            "Validation Accuracy :0.8112999796867371\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6392017361068725\n",
            "Training Accuracy :0.8234399557113647\n",
            "Validation loss :1.643539188194275\n",
            "Validation Accuracy :0.8176999688148499\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6379843333435058\n",
            "Training Accuracy :0.8246399760246277\n",
            "Validation loss :1.643584853363037\n",
            "Validation Accuracy :0.8191999793052673\n",
            "Sparsity=0.018014398509482003\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.3026158186340333\n",
            "Training Accuracy :0.09888000041246414\n",
            "Validation loss :2.302613120651245\n",
            "Validation Accuracy :0.10559999942779541\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.30260564704895\n",
            "Training Accuracy :0.09827999770641327\n",
            "Validation loss :2.3026597175598145\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302596662979126\n",
            "Training Accuracy :0.10071999579668045\n",
            "Validation loss :2.3026803901672364\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.302587836456299\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302705289840698\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025892639923096\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027117443084717\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025853312683107\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027411434173586\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.3025803297424314\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027574531555177\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.3025844435882568\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027566398620607\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.3025825967407227\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027566940307618\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3025770654296873\n",
            "Training Accuracy :0.10075999796390533\n",
            "Validation loss :2.3027673164367677\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.302576745147705\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027654453277586\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.3025799711608887\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30277297706604\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.3025758698272707\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302765784454346\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.302575046310425\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302773114013672\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.302572504119873\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027726554870607\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.302571144180298\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302774929046631\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.3025693671417238\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302766082763672\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.3025686985015867\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027732772827147\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.302564265899658\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027588302612303\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.3025593363189696\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302750369262695\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :2.30255251083374\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027473754882815\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :2.302545473861694\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027512432098387\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :2.3025311853790282\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302734086227417\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :2.302512070159912\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026984592437745\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :2.3024776957702637\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302664446640015\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :2.302406143798828\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3025733039855956\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :2.302230417251587\n",
            "Training Accuracy :0.10117999464273453\n",
            "Validation loss :2.302253150558472\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :2.3014130754089357\n",
            "Training Accuracy :0.10108000040054321\n",
            "Validation loss :2.3002340072631835\n",
            "Validation Accuracy :0.0949999988079071\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :2.265811653289795\n",
            "Training Accuracy :0.22337999939918518\n",
            "Validation loss :2.158134228134155\n",
            "Validation Accuracy :0.3472999930381775\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :2.0320154445648195\n",
            "Training Accuracy :0.44693997502326965\n",
            "Validation loss :1.9242448694229126\n",
            "Validation Accuracy :0.5777999758720398\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.8594328079986573\n",
            "Training Accuracy :0.6314799785614014\n",
            "Validation loss :1.7956572624206544\n",
            "Validation Accuracy :0.7084999680519104\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.7640312603759765\n",
            "Training Accuracy :0.7296599745750427\n",
            "Validation loss :1.7347487903594971\n",
            "Validation Accuracy :0.750499963760376\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.7165830086517333\n",
            "Training Accuracy :0.7610399723052979\n",
            "Validation loss :1.70139504737854\n",
            "Validation Accuracy :0.7717999815940857\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.6973576923370362\n",
            "Training Accuracy :0.7738199830055237\n",
            "Validation loss :1.6979436265945436\n",
            "Validation Accuracy :0.7701999545097351\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.6878567199325563\n",
            "Training Accuracy :0.7803599834442139\n",
            "Validation loss :1.6816314325332642\n",
            "Validation Accuracy :0.7856999635696411\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.6814752199554444\n",
            "Training Accuracy :0.7854200005531311\n",
            "Validation loss :1.6760944219589233\n",
            "Validation Accuracy :0.7882999777793884\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.6747720901489258\n",
            "Training Accuracy :0.7906599640846252\n",
            "Validation loss :1.6822444658279418\n",
            "Validation Accuracy :0.7827999591827393\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.6741291608428954\n",
            "Training Accuracy :0.7914199829101562\n",
            "Validation loss :1.6761509092330933\n",
            "Validation Accuracy :0.7902999520301819\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.670675513534546\n",
            "Training Accuracy :0.7940399646759033\n",
            "Validation loss :1.6758815448760986\n",
            "Validation Accuracy :0.7890999913215637\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.6682238922119141\n",
            "Training Accuracy :0.7967599630355835\n",
            "Validation loss :1.6731240030288697\n",
            "Validation Accuracy :0.791700005531311\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.6673741913223266\n",
            "Training Accuracy :0.7971199750900269\n",
            "Validation loss :1.6825643241882324\n",
            "Validation Accuracy :0.7820999622344971\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.6647961238861084\n",
            "Training Accuracy :0.7989999651908875\n",
            "Validation loss :1.6657744874954223\n",
            "Validation Accuracy :0.7989999651908875\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.6653713353729247\n",
            "Training Accuracy :0.7983199954032898\n",
            "Validation loss :1.6633307996749878\n",
            "Validation Accuracy :0.8000999689102173\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.6617873781585693\n",
            "Training Accuracy :0.8014000058174133\n",
            "Validation loss :1.662145281600952\n",
            "Validation Accuracy :0.8007999658584595\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.6598696591567994\n",
            "Training Accuracy :0.8034799695014954\n",
            "Validation loss :1.6623750581741332\n",
            "Validation Accuracy :0.8000999689102173\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.6592328530502318\n",
            "Training Accuracy :0.8042999505996704\n",
            "Validation loss :1.6686002504348756\n",
            "Validation Accuracy :0.7942000031471252\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.6600599239349365\n",
            "Training Accuracy :0.8030799627304077\n",
            "Validation loss :1.6611103429794312\n",
            "Validation Accuracy :0.8014999628067017\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.6585512899780273\n",
            "Training Accuracy :0.8046199679374695\n",
            "Validation loss :1.6584981756210326\n",
            "Validation Accuracy :0.8046000003814697\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.6574002224731446\n",
            "Training Accuracy :0.8050599694252014\n",
            "Validation loss :1.658669771194458\n",
            "Validation Accuracy :0.804099977016449\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.6566151513671874\n",
            "Training Accuracy :0.8063399791717529\n",
            "Validation loss :1.6761576766967774\n",
            "Validation Accuracy :0.786300003528595\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.655740969543457\n",
            "Training Accuracy :0.8075599670410156\n",
            "Validation loss :1.656512837600708\n",
            "Validation Accuracy :0.8050000071525574\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.6537660297012329\n",
            "Training Accuracy :0.8091199994087219\n",
            "Validation loss :1.6579620286941528\n",
            "Validation Accuracy :0.8046000003814697\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.65258207572937\n",
            "Training Accuracy :0.8102999925613403\n",
            "Validation loss :1.6610085165023805\n",
            "Validation Accuracy :0.8019999861717224\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.6547372632217408\n",
            "Training Accuracy :0.8077399730682373\n",
            "Validation loss :1.6549754833221435\n",
            "Validation Accuracy :0.805899977684021\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.6530941814804077\n",
            "Training Accuracy :0.8094799518585205\n",
            "Validation loss :1.6548126041412354\n",
            "Validation Accuracy :0.8068999648094177\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.6503817177581788\n",
            "Training Accuracy :0.81277996301651\n",
            "Validation loss :1.653375029373169\n",
            "Validation Accuracy :0.8083999752998352\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.6507809590911866\n",
            "Training Accuracy :0.8118000030517578\n",
            "Validation loss :1.65590821723938\n",
            "Validation Accuracy :0.8050000071525574\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.6512011724090576\n",
            "Training Accuracy :0.8108999729156494\n",
            "Validation loss :1.656392854309082\n",
            "Validation Accuracy :0.8044999837875366\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.6492210332489015\n",
            "Training Accuracy :0.8126999735832214\n",
            "Validation loss :1.6507187259674072\n",
            "Validation Accuracy :0.8111000061035156\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.6475980306625366\n",
            "Training Accuracy :0.8149999976158142\n",
            "Validation loss :1.6532554924011231\n",
            "Validation Accuracy :0.8073999881744385\n",
            "Sparsity=0.014411518807585602\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302612406463623\n",
            "Training Accuracy :0.09945999830961227\n",
            "Validation loss :2.3026587718963625\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.302601120223999\n",
            "Training Accuracy :0.09925999492406845\n",
            "Validation loss :2.3026847972869873\n",
            "Validation Accuracy :0.09939999878406525\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.302593376617432\n",
            "Training Accuracy :0.09987999498844147\n",
            "Validation loss :2.302703156661987\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.3025877196502686\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302719257736206\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025812757110597\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027297397613524\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.302579768066406\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302746415710449\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.3025808396911622\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302753360748291\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.3025797209167482\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302757635498047\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.3025789447021485\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027642642974855\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.3025758242797854\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027587047576903\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.3025734394836426\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027715339660646\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.3025758057403563\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027717964172365\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.3025711070251464\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302770418548584\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.302569869232178\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027657318115233\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.3025666871643065\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027616958618164\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.302560325317383\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302768482589722\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.302559532775879\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027700771331787\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.302549986419678\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027551738739014\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.302537855377197\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30273469581604\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.3025185111999513\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027153354644776\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :2.3024817909240722\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026487255096435\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :2.3023898542785646\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302496894454956\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :2.3020444483184814\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30172819519043\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :2.2949032652282715\n",
            "Training Accuracy :0.19293999671936035\n",
            "Validation loss :2.260122152709961\n",
            "Validation Accuracy :0.21969999372959137\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :2.146400659446716\n",
            "Training Accuracy :0.33003997802734375\n",
            "Validation loss :2.0103753412246705\n",
            "Validation Accuracy :0.5047000050544739\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :1.956292488746643\n",
            "Training Accuracy :0.5281000137329102\n",
            "Validation loss :1.9238673706054688\n",
            "Validation Accuracy :0.5475999712944031\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :1.9184101221084595\n",
            "Training Accuracy :0.548039972782135\n",
            "Validation loss :1.9104672479629516\n",
            "Validation Accuracy :0.5539000034332275\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :1.9081203155517579\n",
            "Training Accuracy :0.5559599995613098\n",
            "Validation loss :1.90171557636261\n",
            "Validation Accuracy :0.5601999759674072\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :1.9005936810684203\n",
            "Training Accuracy :0.5618799924850464\n",
            "Validation loss :1.8948335691452027\n",
            "Validation Accuracy :0.564300000667572\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :1.8870906247329713\n",
            "Training Accuracy :0.578220009803772\n",
            "Validation loss :1.863266005897522\n",
            "Validation Accuracy :0.613599956035614\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :1.853475360031128\n",
            "Training Accuracy :0.620639979839325\n",
            "Validation loss :1.8433160402297974\n",
            "Validation Accuracy :0.6266999840736389\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :1.8393369130706787\n",
            "Training Accuracy :0.6291199922561646\n",
            "Validation loss :1.8401301759719848\n",
            "Validation Accuracy :0.6256999969482422\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :1.8342075897216796\n",
            "Training Accuracy :0.6305599808692932\n",
            "Validation loss :1.826315728187561\n",
            "Validation Accuracy :0.6383000016212463\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :1.8293997985839843\n",
            "Training Accuracy :0.6336599588394165\n",
            "Validation loss :1.8301097534179687\n",
            "Validation Accuracy :0.6316999793052673\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :1.8279760885238647\n",
            "Training Accuracy :0.6337199807167053\n",
            "Validation loss :1.8226965492248535\n",
            "Validation Accuracy :0.6394999623298645\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :1.8233943701553346\n",
            "Training Accuracy :0.6377800107002258\n",
            "Validation loss :1.8195128936767577\n",
            "Validation Accuracy :0.6398000121116638\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :1.793932698059082\n",
            "Training Accuracy :0.670960009098053\n",
            "Validation loss :1.7776367055892945\n",
            "Validation Accuracy :0.6886999607086182\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :1.7665998546981811\n",
            "Training Accuracy :0.6977399587631226\n",
            "Validation loss :1.7582033922195435\n",
            "Validation Accuracy :0.7066999673843384\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :1.760982314491272\n",
            "Training Accuracy :0.7025600075721741\n",
            "Validation loss :1.7639261001586914\n",
            "Validation Accuracy :0.6965999603271484\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :1.7571180757904052\n",
            "Training Accuracy :0.705299973487854\n",
            "Validation loss :1.75472287940979\n",
            "Validation Accuracy :0.7067999839782715\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :1.7547045044708252\n",
            "Training Accuracy :0.706820011138916\n",
            "Validation loss :1.749210426902771\n",
            "Validation Accuracy :0.7134000062942505\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.7508248034667968\n",
            "Training Accuracy :0.710599958896637\n",
            "Validation loss :1.7512644367218018\n",
            "Validation Accuracy :0.708299994468689\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.7509160373687744\n",
            "Training Accuracy :0.7104399800300598\n",
            "Validation loss :1.7502089233398437\n",
            "Validation Accuracy :0.7109999656677246\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.7480374963378906\n",
            "Training Accuracy :0.7130999565124512\n",
            "Validation loss :1.7498953882217407\n",
            "Validation Accuracy :0.7091000080108643\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.7485293006134033\n",
            "Training Accuracy :0.7125799655914307\n",
            "Validation loss :1.7451963890075683\n",
            "Validation Accuracy :0.7152000069618225\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.744969281272888\n",
            "Training Accuracy :0.715999960899353\n",
            "Validation loss :1.7427259593963622\n",
            "Validation Accuracy :0.7181000113487244\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.7438960854721068\n",
            "Training Accuracy :0.7166599631309509\n",
            "Validation loss :1.7443256788253785\n",
            "Validation Accuracy :0.7146999835968018\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.742777921218872\n",
            "Training Accuracy :0.7175599932670593\n",
            "Validation loss :1.7399393411636352\n",
            "Validation Accuracy :0.7202999591827393\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.7437391654205323\n",
            "Training Accuracy :0.7169399857521057\n",
            "Validation loss :1.7413405075073243\n",
            "Validation Accuracy :0.7202999591827393\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.7418624097061157\n",
            "Training Accuracy :0.7183600068092346\n",
            "Validation loss :1.741045685005188\n",
            "Validation Accuracy :0.7181000113487244\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.7404007273101807\n",
            "Training Accuracy :0.7198999524116516\n",
            "Validation loss :1.7388228477478027\n",
            "Validation Accuracy :0.7209999561309814\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.7405477030181884\n",
            "Training Accuracy :0.7196999788284302\n",
            "Validation loss :1.7399216697692872\n",
            "Validation Accuracy :0.7191999554634094\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.7395816779327393\n",
            "Training Accuracy :0.7207199931144714\n",
            "Validation loss :1.736705738067627\n",
            "Validation Accuracy :0.7231999635696411\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.7391050638580323\n",
            "Training Accuracy :0.7210800051689148\n",
            "Validation loss :1.73975422000885\n",
            "Validation Accuracy :0.7215999960899353\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.738194408569336\n",
            "Training Accuracy :0.7220199704170227\n",
            "Validation loss :1.7370897150039672\n",
            "Validation Accuracy :0.722599983215332\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.737172109146118\n",
            "Training Accuracy :0.7228800058364868\n",
            "Validation loss :1.7371931951522828\n",
            "Validation Accuracy :0.7224999666213989\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.7371593429946899\n",
            "Training Accuracy :0.7229200005531311\n",
            "Validation loss :1.738271809387207\n",
            "Validation Accuracy :0.7214999794960022\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.7379008269882201\n",
            "Training Accuracy :0.7221599817276001\n",
            "Validation loss :1.7356889499664307\n",
            "Validation Accuracy :0.7251999974250793\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.7354329077911377\n",
            "Training Accuracy :0.7248599529266357\n",
            "Validation loss :1.7411014265060425\n",
            "Validation Accuracy :0.7181999683380127\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.7362536054229736\n",
            "Training Accuracy :0.7234199643135071\n",
            "Validation loss :1.7319462450027465\n",
            "Validation Accuracy :0.7285000085830688\n",
            "Sparsity=0.011529215046068483\n",
            "-----------EPOCH 0 ------------------ \n",
            "Training loss :2.302621834182739\n",
            "Training Accuracy :0.09893999993801117\n",
            "Validation loss :2.3026136333465574\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 1 ------------------ \n",
            "Training loss :2.3026080827331543\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.302646286392212\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 2 ------------------ \n",
            "Training loss :2.3026003565979005\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.3026730693817137\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 3 ------------------ \n",
            "Training loss :2.30259561668396\n",
            "Training Accuracy :0.10063999891281128\n",
            "Validation loss :2.3026860374450684\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 4 ------------------ \n",
            "Training loss :2.3025883173370363\n",
            "Training Accuracy :0.09961999952793121\n",
            "Validation loss :2.302708136367798\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 5 ------------------ \n",
            "Training loss :2.3025884700012207\n",
            "Training Accuracy :0.0997999981045723\n",
            "Validation loss :2.302716040420532\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 6 ------------------ \n",
            "Training loss :2.3025844387817385\n",
            "Training Accuracy :0.09889999777078629\n",
            "Validation loss :2.3027358493804932\n",
            "Validation Accuracy :0.09679999947547913\n",
            "-----------EPOCH 7 ------------------ \n",
            "Training loss :2.302582064666748\n",
            "Training Accuracy :0.09867999702692032\n",
            "Validation loss :2.3027468746185304\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 8 ------------------ \n",
            "Training loss :2.3025810566711424\n",
            "Training Accuracy :0.10117999464273453\n",
            "Validation loss :2.3027572677612307\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 9 ------------------ \n",
            "Training loss :2.302579945526123\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027598388671877\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 10 ------------------ \n",
            "Training loss :2.3025820822906495\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027677227020265\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 11 ------------------ \n",
            "Training loss :2.302584390106201\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302777088546753\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 12 ------------------ \n",
            "Training loss :2.302580764312744\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027813243865967\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 13 ------------------ \n",
            "Training loss :2.3025785523986815\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027762947082517\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 14 ------------------ \n",
            "Training loss :2.302579789505005\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027862209320067\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 15 ------------------ \n",
            "Training loss :2.3025795217132567\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027822303771974\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 16 ------------------ \n",
            "Training loss :2.3025770212554932\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30278649520874\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 17 ------------------ \n",
            "Training loss :2.3025764657592775\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302785767364502\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 18 ------------------ \n",
            "Training loss :2.3025787657928465\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027999950408935\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 19 ------------------ \n",
            "Training loss :2.3025767101287844\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302783665084839\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 20 ------------------ \n",
            "Training loss :2.302577486495972\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027812881469725\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 21 ------------------ \n",
            "Training loss :2.3025741754150393\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027833209991453\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 22 ------------------ \n",
            "Training loss :2.302576632537842\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302782764816284\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 23 ------------------ \n",
            "Training loss :2.302572541656494\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302780010986328\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 24 ------------------ \n",
            "Training loss :2.3025743779754637\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30278737449646\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 25 ------------------ \n",
            "Training loss :2.3025721111297606\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027922332763673\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 26 ------------------ \n",
            "Training loss :2.3025713373565675\n",
            "Training Accuracy :0.10001999884843826\n",
            "Validation loss :2.3027818904876707\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 27 ------------------ \n",
            "Training loss :2.3025699713134764\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302775751876831\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 28 ------------------ \n",
            "Training loss :2.3025697064208983\n",
            "Training Accuracy :0.10040000081062317\n",
            "Validation loss :2.3027789386749267\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 29 ------------------ \n",
            "Training loss :2.3025607511901853\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027801727294923\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 30 ------------------ \n",
            "Training loss :2.302556190032959\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027729988098145\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 31 ------------------ \n",
            "Training loss :2.3025521002960203\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.302770729827881\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 32 ------------------ \n",
            "Training loss :2.302542787322998\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3027505504608152\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 33 ------------------ \n",
            "Training loss :2.3025233836364745\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.30272709236145\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 34 ------------------ \n",
            "Training loss :2.3024903224182127\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3026847003936766\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 35 ------------------ \n",
            "Training loss :2.30240476272583\n",
            "Training Accuracy :0.10115999728441238\n",
            "Validation loss :2.3025394638061525\n",
            "Validation Accuracy :0.094200000166893\n",
            "-----------EPOCH 36 ------------------ \n",
            "Training loss :2.3019368648529053\n",
            "Training Accuracy :0.12721998989582062\n",
            "Validation loss :2.3012278217315676\n",
            "Validation Accuracy :0.1777999997138977\n",
            "-----------EPOCH 37 ------------------ \n",
            "Training loss :2.279597487640381\n",
            "Training Accuracy :0.19064000248908997\n",
            "Validation loss :2.235949160003662\n",
            "Validation Accuracy :0.19299998879432678\n",
            "-----------EPOCH 38 ------------------ \n",
            "Training loss :2.2198183444976807\n",
            "Training Accuracy :0.2083600014448166\n",
            "Validation loss :2.2081125007629394\n",
            "Validation Accuracy :0.27889999747276306\n",
            "-----------EPOCH 39 ------------------ \n",
            "Training loss :2.165934194717407\n",
            "Training Accuracy :0.2922999858856201\n",
            "Validation loss :2.1311091957092283\n",
            "Validation Accuracy :0.3018999993801117\n",
            "-----------EPOCH 40 ------------------ \n",
            "Training loss :2.0686033478546144\n",
            "Training Accuracy :0.41307997703552246\n",
            "Validation loss :2.0007601905822754\n",
            "Validation Accuracy :0.4829999804496765\n",
            "-----------EPOCH 41 ------------------ \n",
            "Training loss :1.9480656634140014\n",
            "Training Accuracy :0.530299961566925\n",
            "Validation loss :1.9186954635620117\n",
            "Validation Accuracy :0.5485999584197998\n",
            "-----------EPOCH 42 ------------------ \n",
            "Training loss :1.9110614597320557\n",
            "Training Accuracy :0.559499979019165\n",
            "Validation loss :1.8766646844863892\n",
            "Validation Accuracy :0.6202999949455261\n",
            "-----------EPOCH 43 ------------------ \n",
            "Training loss :1.8603418619537353\n",
            "Training Accuracy :0.6179800033569336\n",
            "Validation loss :1.8442416246414184\n",
            "Validation Accuracy :0.6279000043869019\n",
            "-----------EPOCH 44 ------------------ \n",
            "Training loss :1.844420463218689\n",
            "Training Accuracy :0.62527996301651\n",
            "Validation loss :1.8357780994415283\n",
            "Validation Accuracy :0.6317999958992004\n",
            "-----------EPOCH 45 ------------------ \n",
            "Training loss :1.8373779360198974\n",
            "Training Accuracy :0.6291999816894531\n",
            "Validation loss :1.832895750427246\n",
            "Validation Accuracy :0.6345999836921692\n",
            "-----------EPOCH 46 ------------------ \n",
            "Training loss :1.832906433944702\n",
            "Training Accuracy :0.6324599981307983\n",
            "Validation loss :1.8298853477478028\n",
            "Validation Accuracy :0.6351999640464783\n",
            "-----------EPOCH 47 ------------------ \n",
            "Training loss :1.8296627550506592\n",
            "Training Accuracy :0.6344999670982361\n",
            "Validation loss :1.8247296201705934\n",
            "Validation Accuracy :0.6399999856948853\n",
            "-----------EPOCH 48 ------------------ \n",
            "Training loss :1.8269932629776\n",
            "Training Accuracy :0.6368799805641174\n",
            "Validation loss :1.82556397895813\n",
            "Validation Accuracy :0.6376999616622925\n",
            "-----------EPOCH 49 ------------------ \n",
            "Training loss :1.8243358437728883\n",
            "Training Accuracy :0.6393600106239319\n",
            "Validation loss :1.8209300020217896\n",
            "Validation Accuracy :0.6419999599456787\n",
            "-----------EPOCH 50 ------------------ \n",
            "Training loss :1.8224265991973876\n",
            "Training Accuracy :0.6411600112915039\n",
            "Validation loss :1.8192664154052733\n",
            "Validation Accuracy :0.6439999938011169\n",
            "-----------EPOCH 51 ------------------ \n",
            "Training loss :1.8220304190063477\n",
            "Training Accuracy :0.6408599615097046\n",
            "Validation loss :1.8182120903015138\n",
            "Validation Accuracy :0.6451999545097351\n",
            "-----------EPOCH 52 ------------------ \n",
            "Training loss :1.819991115951538\n",
            "Training Accuracy :0.642520010471344\n",
            "Validation loss :1.8150222902297974\n",
            "Validation Accuracy :0.6466999650001526\n",
            "-----------EPOCH 53 ------------------ \n",
            "Training loss :1.8196557147598267\n",
            "Training Accuracy :0.6426199674606323\n",
            "Validation loss :1.8176176166534423\n",
            "Validation Accuracy :0.6441999673843384\n",
            "-----------EPOCH 54 ------------------ \n",
            "Training loss :1.818084003944397\n",
            "Training Accuracy :0.6439599990844727\n",
            "Validation loss :1.8139926759719849\n",
            "Validation Accuracy :0.6473000049591064\n",
            "-----------EPOCH 55 ------------------ \n",
            "Training loss :1.81721282081604\n",
            "Training Accuracy :0.6444599628448486\n",
            "Validation loss :1.8170119785308838\n",
            "Validation Accuracy :0.6446999907493591\n",
            "-----------EPOCH 56 ------------------ \n",
            "Training loss :1.813517523727417\n",
            "Training Accuracy :0.6469999551773071\n",
            "Validation loss :1.7989439331054689\n",
            "Validation Accuracy :0.6667999625205994\n",
            "-----------EPOCH 57 ------------------ \n",
            "Training loss :1.7654494311141968\n",
            "Training Accuracy :0.7079600095748901\n",
            "Validation loss :1.7513889980316162\n",
            "Validation Accuracy :0.7163000106811523\n",
            "-----------EPOCH 58 ------------------ \n",
            "Training loss :1.7451060052871703\n",
            "Training Accuracy :0.7230599522590637\n",
            "Validation loss :1.7418383058547973\n",
            "Validation Accuracy :0.7231999635696411\n",
            "-----------EPOCH 59 ------------------ \n",
            "Training loss :1.7412510290908814\n",
            "Training Accuracy :0.7244399785995483\n",
            "Validation loss :1.7430425802230836\n",
            "Validation Accuracy :0.7226999998092651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ4SuwPG6KnV"
      },
      "source": [
        "best_acc_cpu_wr=[0.8971]\n",
        "for i in range(1,len(best_acc_list_wr)):\n",
        "  best_acc_cpu_wr.append(best_acc_list_wr[i].cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "OAJcUeg06A0Y",
        "outputId": "19d562f3-f231-46fc-e337-9ddc0cc434c7"
      },
      "source": [
        "#plotting sparsity vs accuracy\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(0,1)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"validation accuracy\")\n",
        "plt.scatter(sparsity_wr,best_acc_cpu_wr)\n",
        "plt.plot(sparsity_wr,best_acc_list_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61f5862650>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "OPwPcCoL6cba",
        "outputId": "7755e5af-5d54-44af-e3b6-f976b184214a"
      },
      "source": [
        "#comparing acc of random reinit vs lottery ticket based init\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(0.7,0.95)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"validation accuracy\")\n",
        "plt.scatter(sparsity,best_acc_cpu)\n",
        "plt.plot(sparsity,best_acc_list)\n",
        "plt.scatter(sparsity_wr,best_acc_cpu_wr)\n",
        "plt.plot(sparsity_wr,best_acc_list_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61f57c1610>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWDX3a6KG1d7",
        "outputId": "04969905-0a8d-465c-9932-0f0bf82788e9"
      },
      "source": [
        "sparsity_wr,best_acc_cpu_wr,early_stop_list_wr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.8,\n",
              "  0.6400000000000001,\n",
              "  0.5120000000000001,\n",
              "  0.4096000000000001,\n",
              "  0.3276800000000001,\n",
              "  0.2621440000000001,\n",
              "  0.20971520000000007,\n",
              "  0.1677721600000001,\n",
              "  0.13421772800000006,\n",
              "  0.10737418240000006,\n",
              "  0.08589934592000005,\n",
              "  0.06871947673600004,\n",
              "  0.054975581388800036,\n",
              "  0.043980465111040035,\n",
              "  0.03518437208883203,\n",
              "  0.028147497671065624,\n",
              "  0.022517998136852502,\n",
              "  0.018014398509482003,\n",
              "  0.014411518807585602,\n",
              "  0.011529215046068483],\n",
              " [0.8971,\n",
              "  tensor(0.8461),\n",
              "  tensor(0.8423),\n",
              "  tensor(0.8424),\n",
              "  tensor(0.8417),\n",
              "  tensor(0.8433),\n",
              "  tensor(0.8426),\n",
              "  tensor(0.8405),\n",
              "  tensor(0.8394),\n",
              "  tensor(0.8402),\n",
              "  tensor(0.8382),\n",
              "  tensor(0.8397),\n",
              "  tensor(0.8339),\n",
              "  tensor(0.8293),\n",
              "  tensor(0.8319),\n",
              "  tensor(0.8225),\n",
              "  tensor(0.8238),\n",
              "  tensor(0.8204),\n",
              "  tensor(0.8111),\n",
              "  tensor(0.7285),\n",
              "  tensor(0.7232)],\n",
              " [52,\n",
              "  58,\n",
              "  51,\n",
              "  58,\n",
              "  45,\n",
              "  59,\n",
              "  57,\n",
              "  55,\n",
              "  51,\n",
              "  59,\n",
              "  52,\n",
              "  59,\n",
              "  56,\n",
              "  55,\n",
              "  56,\n",
              "  59,\n",
              "  56,\n",
              "  56,\n",
              "  58,\n",
              "  59,\n",
              "  58])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "SzHCz2I0ZTw-",
        "outputId": "55b133d4-0d14-4334-aa3b-c5e8f2d549e7"
      },
      "source": [
        "#plotting early stopping vs sparsity\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(20,60)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"early stopping iteration\")\n",
        "plt.scatter(sparsity_wr,early_stop_list_wr)\n",
        "plt.plot(sparsity_wr,early_stop_list_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61f571c190>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "qfhu9ZbXZ2P3",
        "outputId": "94fcc2dc-26d6-4a64-ddf4-4318f0533e50"
      },
      "source": [
        "#comparing early stopping iterations for random reinit and lottery ticket based\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.xlim(1,0)\n",
        "plt.ylim(20,60)\n",
        "plt.xlabel(\"sparsity\")\n",
        "plt.ylabel(\"early stopping iteration\")\n",
        "#plt.scatter(sparsity,early_stop_list)\n",
        "plt.plot(sparsity,early_stop_list)\n",
        "#plt.scatter(sparsity_wr,early_stop_list_wr)\n",
        "plt.plot(sparsity_wr,early_stop_list_wr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61f565cf10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}